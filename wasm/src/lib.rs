//! CoreGuard WASM module for fast SNP comparison visualization
//!
//! This module loads JSON reports generated by `coreguard compare` and provides
//! fast querying and rendering for the browser-based viewer.

use wasm_bindgen::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// A gap region [start, end) - 1-based positions
#[derive(Clone, Debug)]
struct GapRegion {
    start: u32,
    end: u32,
}

/// SNP data at a position
#[derive(Clone, Debug)]
struct Snp {
    pos: u32,
    ref_allele: u8,  // ASCII char code
    alt_allele: u8,  // ASCII char code
    qual: f32,
    depth: u16,
}

/// Pipeline data with gaps and SNPs stored in sorted vectors for binary search
#[derive(Default)]
struct PipelineData {
    gaps: Vec<GapRegion>,
    snps: Vec<Snp>,
    has_vcf: bool,
    has_bam: bool,
    vcf_path: Option<String>,
    bam_path: Option<String>,
}

/// Sample data containing data for each pipeline
#[derive(Default)]
struct SampleData {
    pipelines: HashMap<String, PipelineData>,
}

/// Report schema matching the JSON from `coreguard compare`
#[derive(Debug, Deserialize, Serialize)]
struct JsonReport {
    #[serde(rename = "_version")]
    version: String,
    reference: JsonReference,
    samples: HashMap<String, JsonSampleInfo>,
    pipelines: HashMap<String, JsonPipelineInfo>,
    data: HashMap<String, HashMap<String, JsonPipelineData>>,
    summary: JsonSummary,
    /// Description (markdown content)
    #[serde(default)]
    description: Option<String>,
    /// Pre-computed distance matrices from pipelines
    #[serde(default)]
    pipeline_distance_matrices: HashMap<String, JsonPipelineDistanceMatrix>,
    /// Pre-computed GT disc vs pipeline results
    #[serde(default)]
    gt_disc_vs_pipelines: Option<Vec<JsonGtDiscVsPipelineResult>>,
}

/// Pre-computed GT disc vs pipeline result (from CLI compare)
#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonGtDiscVsPipelineResult {
    pipeline_id: String,
    #[serde(default)]
    pl_total_core_snps: u32,
    #[serde(default)]
    pl_discriminating_core_snps: u32,
    gap_intersect: JsonGapStrategyResult,
    gap_union: JsonGapStrategyResult,
    pairwise: JsonPairwiseGtDiscResult,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonGapStrategyResult {
    gt_disc: u32,
    same_pos: u32,
    concordant: Option<u32>,
    pl_snps_in_gt_gaps: u32,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPairwiseGtDiscResult {
    gt_disc_avg: f64,
    same_pos_avg: f64,
    concordant_avg: Option<f64>,
    num_pairs: u32,
}

/// Pre-computed distance matrix from a pipeline
#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPipelineDistanceMatrix {
    samples: Vec<String>,
    matrix: Vec<Vec<i64>>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonReference {
    name: String,
    label: Option<String>,
    length: usize,
    sequence: String,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonSampleInfo {
    label: Option<String>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonPipelineInfo {
    label: Option<String>,
    command: Option<String>,
    has_vcf: bool,
    has_bam: bool,
    #[serde(default)]
    ground_truth: bool,
    #[serde(default)]
    from_bam_pileup: bool,
}

#[derive(Debug, Deserialize, Serialize, Default)]
struct JsonPipelineData {
    #[serde(default)]
    gaps: Vec<[usize; 2]>,
    #[serde(default)]
    snps: Vec<JsonSnp>,
    #[serde(default)]
    vcf_path: Option<String>,
    #[serde(default)]
    bam_path: Option<String>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonSnp {
    pos: usize,
    #[serde(rename = "ref")]
    ref_allele: String,
    alt: String,
    qual: f64,
    dp: usize,
}

#[derive(Debug, Deserialize, Serialize)]
#[allow(dead_code)]
struct JsonSummary {
    total_samples: usize,
    total_pipelines: usize,
    generated_at: String,
    coreguard_version: String,
    #[serde(default)]
    warnings: Vec<String>,
}

/// Main data store - holds all samples and pipeline data
#[wasm_bindgen]
pub struct GenomeData {
    samples: HashMap<String, SampleData>,
    sample_labels: HashMap<String, String>,
    pipeline_ids: Vec<String>,  // Ordered list of pipelines
    pipeline_labels: HashMap<String, String>,
    pipeline_commands: HashMap<String, String>,
    /// Pipelines where SNPs come from BAM pileup (no variant calling)
    pipelines_from_bam_pileup: std::collections::HashSet<String>,
    /// Ground truth pipeline ID (if any) - used as baseline for comparison
    ground_truth_pipeline: Option<String>,
    ref_seq: String,
    ref_name: String,
    ref_label: Option<String>,
    ref_len: u32,
    report_version: String,
    generated_at: String,
    warnings: Vec<String>,
    /// Description (markdown content)
    description: Option<String>,
    /// Pre-computed distance matrices from pipelines
    pipeline_distance_matrices: HashMap<String, JsonPipelineDistanceMatrix>,
    /// Pre-computed GT disc vs pipeline results
    gt_disc_vs_pipelines: Option<Vec<JsonGtDiscVsPipelineResult>>,
}

#[wasm_bindgen]
impl GenomeData {
    /// Create a new empty GenomeData
    #[wasm_bindgen(constructor)]
    pub fn new() -> GenomeData {
        GenomeData {
            samples: HashMap::new(),
            sample_labels: HashMap::new(),
            pipeline_ids: Vec::new(),
            pipeline_labels: HashMap::new(),
            pipeline_commands: HashMap::new(),
            pipelines_from_bam_pileup: std::collections::HashSet::new(),
            ground_truth_pipeline: None,
            ref_seq: String::new(),
            ref_name: String::new(),
            ref_label: None,
            ref_len: 0,
            report_version: String::new(),
            generated_at: String::new(),
            warnings: Vec::new(),
            description: None,
            pipeline_distance_matrices: HashMap::new(),
            gt_disc_vs_pipelines: None,
        }
    }

    /// Load data from JSON report (the main entry point)
    #[wasm_bindgen]
    pub fn load_json(&mut self, json: &str) -> Result<(), JsValue> {
        let report: JsonReport = serde_json::from_str(json)
            .map_err(|e| JsValue::from_str(&format!("JSON parse error: {}", e)))?;

        self.load_report(report)
    }

    /// Load data from binary (bincode) report - faster than JSON
    #[wasm_bindgen]
    pub fn load_binary(&mut self, data: &[u8]) -> Result<(), JsValue> {
        let report: JsonReport = bincode::deserialize(data)
            .map_err(|e| JsValue::from_str(&format!("Bincode parse error: {}", e)))?;

        self.load_report(report)
    }

    /// Common logic for loading a parsed report (used by both load_json and load_binary)
    fn load_report(&mut self, report: JsonReport) -> Result<(), JsValue> {
        let t0 = js_sys::Date::now();

        // Clear existing data
        self.samples.clear();
        self.sample_labels.clear();
        self.pipeline_ids.clear();
        self.pipeline_labels.clear();
        self.pipeline_commands.clear();
        self.pipelines_from_bam_pileup.clear();
        self.ground_truth_pipeline = None;

        // Load reference
        self.ref_seq = report.reference.sequence;
        self.ref_name = report.reference.name;
        self.ref_label = report.reference.label;
        self.ref_len = report.reference.length as u32;
        self.report_version = report.version;
        self.generated_at = report.summary.generated_at;
        self.warnings = report.summary.warnings;
        self.description = report.description;
        self.pipeline_distance_matrices = report.pipeline_distance_matrices;
        self.gt_disc_vs_pipelines = report.gt_disc_vs_pipelines;

        // Load sample labels
        for (id, info) in &report.samples {
            if let Some(label) = &info.label {
                self.sample_labels.insert(id.clone(), label.clone());
            }
        }

        // Detect ground truth pipeline from JSON
        for (id, info) in &report.pipelines {
            if info.ground_truth {
                self.ground_truth_pipeline = Some(id.clone());
                break;
            }
        }

        // Load pipeline metadata (ground truth first, then alphabetical)
        let mut pipeline_ids: Vec<_> = report.pipelines.keys().cloned().collect();
        let gt_id = self.ground_truth_pipeline.clone();
        pipeline_ids.sort_by(|a, b| {
            // Ground truth pipeline always first
            match (&gt_id, a.as_str(), b.as_str()) {
                (Some(gt), a_str, _) if a_str == gt => std::cmp::Ordering::Less,
                (Some(gt), _, b_str) if b_str == gt => std::cmp::Ordering::Greater,
                _ => a.cmp(b),
            }
        });
        for id in &pipeline_ids {
            if let Some(info) = report.pipelines.get(id) {
                if let Some(label) = &info.label {
                    self.pipeline_labels.insert(id.clone(), label.clone());
                }
                if let Some(command) = &info.command {
                    self.pipeline_commands.insert(id.clone(), command.clone());
                }
                if info.from_bam_pileup {
                    self.pipelines_from_bam_pileup.insert(id.clone());
                }
            }
        }
        self.pipeline_ids = pipeline_ids;

        let t1 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Metadata loaded: {}ms", t1 - t0).into());

        // Load data for each sample
        for (sample_id, sample_pipelines) in &report.data {
            let mut sample_data = SampleData::default();

            for (pipeline_id, json_data) in sample_pipelines {
                let mut pipeline_data = PipelineData::default();

                // Load gaps
                for gap in &json_data.gaps {
                    pipeline_data.gaps.push(GapRegion {
                        start: gap[0] as u32,
                        end: gap[1] as u32,
                    });
                }

                // Load SNPs
                for snp in &json_data.snps {
                    let ref_char = snp.ref_allele.chars().next().unwrap_or('N') as u8;
                    let alt_char = snp.alt.chars().next().unwrap_or('N') as u8;
                    pipeline_data.snps.push(Snp {
                        pos: snp.pos as u32,
                        ref_allele: ref_char,
                        alt_allele: alt_char,
                        qual: snp.qual as f32,
                        depth: snp.dp as u16,
                    });
                }

                // Store pipeline info
                if let Some(info) = report.pipelines.get(pipeline_id) {
                    pipeline_data.has_vcf = info.has_vcf;
                    pipeline_data.has_bam = info.has_bam;
                }

                // Store file paths for reproducibility
                pipeline_data.vcf_path = json_data.vcf_path.clone();
                pipeline_data.bam_path = json_data.bam_path.clone();

                sample_data.pipelines.insert(pipeline_id.clone(), pipeline_data);
            }

            self.samples.insert(sample_id.clone(), sample_data);
        }

        let t2 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Data loaded: {}ms", t2 - t1).into());

        // Finalize (sort for binary search)
        self.finalize();

        let t3 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Finalized: {}ms", t3 - t2).into());

        web_sys::console::log_1(&format!("TOTAL: {}ms", js_sys::Date::now() - t0).into());

        web_sys::console::log_1(&format!(
            "Loaded report v{}: {} samples, {} pipelines, {} bp reference",
            self.report_version,
            self.samples.len(),
            self.pipeline_ids.len(),
            self.ref_len,
        ).into());

        Ok(())
    }

    /// Sort all data for binary search (called after loading)
    fn finalize(&mut self) {
        for sample_data in self.samples.values_mut() {
            for pipeline_data in sample_data.pipelines.values_mut() {
                pipeline_data.gaps.sort_by_key(|g| g.start);
                pipeline_data.snps.sort_by_key(|s| s.pos);
            }
        }
    }

    /// Get reference length
    #[wasm_bindgen]
    pub fn get_ref_length(&self) -> u32 {
        self.ref_len
    }

    /// Get reference name
    #[wasm_bindgen]
    pub fn get_ref_name(&self) -> String {
        self.ref_label.clone().unwrap_or_else(|| self.ref_name.clone())
    }

    /// Get all sample IDs as JSON array
    #[wasm_bindgen]
    pub fn get_sample_ids(&self) -> String {
        let mut ids: Vec<_> = self.samples.keys().cloned().collect();
        ids.sort();
        serde_json::to_string(&ids).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get display label for a sample
    #[wasm_bindgen]
    pub fn get_sample_label(&self, sample_id: &str) -> String {
        self.sample_labels.get(sample_id)
            .cloned()
            .unwrap_or_else(|| sample_id.to_string())
    }

    /// Get all pipeline IDs as JSON array
    #[wasm_bindgen]
    pub fn get_pipeline_ids(&self) -> String {
        serde_json::to_string(&self.pipeline_ids).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get display label for a pipeline
    #[wasm_bindgen]
    pub fn get_pipeline_label(&self, pipeline_id: &str) -> String {
        self.pipeline_labels.get(pipeline_id)
            .cloned()
            .unwrap_or_else(|| pipeline_id.to_string())
    }

    /// Get command for a pipeline (if any)
    #[wasm_bindgen]
    pub fn get_pipeline_command(&self, pipeline_id: &str) -> Option<String> {
        self.pipeline_commands.get(pipeline_id).cloned()
    }

    /// Get ground truth pipeline ID (if any)
    #[wasm_bindgen]
    pub fn get_ground_truth_pipeline(&self) -> Option<String> {
        self.ground_truth_pipeline.clone()
    }

    /// Check if a pipeline is the ground truth
    #[wasm_bindgen]
    pub fn is_ground_truth(&self, pipeline_id: &str) -> bool {
        self.ground_truth_pipeline.as_ref().map(|gt| gt == pipeline_id).unwrap_or(false)
    }

    /// Check if a pipeline's SNPs come from BAM pileup (no variant calling)
    #[wasm_bindgen]
    pub fn is_from_bam_pileup(&self, pipeline_id: &str) -> bool {
        self.pipelines_from_bam_pileup.contains(pipeline_id)
    }

    /// Get pipelines that have VCF data (used for consensus/discordant)
    #[wasm_bindgen]
    pub fn get_vcf_pipelines(&self) -> String {
        let vcf_pipelines: Vec<&String> = self.pipeline_ids.iter()
            .filter(|p| {
                self.samples.values().any(|sd| {
                    sd.pipelines.get(*p)
                        .map(|pd| pd.has_vcf)
                        .unwrap_or(false)
                })
            })
            .collect();
        serde_json::to_string(&vcf_pipelines).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get report generation timestamp
    #[wasm_bindgen]
    pub fn get_generated_at(&self) -> String {
        self.generated_at.clone()
    }

    /// Get warnings as JSON array
    #[wasm_bindgen]
    pub fn get_warnings(&self) -> String {
        serde_json::to_string(&self.warnings).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get report description (markdown content)
    /// Returns: description string or null if not available
    #[wasm_bindgen]
    pub fn get_description(&self) -> String {
        match &self.description {
            Some(desc) => desc.clone(),
            None => "".to_string(),
        }
    }

    /// Get pre-computed distance matrices from pipelines
    /// Returns: JSON object { pipeline_id: { samples: [...], matrix: [[...], ...] } }
    #[wasm_bindgen]
    pub fn get_pipeline_distance_matrices(&self) -> String {
        if self.pipeline_distance_matrices.is_empty() {
            "{}".to_string()
        } else {
            serde_json::to_string(&self.pipeline_distance_matrices)
                .unwrap_or_else(|_| "{}".to_string())
        }
    }

    /// Build a SNP map for a sample/pipeline, filtering out SNPs where alt == genomic reference.
    /// These bogus SNPs arise from BAM pileup when the local alignment reference differs from
    /// the FASTA reference. Returns HashMap<position, alt_allele>.
    fn build_snp_map(&self, pipeline_data: &PipelineData) -> HashMap<u32, u8> {
        let ref_bytes = self.ref_seq.as_bytes();
        pipeline_data.snps.iter()
            .filter(|s| {
                let pos = s.pos as usize;
                // Keep SNP only if alt != genomic reference at this position
                pos < ref_bytes.len() && s.alt_allele != ref_bytes[pos]
            })
            .map(|s| (s.pos, s.alt_allele))
            .collect()
    }

    /// Get reference nucleotide at position (0-based index)
    fn get_ref_nuc(&self, pos: u32) -> char {
        self.ref_seq.chars().nth(pos as usize).unwrap_or('N')
    }

    /// Check if position is in a gap for a sample/pipeline
    fn is_gap(&self, sample: &str, pipeline: &str, pos: u32) -> bool {
        self.samples.get(sample)
            .and_then(|s| s.pipelines.get(pipeline))
            .map(|p| Self::pos_in_gaps(&p.gaps, pos))
            .unwrap_or(false)
    }

    /// Get SNP alt allele at position (returns empty if no SNP)
    fn get_snp_alt(&self, sample: &str, pipeline: &str, pos: u32) -> String {
        self.samples.get(sample)
            .and_then(|s| s.pipelines.get(pipeline))
            .and_then(|p| Self::find_snp(&p.snps, pos))
            .map(|s| (s.alt_allele as char).to_string())
            .unwrap_or_default()
    }

    /// Get SNP at position (returns "ref,alt,qual,depth" or empty string)
    #[wasm_bindgen]
    pub fn get_snp(&self, sample: &str, pipeline: &str, pos: u32) -> String {
        self.samples.get(sample)
            .and_then(|s| s.pipelines.get(pipeline))
            .and_then(|p| Self::find_snp(&p.snps, pos))
            .map(|s| format!("{},{},{},{}",
                s.ref_allele as char,
                s.alt_allele as char,
                s.qual,
                s.depth))
            .unwrap_or_default()
    }

    /// Get KPI summary as JSON
    #[wasm_bindgen]
    pub fn get_kpis(&self) -> String {
        let ref_bytes = self.ref_seq.as_bytes();
        let mut total_snps: HashMap<String, u32> = HashMap::new();
        let mut total_gaps: HashMap<String, u32> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut snp_count = 0u32;
            let mut gap_bases = 0u32;

            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    snp_count += pipeline_data.snps.iter()
                        .filter(|s| {
                            let pos = s.pos as usize;
                            pos < ref_bytes.len() && s.alt_allele != ref_bytes[pos]
                        })
                        .count() as u32;
                    gap_bases += pipeline_data.gaps.iter()
                        .map(|g| g.end - g.start)
                        .sum::<u32>();
                }
            }

            total_snps.insert(pipeline_id.clone(), snp_count);
            total_gaps.insert(pipeline_id.clone(), gap_bases);
        }

        // Calculate core SNPs per pipeline (positions present in ALL samples)
        // Store both counts and position sets for GT comparison
        let mut core_snps: HashMap<String, u32> = HashMap::new();
        let mut core_positions: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut sample_positions: Vec<std::collections::HashSet<u32>> = Vec::new();

            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    let positions: std::collections::HashSet<u32> = pipeline_data.snps.iter()
                        .map(|s| s.pos)
                        .collect();
                    sample_positions.push(positions);
                }
            }

            // Intersection of all samples = core SNPs
            let core_set = if sample_positions.len() > 1 {
                let mut core = sample_positions[0].clone();
                for positions in &sample_positions[1..] {
                    core = core.intersection(positions).cloned().collect();
                }
                core
            } else if sample_positions.len() == 1 {
                sample_positions[0].clone()
            } else {
                std::collections::HashSet::new()
            };

            core_snps.insert(pipeline_id.clone(), core_set.len() as u32);
            core_positions.insert(pipeline_id.clone(), core_set);
        }

        // Calculate consensus SNPs per pipeline
        // Consensus = positions where ALL samples have the SAME alt allele
        let mut consensus_snps: HashMap<String, u32> = HashMap::new();
        let mut consensus_positions: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            // For each position in core, check if all samples have the same alt
            let core_pos = core_positions.get(pipeline_id).cloned().unwrap_or_default();
            let mut consensus_set: std::collections::HashSet<u32> = std::collections::HashSet::new();

            for &pos in &core_pos {
                // Get alt allele for each sample at this position
                let mut alts: Vec<u8> = Vec::new();
                let mut all_have_snp = true;

                let ref_base = ref_bytes.get(pos as usize).copied().unwrap_or(b'N');
                for sample_data in self.samples.values() {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                            if snp.alt_allele == ref_base {
                                // alt == genomic ref: not a real SNP
                                all_have_snp = false;
                                break;
                            }
                            alts.push(snp.alt_allele);
                        } else {
                            all_have_snp = false;
                            break;
                        }
                    } else {
                        all_have_snp = false;
                        break;
                    }
                }

                // Check if all samples have the same alt
                if all_have_snp && !alts.is_empty() && alts.iter().all(|&a| a == alts[0]) {
                    consensus_set.insert(pos);
                }
            }

            consensus_snps.insert(pipeline_id.clone(), consensus_set.len() as u32);
            consensus_positions.insert(pipeline_id.clone(), consensus_set);
        }

        // Calculate GT SNPs missing per pipeline
        // For each pipeline: sum across samples of (GT SNPs not called by pipeline)
        let mut gt_snps_missing: HashMap<String, u32> = HashMap::new();
        let mut gt_snps_called: HashMap<String, u32> = HashMap::new();
        let mut gt_total_snps: u32 = 0;

        // Core GT missing and Consensus GT missing
        let mut core_gt_missing: HashMap<String, u32> = HashMap::new();
        let mut core_gt_total: u32 = 0;
        let mut consensus_gt_missing: HashMap<String, u32> = HashMap::new();
        let mut consensus_gt_total: u32 = 0;

        if let Some(ref gt_id) = self.ground_truth_pipeline {
            // First calculate total GT SNPs
            for sample_data in self.samples.values() {
                if let Some(gt_data) = sample_data.pipelines.get(gt_id) {
                    gt_total_snps += gt_data.snps.len() as u32;
                }
            }

            // Get Core GT and Consensus GT
            let gt_core = core_positions.get(gt_id).cloned().unwrap_or_default();
            let gt_consensus = consensus_positions.get(gt_id).cloned().unwrap_or_default();
            core_gt_total = gt_core.len() as u32;
            consensus_gt_total = gt_consensus.len() as u32;

            // For each non-GT pipeline, calculate missing GT SNPs
            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_id {
                    continue;
                }

                let mut missing = 0u32;
                let mut called = 0u32;

                for sample_data in self.samples.values() {
                    // Get GT SNP positions for this sample
                    let gt_positions: std::collections::HashSet<u32> = sample_data
                        .pipelines.get(gt_id)
                        .map(|p| p.snps.iter().map(|s| s.pos).collect())
                        .unwrap_or_default();

                    // Get pipeline SNP positions for this sample
                    let pipeline_positions: std::collections::HashSet<u32> = sample_data
                        .pipelines.get(pipeline_id)
                        .map(|p| p.snps.iter().map(|s| s.pos).collect())
                        .unwrap_or_default();

                    // GT ∩ Pipeline = GT positions that pipeline also calls
                    let intersection = gt_positions.intersection(&pipeline_positions).count() as u32;
                    called += intersection;

                    // GT SNPs not in pipeline = |GT| - |GT ∩ Pipeline|
                    missing += gt_positions.len() as u32 - intersection;
                }

                gt_snps_missing.insert(pipeline_id.clone(), missing);
                gt_snps_called.insert(pipeline_id.clone(), called);

                // Core GT missing: |Core GT| - |Core GT ∩ Core Pipeline|
                let pipeline_core = core_positions.get(pipeline_id).cloned().unwrap_or_default();
                let core_intersection = gt_core.intersection(&pipeline_core).count() as u32;
                core_gt_missing.insert(pipeline_id.clone(), core_gt_total - core_intersection);

                // Consensus GT missing: |Consensus GT| - |Consensus GT ∩ Consensus Pipeline|
                let pipeline_consensus = consensus_positions.get(pipeline_id).cloned().unwrap_or_default();
                let consensus_intersection = gt_consensus.intersection(&pipeline_consensus).count() as u32;
                consensus_gt_missing.insert(pipeline_id.clone(), consensus_gt_total - consensus_intersection);
            }
        }

        // Calculate SNPs in GT gaps for total, core, and consensus
        let mut snps_in_gt_gaps_total: HashMap<String, u32> = HashMap::new();
        let mut snps_in_gt_gaps_core: HashMap<String, u32> = HashMap::new();
        let mut snps_in_gt_gaps_consensus: HashMap<String, u32> = HashMap::new();

        if let Some(ref gt_id) = self.ground_truth_pipeline {
            // Collect all GT gap regions across all samples
            let mut all_gt_gaps: Vec<(u32, u32)> = Vec::new();
            for sample_data in self.samples.values() {
                if let Some(gt_data) = sample_data.pipelines.get(gt_id) {
                    for gap in &gt_data.gaps {
                        all_gt_gaps.push((gap.start, gap.end));
                    }
                }
            }

            // Helper to check if position is in any GT gap
            let in_gt_gap = |pos: u32| -> bool {
                all_gt_gaps.iter().any(|(start, end)| pos >= *start && pos < *end)
            };

            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_id {
                    continue;
                }

                // Total SNPs in GT gaps (sum across samples)
                let mut total_in_gaps = 0u32;
                for sample_data in self.samples.values() {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        // Get GT gaps for this sample
                        let sample_gt_gaps: Vec<(u32, u32)> = sample_data.pipelines.get(gt_id)
                            .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                            .unwrap_or_default();

                        total_in_gaps += pipeline_data.snps.iter()
                            .filter(|snp| sample_gt_gaps.iter().any(|(s, e)| snp.pos >= *s && snp.pos < *e))
                            .count() as u32;
                    }
                }
                snps_in_gt_gaps_total.insert(pipeline_id.clone(), total_in_gaps);

                // Core SNPs in GT gaps
                let pipeline_core = core_positions.get(pipeline_id).cloned().unwrap_or_default();
                let core_in_gaps = pipeline_core.iter()
                    .filter(|&&pos| in_gt_gap(pos))
                    .count() as u32;
                snps_in_gt_gaps_core.insert(pipeline_id.clone(), core_in_gaps);

                // Consensus SNPs in GT gaps
                let pipeline_cons = consensus_positions.get(pipeline_id).cloned().unwrap_or_default();
                let cons_in_gaps = pipeline_cons.iter()
                    .filter(|&&pos| in_gt_gap(pos))
                    .count() as u32;
                snps_in_gt_gaps_consensus.insert(pipeline_id.clone(), cons_in_gaps);
            }
        }

        #[derive(Serialize)]
        struct Kpis {
            snps: HashMap<String, u32>,
            gaps: HashMap<String, u32>,
            core_snps: HashMap<String, u32>,
            consensus_snps: HashMap<String, u32>,
            gt_snps_missing: HashMap<String, u32>,
            gt_snps_called: HashMap<String, u32>,
            gt_total_snps: u32,
            core_gt_missing: HashMap<String, u32>,
            core_gt_total: u32,
            consensus_gt_missing: HashMap<String, u32>,
            consensus_gt_total: u32,
            snps_in_gt_gaps_total: HashMap<String, u32>,
            snps_in_gt_gaps_core: HashMap<String, u32>,
            snps_in_gt_gaps_consensus: HashMap<String, u32>,
            samples: usize,
            pipelines: usize,
            ref_length: u32,
        }

        let kpis = Kpis {
            snps: total_snps,
            gaps: total_gaps,
            core_snps,
            consensus_snps,
            gt_snps_missing,
            gt_snps_called,
            gt_total_snps,
            core_gt_missing,
            core_gt_total,
            consensus_gt_missing,
            consensus_gt_total,
            snps_in_gt_gaps_total,
            snps_in_gt_gaps_core,
            snps_in_gt_gaps_consensus,
            samples: self.samples.len(),
            pipelines: self.pipeline_ids.len(),
            ref_length: self.ref_len,
        };

        serde_json::to_string(&kpis).unwrap_or_else(|_| "{}".to_string())
    }

    /// Global stats for GT pipeline (backward compat)
    #[wasm_bindgen]
    pub fn get_global_stats(&self) -> String {
        match &self.ground_truth_pipeline {
            Some(id) => self.get_global_stats_for_pipeline(id),
            None => "null".to_string(),
        }
    }

    /// Global stats for a specific pipeline: both union and intersection of gaps
    ///
    /// Strict (union): exclude position if at least 1 sample has gap
    /// Relaxed (intersection): exclude position only if ALL samples have gap
    /// For each: Usable Space, Total SNPs (in usable space), Consensus SNPs, Discriminating SNPs
    #[wasm_bindgen]
    pub fn get_global_stats_for_pipeline(&self, pipeline_id: &str) -> String {
        #[derive(Serialize)]
        struct DiscBreakdown {
            gap_affected: u32,
            gt_consensus: u32,
            majority_rule: u32,
            confirmed: u32,
        }

        #[derive(Serialize)]
        struct GlobalVariant {
            usable_space: u32,
            usable_space_pct: f64,
            total_snps: u32,
            consensus_snps: u32,
            discriminating_snps: u32,
            disc_breakdown: DiscBreakdown,
            missing_calls: u32,
        }

        #[derive(Serialize)]
        struct GlobalStats {
            strict: GlobalVariant,
            relaxed: GlobalVariant,
        }

        let pid = pipeline_id.to_string();

        let sample_ids: Vec<&String> = self.samples.keys().collect();

        // Build per-sample gap sets for the target pipeline
        let mut sample_gap_sets: Vec<std::collections::HashSet<u32>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let mut gap_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
            if let Some(p_data) = sample_data.pipelines.get(&pid) {
                for gap in &p_data.gaps {
                    for pos in gap.start..gap.end {
                        gap_positions.insert(pos);
                    }
                }
            }
            sample_gap_sets.push(gap_positions);
        }

        // Union: positions where at least 1 sample has gap
        let mut gap_union: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for gs in &sample_gap_sets {
            gap_union.extend(gs);
        }

        // Intersection: positions where ALL samples have gap
        let gap_intersection = if sample_gap_sets.len() > 1 {
            let mut isect = sample_gap_sets[0].clone();
            for gs in &sample_gap_sets[1..] {
                isect = isect.intersection(gs).cloned().collect();
            }
            isect
        } else if sample_gap_sets.len() == 1 {
            sample_gap_sets[0].clone()
        } else {
            std::collections::HashSet::new()
        };

        // Build per-sample SNP maps for the target pipeline
        let mut snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let snps: HashMap<u32, u8> = sample_data.pipelines.get(&pid)
                .map(|p| self.build_snp_map(p))
                .unwrap_or_default();
            snp_maps.push(snps);
        }

        // Build per-sample GT SNP maps (for cross-check heuristic)
        let gt_id = self.ground_truth_pipeline.clone().unwrap_or_default();
        let is_gt_pipeline = pid == gt_id;
        let mut gt_snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
        if !is_gt_pipeline && !gt_id.is_empty() {
            for sample_id in &sample_ids {
                let sample_data = &self.samples[*sample_id];
                let snps: HashMap<u32, u8> = sample_data.pipelines.get(&gt_id)
                    .map(|p| self.build_snp_map(p))
                    .unwrap_or_default();
                gt_snp_maps.push(snps);
            }
        }

        // All SNP positions for this pipeline
        let mut all_snp_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for snp_map in &snp_maps {
            all_snp_positions.extend(snp_map.keys());
        }

        // Helper: check if GT shows consensus at a position
        // Returns true if all samples agree in GT (all same alt, or all ref)
        let gt_is_consensus_at = |pos: u32| -> bool {
            if is_gt_pipeline || gt_snp_maps.is_empty() {
                return false;
            }
            let first = gt_snp_maps[0].get(&pos).copied();
            gt_snp_maps.iter().all(|m| m.get(&pos).copied() == first)
        };

        // Helper: check majority rule on a set of alleles
        // Returns true if all-but-one agree (N-1 have same allele, 1 differs)
        let is_majority = |alleles: &[Option<u8>]| -> bool {
            if alleles.len() < 3 { return false; } // need ≥3 to have meaningful majority
            // Count occurrences of each allele
            let mut counts: HashMap<Option<u8>, usize> = HashMap::new();
            for a in alleles {
                *counts.entry(*a).or_insert(0) += 1;
            }
            // Check if one allele has N-1 and another has 1
            let max_count = counts.values().max().copied().unwrap_or(0);
            max_count == alleles.len() - 1 && counts.len() == 2
        };

        let compute_variant = |gap_set: &std::collections::HashSet<u32>, gap_aware: bool| -> GlobalVariant {
            let usable_space = self.ref_len - gap_set.len() as u32;
            let usable_space_pct = (usable_space as f64 / self.ref_len as f64) * 100.0;

            let mut total_count: u32 = 0;
            let mut consensus_count: u32 = 0;
            let mut discriminating_count: u32 = 0;
            let mut h_gap_affected: u32 = 0;
            let mut h_gt_consensus: u32 = 0;
            let mut h_majority: u32 = 0;
            let mut h_confirmed: u32 = 0;
            let mut missing_calls_count: u32 = 0;

            for &pos in &all_snp_positions {
                if gap_set.contains(&pos) {
                    continue;
                }
                total_count += 1;

                if gap_aware {
                    // Gap-Intersect: consider only samples without gap
                    let mut alleles: Vec<Option<u8>> = Vec::new();
                    let mut any_gap = false;
                    for (idx, snp_map) in snp_maps.iter().enumerate() {
                        if sample_gap_sets[idx].contains(&pos) {
                            any_gap = true;
                            continue;
                        }
                        alleles.push(snp_map.get(&pos).copied());
                    }
                    if alleles.len() < 2 {
                        continue;
                    }
                    // Missing call: ≥1 non-gap sample has SNP, ≥1 non-gap sample has no call (None)
                    let has_snp = alleles.iter().any(|a| a.is_some());
                    let has_no_call = alleles.iter().any(|a| a.is_none());
                    if has_snp && has_no_call {
                        missing_calls_count += 1;
                    }
                    let first = alleles[0];
                    let all_same = alleles.iter().all(|a| *a == first);
                    if all_same {
                        if first.is_some() {
                            consensus_count += 1;
                        }
                    } else {
                        discriminating_count += 1;
                        // Classify: priority order gap > gt > majority > confirmed
                        if any_gap {
                            h_gap_affected += 1;
                        } else if gt_is_consensus_at(pos) {
                            h_gt_consensus += 1;
                        } else if is_majority(&alleles) {
                            h_majority += 1;
                        } else {
                            h_confirmed += 1;
                        }
                    }
                } else {
                    // Gap-Union: all samples have data (no gaps)
                    // Missing call: ≥1 sample has SNP, ≥1 sample has no call
                    let has_snp = snp_maps.iter().any(|m| m.contains_key(&pos));
                    let has_no_call = snp_maps.iter().any(|m| !m.contains_key(&pos));
                    if has_snp && has_no_call {
                        missing_calls_count += 1;
                    }
                    let mut all_have = true;
                    let mut first_alt: Option<u8> = None;
                    let mut all_same = true;
                    for snp_map in &snp_maps {
                        if let Some(&alt) = snp_map.get(&pos) {
                            match first_alt {
                                None => first_alt = Some(alt),
                                Some(f) => if alt != f { all_same = false; }
                            }
                        } else {
                            all_have = false;
                            break;
                        }
                    }
                    if all_have && all_same && first_alt.is_some() {
                        consensus_count += 1;
                    } else {
                        discriminating_count += 1;
                        // Classify: no gap_affected possible in Gap-Union
                        let alleles: Vec<Option<u8>> = snp_maps.iter()
                            .map(|m| m.get(&pos).copied())
                            .collect();
                        if gt_is_consensus_at(pos) {
                            h_gt_consensus += 1;
                        } else if is_majority(&alleles) {
                            h_majority += 1;
                        } else {
                            h_confirmed += 1;
                        }
                    }
                }
            }

            GlobalVariant {
                usable_space,
                usable_space_pct,
                total_snps: total_count,
                consensus_snps: consensus_count,
                discriminating_snps: discriminating_count,
                disc_breakdown: DiscBreakdown {
                    gap_affected: h_gap_affected,
                    gt_consensus: h_gt_consensus,
                    majority_rule: h_majority,
                    confirmed: h_confirmed,
                },
                missing_calls: missing_calls_count,
            }
        };

        let stats = GlobalStats {
            strict: compute_variant(&gap_union, false),
            relaxed: compute_variant(&gap_intersection, true),
        };

        serde_json::to_string(&stats).unwrap_or_else(|_| "{}".to_string())
    }

    /// Pairwise stats for GT pipeline (backward compat)
    #[wasm_bindgen]
    pub fn get_pairwise_usable_stats(&self) -> String {
        match &self.ground_truth_pipeline {
            Some(id) => self.get_pairwise_usable_stats_for_pipeline(id),
            None => "{}".to_string(),
        }
    }

    /// Get average pairwise usable stats for a specific pipeline
    /// For each pair (A, B):
    ///   - usable_space = refLength - union of pipeline gap bases for A and B
    ///   - discriminating SNPs not in gaps
    /// Returns averages across all N*(N-1)/2 pairs + per-sample breakdown
    #[wasm_bindgen]
    pub fn get_pairwise_usable_stats_for_pipeline(&self, pipeline_id: &str) -> String {
        #[derive(Serialize)]
        struct PerSamplePairwise {
            sample_id: String,
            sample_label: String,
            avg_usable_space: f64,
            avg_usable_space_pct: f64,
            avg_disc_snps: f64,
        }

        #[derive(Serialize)]
        struct PairwiseUsableStats {
            avg_usable_space: f64,
            avg_usable_space_pct: f64,
            avg_usable_snps: f64,
            min_usable_snps: u32,
            max_usable_snps: u32,
            median_usable_snps: f64,
            num_pairs: usize,
            per_sample: Vec<PerSamplePairwise>,
        }

        let sample_ids: Vec<&String> = self.samples.keys().collect();
        let n = sample_ids.len();
        if n < 2 {
            return serde_json::to_string(&PairwiseUsableStats {
                avg_usable_space: self.ref_len as f64,
                avg_usable_space_pct: 100.0,
                avg_usable_snps: 0.0,
                min_usable_snps: 0,
                max_usable_snps: 0,
                median_usable_snps: 0.0,
                num_pairs: 0,
                per_sample: Vec::new(),
            }).unwrap_or_else(|_| "{}".to_string());
        }

        let gt_id = Some(pipeline_id.to_string());
        let num_pairs = n * (n - 1) / 2;
        let mut total_usable_space: f64 = 0.0;
        let mut total_usable_snps: f64 = 0.0;
        let mut per_pair_disc: Vec<u32> = Vec::with_capacity(num_pairs);
        // Per-sample accumulators: sum of usable_space and disc_snps across all pairs involving sample i
        let mut sample_sum_space: Vec<f64> = vec![0.0; n];
        let mut sample_sum_disc: Vec<f64> = vec![0.0; n];

        // Helper: merge gap regions into non-overlapping sorted list and compute total bases
        fn merge_gaps_total(gaps_a: &[(u32, u32)], gaps_b: &[(u32, u32)]) -> u32 {
            let mut all: Vec<(u32, u32)> = Vec::with_capacity(gaps_a.len() + gaps_b.len());
            all.extend_from_slice(gaps_a);
            all.extend_from_slice(gaps_b);
            all.sort_unstable();
            let mut total = 0u32;
            let mut cur_start = 0u32;
            let mut cur_end = 0u32;
            for &(s, e) in &all {
                if s > cur_end {
                    total += cur_end - cur_start;
                    cur_start = s;
                    cur_end = e;
                } else if e > cur_end {
                    cur_end = e;
                }
            }
            total += cur_end - cur_start;
            total
        }

        // Helper: check if position is in any gap from merged list
        fn in_merged_gaps(pos: u32, gaps: &[(u32, u32)]) -> bool {
            // Binary search for efficiency
            match gaps.binary_search_by(|&(s, _)| s.cmp(&pos)) {
                Ok(_) => true, // pos == start of a gap
                Err(idx) => {
                    // Check if pos is inside the preceding gap
                    if idx > 0 {
                        let (_, end) = gaps[idx - 1];
                        pos < end
                    } else {
                        false
                    }
                }
            }
        }

        // Merge and sort gaps helper
        fn merge_gap_regions(gaps_a: &[(u32, u32)], gaps_b: &[(u32, u32)]) -> Vec<(u32, u32)> {
            let mut all: Vec<(u32, u32)> = Vec::with_capacity(gaps_a.len() + gaps_b.len());
            all.extend_from_slice(gaps_a);
            all.extend_from_slice(gaps_b);
            all.sort_unstable();
            let mut merged: Vec<(u32, u32)> = Vec::new();
            for &(s, e) in &all {
                if let Some(last) = merged.last_mut() {
                    if s <= last.1 {
                        last.1 = last.1.max(e);
                    } else {
                        merged.push((s, e));
                    }
                } else {
                    merged.push((s, e));
                }
            }
            merged
        }

        for i in 0..n {
            for j in (i+1)..n {
                let sample_a = &self.samples[sample_ids[i]];
                let sample_b = &self.samples[sample_ids[j]];

                // Get GT gaps for both samples
                let gaps_a: Vec<(u32, u32)> = gt_id.as_ref()
                    .and_then(|gt| sample_a.pipelines.get(gt))
                    .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                    .unwrap_or_default();
                let gaps_b: Vec<(u32, u32)> = gt_id.as_ref()
                    .and_then(|gt| sample_b.pipelines.get(gt))
                    .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                    .unwrap_or_default();

                // Usable space = refLen - merged GT gaps
                let gap_bases = merge_gaps_total(&gaps_a, &gaps_b);
                let pair_usable_space = (self.ref_len - gap_bases) as f64;
                total_usable_space += pair_usable_space;
                sample_sum_space[i] += pair_usable_space;
                sample_sum_space[j] += pair_usable_space;

                // Count discriminating GT SNPs not in GT gaps
                if let Some(ref gt) = gt_id {
                    let merged_gaps = merge_gap_regions(&gaps_a, &gaps_b);

                    let snps_a: HashMap<u32, u8> = sample_a.pipelines.get(gt)
                        .map(|p| self.build_snp_map(p))
                        .unwrap_or_default();
                    let snps_b: HashMap<u32, u8> = sample_b.pipelines.get(gt)
                        .map(|p| self.build_snp_map(p))
                        .unwrap_or_default();

                    // All GT SNP positions in either sample
                    let mut all_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
                    all_positions.extend(snps_a.keys());
                    all_positions.extend(snps_b.keys());

                    let mut discriminating = 0u32;
                    for &pos in &all_positions {
                        // Skip if in GT gaps
                        if !merged_gaps.is_empty() && in_merged_gaps(pos, &merged_gaps) {
                            continue;
                        }
                        // Discriminating: different between the two samples
                        let alt_a = snps_a.get(&pos);
                        let alt_b = snps_b.get(&pos);
                        if alt_a != alt_b {
                            discriminating += 1;
                        }
                    }

                    per_pair_disc.push(discriminating);
                    total_usable_snps += discriminating as f64;
                    sample_sum_disc[i] += discriminating as f64;
                    sample_sum_disc[j] += discriminating as f64;
                }
            }
        }

        let avg_usable_space = total_usable_space / num_pairs as f64;
        let avg_usable_space_pct = (avg_usable_space / self.ref_len as f64) * 100.0;
        let avg_usable_snps = total_usable_snps / num_pairs as f64;

        per_pair_disc.sort_unstable();
        let min_usable_snps = *per_pair_disc.first().unwrap_or(&0);
        let max_usable_snps = *per_pair_disc.last().unwrap_or(&0);
        let median_usable_snps = if per_pair_disc.is_empty() {
            0.0
        } else {
            let mid = per_pair_disc.len() / 2;
            if per_pair_disc.len() % 2 == 0 {
                (per_pair_disc[mid - 1] as f64 + per_pair_disc[mid] as f64) / 2.0
            } else {
                per_pair_disc[mid] as f64
            }
        };

        // Per-sample averages: each sample is in (n-1) pairs
        let pairs_per_sample = (n - 1) as f64;
        let per_sample: Vec<PerSamplePairwise> = (0..n).map(|i| {
            let avg_space = sample_sum_space[i] / pairs_per_sample;
            PerSamplePairwise {
                sample_id: sample_ids[i].clone(),
                sample_label: self.sample_labels.get(sample_ids[i])
                    .cloned()
                    .unwrap_or_else(|| sample_ids[i].clone()),
                avg_usable_space: avg_space,
                avg_usable_space_pct: (avg_space / self.ref_len as f64) * 100.0,
                avg_disc_snps: sample_sum_disc[i] / pairs_per_sample,
            }
        }).collect();

        let stats = PairwiseUsableStats {
            avg_usable_space,
            avg_usable_space_pct,
            avg_usable_snps,
            min_usable_snps,
            max_usable_snps,
            median_usable_snps,
            num_pairs,
            per_sample,
        };

        serde_json::to_string(&stats).unwrap_or_else(|_| "{}".to_string())
    }


    /// For each VCF pipeline, return GT discriminating SNPs vs pipeline core SNP data.
    /// Returns pre-computed results from the CLI compare command, or falls back to
    /// VCF-based computation if no pre-computed data is available.
    /// Output format: { pipeline_id: { gap_intersect_gt_disc, ..., concordant (nullable) } }
    #[wasm_bindgen]
    pub fn get_gt_disc_vs_pipelines(&self) -> String {
        // If pre-computed data exists, convert to the flat format expected by the HTML
        if let Some(ref results) = self.gt_disc_vs_pipelines {
            #[derive(Serialize)]
            struct GtDiscVsPipeline {
                pl_total_core_snps: u32,
                pl_discriminating_core_snps: u32,

                gap_intersect_gt_disc: u32,
                gap_intersect_same_pos: u32,
                gap_intersect_concordant: Option<u32>,
                gap_intersect_pl_snps_in_gt_gaps: u32,

                gap_union_gt_disc: u32,
                gap_union_same_pos: u32,
                gap_union_concordant: Option<u32>,
                gap_union_pl_snps_in_gt_gaps: u32,

                pairwise_gt_disc_avg: f64,
                pairwise_same_pos_avg: f64,
                pairwise_concordant_avg: Option<f64>,
                pairwise_num_pairs: u32,
            }

            let mut map: HashMap<String, GtDiscVsPipeline> = HashMap::new();
            for r in results {
                map.insert(r.pipeline_id.clone(), GtDiscVsPipeline {
                    pl_total_core_snps: r.pl_total_core_snps,
                    pl_discriminating_core_snps: r.pl_discriminating_core_snps,
                    gap_intersect_gt_disc: r.gap_intersect.gt_disc,
                    gap_intersect_same_pos: r.gap_intersect.same_pos,
                    gap_intersect_concordant: r.gap_intersect.concordant,
                    gap_intersect_pl_snps_in_gt_gaps: r.gap_intersect.pl_snps_in_gt_gaps,

                    gap_union_gt_disc: r.gap_union.gt_disc,
                    gap_union_same_pos: r.gap_union.same_pos,
                    gap_union_concordant: r.gap_union.concordant,
                    gap_union_pl_snps_in_gt_gaps: r.gap_union.pl_snps_in_gt_gaps,

                    pairwise_gt_disc_avg: r.pairwise.gt_disc_avg,
                    pairwise_same_pos_avg: r.pairwise.same_pos_avg,
                    pairwise_concordant_avg: r.pairwise.concordant_avg,
                    pairwise_num_pairs: r.pairwise.num_pairs,
                });
            }
            return serde_json::to_string(&map).unwrap_or_else(|_| "{}".to_string());
        }

        // Fallback: compute from VCF data (legacy behavior for reports without core_snps)
        self.compute_gt_disc_vs_pipelines_from_vcf()
    }

    /// Legacy VCF-based computation of GT disc vs pipelines (fallback when no pre-computed data)
    fn compute_gt_disc_vs_pipelines_from_vcf(&self) -> String {
        #[derive(Serialize)]
        struct GtDiscVsPipeline {
            pl_total_core_snps: u32,
            pl_discriminating_core_snps: u32,

            gap_intersect_gt_disc: u32,
            gap_intersect_same_pos: u32,
            gap_intersect_concordant: Option<u32>,
            gap_intersect_pl_snps_in_gt_gaps: u32,

            gap_union_gt_disc: u32,
            gap_union_same_pos: u32,
            gap_union_concordant: Option<u32>,
            gap_union_pl_snps_in_gt_gaps: u32,

            pairwise_gt_disc_avg: f64,
            pairwise_same_pos_avg: f64,
            pairwise_concordant_avg: Option<f64>,
            pairwise_num_pairs: u32,
        }

        let gt_id = match &self.ground_truth_pipeline {
            Some(id) => id.clone(),
            None => return "{}".to_string(),
        };

        let sample_ids: Vec<&String> = self.samples.keys().collect();
        let n = sample_ids.len();
        if n < 2 {
            return "{}".to_string();
        }

        // Build per-sample GT gap sets
        let mut gt_gap_sets: Vec<std::collections::HashSet<u32>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let mut gaps: std::collections::HashSet<u32> = std::collections::HashSet::new();
            if let Some(gt_data) = sample_data.pipelines.get(&gt_id) {
                for gap in &gt_data.gaps {
                    for pos in gap.start..gap.end {
                        gaps.insert(pos);
                    }
                }
            }
            gt_gap_sets.push(gaps);
        }

        // GT gap union (positions where ANY sample has GT gap)
        let mut gt_gap_union: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for gs in &gt_gap_sets {
            gt_gap_union.extend(gs);
        }

        // GT gap intersection (positions where ALL samples have GT gap)
        let gt_gap_intersection = if gt_gap_sets.len() > 1 {
            let mut isect = gt_gap_sets[0].clone();
            for gs in &gt_gap_sets[1..] {
                isect = isect.intersection(gs).cloned().collect();
            }
            isect
        } else if gt_gap_sets.len() == 1 {
            gt_gap_sets[0].clone()
        } else {
            std::collections::HashSet::new()
        };

        // Build per-sample GT SNP maps
        let mut gt_snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let snps: HashMap<u32, u8> = sample_data.pipelines.get(&gt_id)
                .map(|p| self.build_snp_map(p))
                .unwrap_or_default();
            gt_snp_maps.push(snps);
        }

        // Find all GT SNP positions
        let mut all_gt_snp_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for snp_map in &gt_snp_maps {
            all_gt_snp_positions.extend(snp_map.keys());
        }

        // --- Gap-Union GT discriminating positions ---
        let mut gt_disc_union: Vec<u32> = Vec::new();
        for &pos in &all_gt_snp_positions {
            if gt_gap_union.contains(&pos) {
                continue;
            }
            let alleles: Vec<Option<u8>> = (0..n).map(|idx| gt_snp_maps[idx].get(&pos).copied()).collect();
            let first = alleles[0];
            if alleles.iter().any(|a| *a != first) {
                gt_disc_union.push(pos);
            }
        }

        // --- Gap-Intersect GT discriminating positions ---
        let mut gt_disc_intersect: Vec<u32> = Vec::new();
        for &pos in &all_gt_snp_positions {
            if gt_gap_intersection.contains(&pos) {
                continue;
            }
            let alleles: Vec<Option<u8>> = (0..n)
                .filter(|&idx| !gt_gap_sets[idx].contains(&pos))
                .map(|idx| gt_snp_maps[idx].get(&pos).copied())
                .collect();
            if alleles.len() < 2 {
                continue;
            }
            let first = alleles[0];
            if alleles.iter().any(|a| *a != first) {
                gt_disc_intersect.push(pos);
            }
        }

        let ref_bytes = self.ref_seq.as_bytes();

        // Helper: for a set of GT disc positions, compute same_pos and concordant
        let count_same_concordant = |disc_positions: &[u32],
                                      sample_indices: &[usize],
                                      gt_snp_maps: &[HashMap<u32, u8>],
                                      pl_gap_sets: &[std::collections::HashSet<u32>],
                                      pl_snp_maps: &[HashMap<u32, u8>]| -> (u32, u32) {
            let mut same_pos: u32 = 0;
            let mut concordant: u32 = 0;
            for &pos in disc_positions {
                let pl_has_snp = sample_indices.iter().any(|&idx| pl_snp_maps[idx].contains_key(&pos));
                if !pl_has_snp {
                    continue;
                }
                same_pos += 1;

                let any_pl_gap = sample_indices.iter().any(|&idx| pl_gap_sets[idx].contains(&pos));
                if any_pl_gap {
                    continue;
                }

                let all_match = sample_indices.iter().all(|&idx| {
                    let gt_allele = gt_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    let pl_allele = pl_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    gt_allele == pl_allele
                });
                if all_match {
                    concordant += 1;
                }
            }
            (same_pos, concordant)
        };

        // Helper: count pipeline SNPs that fall in a GT gap set
        let count_pl_snps_in_gt_gaps = |gt_gaps: &std::collections::HashSet<u32>,
                                         pl_snp_maps: &[HashMap<u32, u8>]| -> u32 {
            let mut all_pl_snp_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
            for snp_map in pl_snp_maps {
                all_pl_snp_positions.extend(snp_map.keys());
            }
            all_pl_snp_positions.iter().filter(|pos| gt_gaps.contains(pos)).count() as u32
        };

        let all_indices: Vec<usize> = (0..n).collect();

        let mut result: HashMap<String, GtDiscVsPipeline> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            if *pipeline_id == gt_id {
                continue;
            }

            // Build per-sample pipeline gap sets
            let mut pl_gap_sets: Vec<std::collections::HashSet<u32>> = Vec::new();
            for sample_id in &sample_ids {
                let sample_data = &self.samples[*sample_id];
                let mut gaps: std::collections::HashSet<u32> = std::collections::HashSet::new();
                if let Some(pl_data) = sample_data.pipelines.get(pipeline_id) {
                    for gap in &pl_data.gaps {
                        for pos in gap.start..gap.end {
                            gaps.insert(pos);
                        }
                    }
                }
                pl_gap_sets.push(gaps);
            }

            // Build per-sample pipeline SNP maps
            let mut pl_snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
            let mut all_pl_snp_pos: std::collections::HashSet<u32> = std::collections::HashSet::new();
            for sample_id in &sample_ids {
                let sample_data = &self.samples[*sample_id];
                let snps: HashMap<u32, u8> = sample_data.pipelines.get(pipeline_id)
                    .map(|p| self.build_snp_map(p))
                    .unwrap_or_default();
                all_pl_snp_pos.extend(snps.keys());
                pl_snp_maps.push(snps);
            }
            let pl_total_core_snps = all_pl_snp_pos.len() as u32;

            // Count discriminating positions: at least 2 samples with different alleles
            let pl_discriminating_core_snps = all_pl_snp_pos.iter().filter(|&&pos| {
                let alleles: Vec<Option<u8>> = pl_snp_maps.iter()
                    .map(|m| m.get(&pos).copied())
                    .collect();
                if alleles.len() < 2 { return false; }
                let first = alleles[0];
                alleles.iter().any(|a| *a != first)
            }).count() as u32;

            let (gu_same_pos, gu_concordant) = count_same_concordant(
                &gt_disc_union, &all_indices, &gt_snp_maps, &pl_gap_sets, &pl_snp_maps);
            let gu_pl_in_gaps = count_pl_snps_in_gt_gaps(&gt_gap_union, &pl_snp_maps);

            let mut gi_same_pos: u32 = 0;
            let mut gi_concordant: u32 = 0;
            for &pos in &gt_disc_intersect {
                let active: Vec<usize> = (0..n).filter(|&idx| !gt_gap_sets[idx].contains(&pos)).collect();
                if active.len() < 2 { continue; }

                let pl_has_snp = active.iter().any(|&idx| pl_snp_maps[idx].contains_key(&pos));
                if !pl_has_snp { continue; }
                gi_same_pos += 1;

                let any_pl_gap = active.iter().any(|&idx| pl_gap_sets[idx].contains(&pos));
                if any_pl_gap { continue; }

                let all_match = active.iter().all(|&idx| {
                    let gt_allele = gt_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    let pl_allele = pl_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    gt_allele == pl_allele
                });
                if all_match {
                    gi_concordant += 1;
                }
            }
            let gi_pl_in_gaps = count_pl_snps_in_gt_gaps(&gt_gap_intersection, &pl_snp_maps);

            let mut pw_total_disc: f64 = 0.0;
            let mut pw_total_same_pos: f64 = 0.0;
            let mut pw_total_concordant: f64 = 0.0;
            let mut num_pairs: u32 = 0;

            for i in 0..n {
                for j in (i+1)..n {
                    let pair_gap_union: std::collections::HashSet<u32> = gt_gap_sets[i].union(&gt_gap_sets[j]).cloned().collect();

                    let mut pair_disc: Vec<u32> = Vec::new();
                    for &pos in &all_gt_snp_positions {
                        if pair_gap_union.contains(&pos) { continue; }
                        let a_i = gt_snp_maps[i].get(&pos).copied();
                        let a_j = gt_snp_maps[j].get(&pos).copied();
                        if a_i != a_j {
                            pair_disc.push(pos);
                        }
                    }

                    let pair_indices = vec![i, j];
                    let (p_same, p_conc) = count_same_concordant(
                        &pair_disc, &pair_indices, &gt_snp_maps, &pl_gap_sets, &pl_snp_maps);

                    pw_total_disc += pair_disc.len() as f64;
                    pw_total_same_pos += p_same as f64;
                    pw_total_concordant += p_conc as f64;
                    num_pairs += 1;
                }
            }

            let np = if num_pairs > 0 { num_pairs as f64 } else { 1.0 };

            result.insert(pipeline_id.clone(), GtDiscVsPipeline {
                pl_total_core_snps,
                pl_discriminating_core_snps,
                gap_intersect_gt_disc: gt_disc_intersect.len() as u32,
                gap_intersect_same_pos: gi_same_pos,
                gap_intersect_concordant: Some(gi_concordant),
                gap_intersect_pl_snps_in_gt_gaps: gi_pl_in_gaps,

                gap_union_gt_disc: gt_disc_union.len() as u32,
                gap_union_same_pos: gu_same_pos,
                gap_union_concordant: Some(gu_concordant),
                gap_union_pl_snps_in_gt_gaps: gu_pl_in_gaps,

                pairwise_gt_disc_avg: pw_total_disc / np,
                pairwise_same_pos_avg: pw_total_same_pos / np,
                pairwise_concordant_avg: Some(pw_total_concordant / np),
                pairwise_num_pairs: num_pairs,
            });
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }





    /// Get all SNP positions that match the given filters
    /// filters: comma-separated list of pipeline IDs, or special filters:
    /// - "consensus": positions where all pipelines agree
    /// - "discordant": positions where pipelines disagree
    /// - "exclusive:<pipeline>": positions only in that pipeline
    /// - "gaps:<pipeline>": positions where pipeline has a gap
    /// filter_mode: "and" (all filters must match) or "or" (any filter matches)
    /// sample_mode: "any" (at least one sample) or "all" (all samples)
    #[wasm_bindgen]
    pub fn get_filtered_positions_v2(
        &self,
        samples_json: &str,
        filters: &str,
        filter_mode: &str,
        sample_mode: &str,
    ) -> String {
        let samples: Vec<String> = serde_json::from_str(samples_json).unwrap_or_default();
        let filter_parts: Vec<&str> = filters.split(',').filter(|f| !f.is_empty()).collect();
        let use_or = filter_mode == "or";
        let require_all_samples = sample_mode == "all";

        // Check if we have any gap filters
        let gap_filters: Vec<&str> = filter_parts.iter()
            .filter(|f| f.starts_with("gaps:"))
            .map(|f| &f[5..])
            .collect();

        let mut positions: std::collections::HashSet<u32> = std::collections::HashSet::new();

        // Collect all SNP positions
        for sample in &samples {
            if let Some(sample_data) = self.samples.get(sample) {
                for pipeline_data in sample_data.pipelines.values() {
                    for snp in &pipeline_data.snps {
                        positions.insert(snp.pos);
                    }
                }
            }
        }

        // If gap filters are active, also collect gap positions
        if !gap_filters.is_empty() {
            for sample in &samples {
                if let Some(sample_data) = self.samples.get(sample) {
                    for gap_pipeline in &gap_filters {
                        if let Some(pipeline_data) = sample_data.pipelines.get(*gap_pipeline) {
                            for gap in &pipeline_data.gaps {
                                for pos in gap.start..gap.end.min(gap.start + 1000) {
                                    positions.insert(pos);
                                }
                            }
                        }
                    }
                }
            }
        }

        // If no filters, return all positions
        if filter_parts.is_empty() {
            let mut sorted: Vec<u32> = positions.into_iter().collect();
            sorted.sort();
            return serde_json::to_string(&sorted).unwrap_or_else(|_| "[]".to_string());
        }

        // Extract pipeline filters (those that are not special filters)
        let pipeline_filters: Vec<&str> = filter_parts.iter()
            .filter(|f| {
                !f.starts_with("gaps:") &&
                !f.starts_with("exclusive:") &&
                **f != "consensus" &&
                **f != "discordant"
            })
            .copied()
            .collect();

        // Apply filters
        let filtered: Vec<u32> = positions.into_iter().filter(|&pos| {
            // For each filter, check if it matches
            let filter_results: Vec<bool> = filter_parts.iter().map(|filter| {
                self.check_filter_at_pos(&samples, pos, filter, require_all_samples, &pipeline_filters)
            }).collect();

            // Combine results based on filter mode
            if use_or {
                filter_results.iter().any(|&r| r)
            } else {
                filter_results.iter().all(|&r| r)
            }
        }).collect();

        let mut sorted = filtered;
        sorted.sort();
        serde_json::to_string(&sorted).unwrap_or_else(|_| "[]".to_string())
    }

    /// Check if a single filter matches at a position
    /// pipeline_scope: if not empty, consensus/discordant only consider these pipelines
    fn check_filter_at_pos(&self, samples: &[String], pos: u32, filter: &str, require_all_samples: bool, pipeline_scope: &[&str]) -> bool {
        if filter == "consensus" {
            return self.check_consensus(samples, pos, pipeline_scope);
        } else if filter == "discordant" {
            return self.check_discordant(samples, pos, pipeline_scope);
        } else if filter.starts_with("exclusive:") {
            let target = &filter[10..];
            return self.check_exclusive(samples, pos, target);
        } else if filter.starts_with("gaps:") {
            let target_pipeline = &filter[5..];
            return self.check_gap(samples, pos, target_pipeline, require_all_samples);
        } else {
            // Regular pipeline SNP filter
            return self.check_snp_in_pipeline(samples, pos, filter, require_all_samples);
        }
    }

    /// Check if position has consensus (all pipelines with VCF agree)
    ///
    /// For each sample, ALL pipelines in scope that have VCF data must have called a SNP
    /// at this position, and all calls must agree on the same allele.
    /// pipeline_scope: if not empty, only consider these pipelines; otherwise use all VCF pipelines
    fn check_consensus(&self, samples: &[String], pos: u32, pipeline_scope: &[&str]) -> bool {
        // Get pipelines to check: either scoped or all VCF pipelines
        let vcf_pipelines: Vec<&String> = if pipeline_scope.is_empty() {
            // No scope - use all VCF pipelines
            self.pipeline_ids.iter()
                .filter(|p| {
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        } else {
            // Use only scoped pipelines that have VCF
            self.pipeline_ids.iter()
                .filter(|p| {
                    pipeline_scope.contains(&p.as_str()) &&
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        };

        // Need at least 2 VCF pipelines to check consensus
        if vcf_pipelines.len() < 2 {
            return false;
        }

        // For each sample, check if ALL VCF pipelines have a SNP and they agree
        let ref_bytes = self.ref_seq.as_bytes();
        for sample in samples {
            let mut sample_alts: Vec<char> = Vec::new();
            let mut all_have_snp = true;

            for pipeline_id in &vcf_pipelines {
                if let Some(sample_data) = self.samples.get(sample) {
                    if let Some(pipeline_data) = sample_data.pipelines.get(*pipeline_id) {
                        if pipeline_data.has_vcf {
                            if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                                let ref_base = ref_bytes.get(pos as usize).copied().unwrap_or(b'N');
                                if snp.alt_allele == ref_base {
                                    all_have_snp = false;
                                    break;
                                }
                                sample_alts.push(snp.alt_allele as char);
                            } else {
                                all_have_snp = false;
                                break;
                            }
                        }
                    }
                }
            }

            // If all VCF pipelines have SNP for this sample and they agree, it's consensus
            if all_have_snp && sample_alts.len() >= 2 {
                let first = sample_alts[0];
                if sample_alts.iter().all(|&a| a == first) {
                    return true;  // Found consensus for at least one sample
                }
            }
        }

        false
    }

    /// Check if position has discordance (pipelines disagree)
    ///
    /// For at least one sample, multiple pipelines in scope with VCF must have called
    /// different SNPs at this position.
    /// pipeline_scope: if not empty, only consider these pipelines; otherwise use all VCF pipelines
    fn check_discordant(&self, samples: &[String], pos: u32, pipeline_scope: &[&str]) -> bool {
        // Get pipelines to check: either scoped or all VCF pipelines
        let vcf_pipelines: Vec<&String> = if pipeline_scope.is_empty() {
            self.pipeline_ids.iter()
                .filter(|p| {
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        } else {
            self.pipeline_ids.iter()
                .filter(|p| {
                    pipeline_scope.contains(&p.as_str()) &&
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        };

        if vcf_pipelines.len() < 2 {
            return false;
        }

        let ref_bytes = self.ref_seq.as_bytes();
        // For each sample, check if pipelines disagree
        for sample in samples {
            let mut sample_alts: Vec<char> = Vec::new();

            for pipeline_id in &vcf_pipelines {
                if let Some(sample_data) = self.samples.get(sample) {
                    if let Some(pipeline_data) = sample_data.pipelines.get(*pipeline_id) {
                        if pipeline_data.has_vcf {
                            if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                                let ref_base = ref_bytes.get(pos as usize).copied().unwrap_or(b'N');
                                if snp.alt_allele != ref_base {
                                    sample_alts.push(snp.alt_allele as char);
                                }
                            }
                        }
                    }
                }
            }

            // If at least 2 pipelines have SNPs for this sample and they disagree
            if sample_alts.len() >= 2 {
                let first = sample_alts[0];
                if !sample_alts.iter().all(|&a| a == first) {
                    return true;  // Found discordance for at least one sample
                }
            }
        }

        false
    }

    /// Check if position is exclusive to one pipeline
    fn check_exclusive(&self, samples: &[String], pos: u32, target: &str) -> bool {
        let mut found_in_target = false;
        let mut found_in_other = false;

        for pipeline_id in &self.pipeline_ids {
            for sample in samples {
                if let Some(sample_data) = self.samples.get(sample) {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        if Self::find_snp(&pipeline_data.snps, pos).is_some() {
                            if pipeline_id == target {
                                found_in_target = true;
                            } else {
                                found_in_other = true;
                            }
                        }
                    }
                }
            }
        }

        found_in_target && !found_in_other
    }

    /// Check if position is in a gap for a pipeline
    fn check_gap(&self, samples: &[String], pos: u32, pipeline: &str, require_all: bool) -> bool {
        if require_all {
            // All samples must have gap
            samples.iter().all(|sample| self.is_gap(sample, pipeline, pos))
        } else {
            // At least one sample has gap
            samples.iter().any(|sample| self.is_gap(sample, pipeline, pos))
        }
    }

    /// Check if position has SNP in a specific pipeline
    fn check_snp_in_pipeline(&self, samples: &[String], pos: u32, pipeline: &str, require_all: bool) -> bool {
        let sample_results: Vec<bool> = samples.iter().map(|sample| {
            self.samples.get(sample)
                .and_then(|s| s.pipelines.get(pipeline))
                .map(|p| Self::find_snp(&p.snps, pos).is_some())
                .unwrap_or(false)
        }).collect();

        if require_all {
            sample_results.iter().all(|&r| r)
        } else {
            sample_results.iter().any(|&r| r)
        }
    }

    /// Render filtered view (compact, only SNP positions)
    #[wasm_bindgen]
    pub fn render_filtered(&self, samples_json: &str, positions_json: &str, offset: u32, limit: u32) -> String {
        let samples: Vec<String> = serde_json::from_str(samples_json).unwrap_or_default();
        let positions: Vec<u32> = serde_json::from_str(positions_json).unwrap_or_default();

        let start = offset as usize;
        let end = (offset + limit) as usize;
        let visible: Vec<u32> = positions.iter()
            .skip(start)
            .take(end - start)
            .copied()
            .collect();

        if visible.is_empty() {
            return "<div class=\"block\"><p style=\"color:#888;padding:20px;\">No positions match this filter.</p></div>".to_string();
        }

        let mut html = String::with_capacity(visible.len() * samples.len() * 80);
        html.push_str("<div class=\"block compact\">");

        // Position markers - minimal width, full position in tooltip
        html.push_str("<div class=\"row\"><span class=\"lbl\">Pos</span><span class=\"ref\">");
        for &pos in &visible {
            html.push_str(&format!("<span class=\"pos-num\" data-pos=\"{}\">|</span>", pos));
        }
        html.push_str("</span></div>");

        // Reference row
        html.push_str("<div class=\"row\"><span class=\"lbl\">REF</span><span class=\"ref\">");
        for &pos in &visible {
            let nuc = self.get_ref_nuc(pos - 1);
            html.push_str(&format!("<span class=\"nuc\" data-pos=\"{}\">{}</span>", pos, nuc));
        }
        html.push_str("</span></div>");

        // Sample rows
        for sample in &samples {
            let sample_label = self.get_sample_label(sample);

            // Consensus row
            html.push_str(&format!("<div class=\"row\"><span class=\"lbl\">{}</span><span class=\"sample\">", sample_label));
            for &pos in &visible {
                let idx = pos - 1;

                // Check gaps
                let in_gap = self.pipeline_ids.iter().any(|p| self.is_gap(sample, p, pos));

                if in_gap {
                    html.push_str(&format!("<span class=\"gap\" data-pos=\"{}\">-</span>", pos));
                } else {
                    let alts: Vec<char> = self.pipeline_ids.iter()
                        .filter_map(|p| {
                            let alt = self.get_snp_alt(sample, p, pos);
                            if !alt.is_empty() { alt.chars().next() } else { None }
                        })
                        .collect();

                    if alts.is_empty() {
                        html.push_str(&format!("<span class=\"nuc\" data-pos=\"{}\">{}</span>", pos, self.get_ref_nuc(idx)));
                    } else if alts.len() == 1 {
                        html.push_str(&format!("<span class=\"snp-uncertain\" data-pos=\"{}\">{}</span>", pos, alts[0]));
                    } else if alts.iter().all(|&a| a == alts[0]) {
                        html.push_str(&format!("<span class=\"snp-consensus\" data-pos=\"{}\">{}</span>", pos, alts[0]));
                    } else {
                        html.push_str(&format!("<span class=\"snp-discord\" data-pos=\"{}\">{}</span>", pos, self.get_ref_nuc(idx)));
                    }
                }
            }
            html.push_str("</span></div>");

            // Pipeline-specific rows - shows VCF calls only
            // Skip ground truth pipeline (it's used for the sample row above)
            for pipeline_id in &self.pipeline_ids {
                // Skip ground truth pipeline - its data is shown in the sample row
                if let Some(ref gt) = self.ground_truth_pipeline {
                    if pipeline_id == gt {
                        continue;
                    }
                }

                let pipeline_label = self.get_pipeline_label(pipeline_id);
                html.push_str(&format!("<div class=\"row\"><span class=\"lbl sub\">{}</span><span class=\"sample\">", pipeline_label));

                for &pos in &visible {
                    let alt = self.get_snp_alt(sample, pipeline_id, pos);

                    if !alt.is_empty() {
                        html.push_str(&format!("<span class=\"snp-pipeline\" data-pos=\"{}\">{}</span>", pos, alt));
                    } else if self.is_gap(sample, pipeline_id, pos) {
                        html.push_str(&format!("<span class=\"gap\" data-pos=\"{}\">-</span>", pos));
                    } else {
                        html.push_str(&format!("<span class=\"dim\" data-pos=\"{}\">.</span>", pos));
                    }
                }
                html.push_str("</span></div>");
            }
        }

        html.push_str("</div>");
        html
    }

    // Internal helper: binary search for position in gaps
    fn pos_in_gaps(gaps: &[GapRegion], pos: u32) -> bool {
        let idx = gaps.partition_point(|g| g.end <= pos);
        if idx < gaps.len() {
            let gap = &gaps[idx];
            pos >= gap.start && pos < gap.end
        } else {
            false
        }
    }

    // Internal helper: binary search for SNP at position
    fn find_snp(snps: &[Snp], pos: u32) -> Option<&Snp> {
        snps.binary_search_by_key(&pos, |s| s.pos)
            .ok()
            .map(|idx| &snps[idx])
    }

}

/// Initialize panic hook for better error messages
#[wasm_bindgen(start)]
pub fn init() {
    console_error_panic_hook::set_once();
}
