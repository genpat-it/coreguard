//! CoreGuard WASM module for fast SNP comparison visualization
//!
//! This module loads JSON reports generated by `coreguard compare` and provides
//! fast querying and rendering for the browser-based viewer.

use wasm_bindgen::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// A gap region [start, end) - 1-based positions
#[derive(Clone, Debug)]
struct GapRegion {
    start: u32,
    end: u32,
}

/// SNP data at a position
#[derive(Clone, Debug)]
struct Snp {
    pos: u32,
    alt_allele: u8,  // ASCII char code
}

/// Pipeline data with gaps and SNPs stored in sorted vectors for binary search
#[derive(Default)]
struct PipelineData {
    gaps: Vec<GapRegion>,
    snps: Vec<Snp>,
    has_vcf: bool,
    has_bam: bool,
    vcf_path: Option<String>,
    bam_path: Option<String>,
}

/// Sample data containing data for each pipeline
#[derive(Default)]
struct SampleData {
    pipelines: HashMap<String, PipelineData>,
}

/// Report schema matching the JSON from `coreguard compare`
#[derive(Debug, Deserialize, Serialize)]
struct JsonReport {
    #[serde(rename = "_version")]
    version: String,
    reference: JsonReference,
    samples: HashMap<String, JsonSampleInfo>,
    pipelines: HashMap<String, JsonPipelineInfo>,
    /// Data is optional - v2 reports may not have it (KPIs are pre-computed)
    #[serde(default)]
    data: HashMap<String, HashMap<String, JsonPipelineData>>,
    summary: JsonSummary,
    /// Description (markdown content)
    #[serde(default)]
    description: Option<String>,
    /// Raw YAML configuration
    #[serde(default)]
    config_yaml: Option<String>,
    /// Pre-computed distance matrices from pipelines
    #[serde(default)]
    pipeline_distance_matrices: HashMap<String, JsonPipelineDistanceMatrix>,
    /// Pre-computed GT disc vs pipeline results
    #[serde(default)]
    gt_disc_vs_pipelines: Option<Vec<JsonGtDiscVsPipelineResult>>,
    /// Pre-computed per-pipeline KPIs (v2 format)
    #[serde(default)]
    kpis: Option<JsonPreComputedKpis>,
    /// Pre-computed per-pipeline statistics (v2 format)
    #[serde(default)]
    pipeline_stats: Option<HashMap<String, JsonPipelineStats>>,
}

// ===== Pre-computed stats structs (v2 format) =====

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPreComputedKpis {
    pipelines: HashMap<String, JsonPipelineKpi>,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPipelineKpi {
    total_snps: u32,
    total_gap_positions: u32,
    core_snps: u32,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPipelineStats {
    global: JsonGlobalPipelineStats,
    pairwise: JsonPairwisePipelineStats,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonGlobalPipelineStats {
    ref_length: u32,
    gap_intersect_count: u32,
    gap_union_count: u32,
    usable_intersect: u32,
    usable_union: u32,
    total_snps_intersect: u32,
    total_snps_union: u32,
    consensus_snps_intersect: u32,
    consensus_snps_union: u32,
    disc_snps_intersect: u32,
    disc_snps_union: u32,
    missing_vcf_intersect: u32,
    missing_vcf_union: u32,
    disc_breakdown: Option<JsonDiscBreakdown>,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonDiscBreakdown {
    gap_affected: u32,
    gt_consensus: u32,
    majority_rule: u32,
    confirmed: u32,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPairwisePipelineStats {
    num_pairs: u32,
    disc_snps_min: u32,
    disc_snps_median: f64,
    disc_snps_max: u32,
    disc_snps_avg: f64,
    usable_space_avg: f64,
    per_sample: HashMap<String, JsonSamplePairwiseStats>,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonSamplePairwiseStats {
    avg_usable_space: f64,
    avg_disc_snps: f64,
    #[serde(default)]
    pairs: HashMap<String, JsonPairDetail>,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPairDetail {
    usable_space: u32,
    disc_snps: u32,
}

/// Pre-computed GT disc vs pipeline result (from CLI compare)
#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonGtDiscVsPipelineResult {
    pipeline_id: String,
    #[serde(default)]
    pl_total_core_snps: u32,
    #[serde(default)]
    pl_discriminating_core_snps: u32,
    gap_intersect: JsonGapStrategyResult,
    gap_union: JsonGapStrategyResult,
    pairwise: JsonPairwiseGtDiscResult,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonGapStrategyResult {
    gt_disc: u32,
    same_pos: u32,
    concordant: Option<u32>,
    pl_snps_in_gt_gaps: u32,
    #[serde(default)]
    position_details: Option<Vec<JsonPositionDetail>>,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPositionDetail {
    pos: usize,
    #[serde(rename = "ref")]
    ref_allele: String,
    gt: HashMap<String, String>,
    pl: HashMap<String, String>,
    status: String,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPairwiseGtDiscResult {
    gt_disc_avg: f64,
    same_pos_avg: f64,
    concordant_avg: Option<f64>,
    num_pairs: u32,
}

/// Pre-computed distance matrix from a pipeline
#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPipelineDistanceMatrix {
    samples: Vec<String>,
    matrix: Vec<Vec<i64>>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonReference {
    name: String,
    label: Option<String>,
    length: usize,
    sequence: String,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonSampleInfo {
    label: Option<String>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonPipelineInfo {
    label: Option<String>,
    command: Option<String>,
    has_vcf: bool,
    has_bam: bool,
    #[serde(default)]
    ground_truth: bool,
    #[serde(default)]
    from_bam_pileup: bool,
}

#[derive(Debug, Deserialize, Serialize, Default)]
struct JsonPipelineData {
    #[serde(default)]
    gaps: Vec<[usize; 2]>,
    #[serde(default)]
    snps: Vec<JsonSnp>,
    #[serde(default)]
    vcf_path: Option<String>,
    #[serde(default)]
    bam_path: Option<String>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonSnp {
    pos: usize,
    #[serde(rename = "ref")]
    ref_allele: String,
    alt: String,
    qual: f64,
    dp: usize,
}

#[derive(Debug, Deserialize, Serialize)]
#[allow(dead_code)]
struct JsonSummary {
    total_samples: usize,
    total_pipelines: usize,
    generated_at: String,
    coreguard_version: String,
    #[serde(default)]
    warnings: Vec<String>,
    #[serde(default)]
    pileup_options: Option<JsonPileupOptions>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct JsonPileupOptions {
    min_depth: usize,
    min_qual: f64,
    min_consensus: f64,
    include_indels: bool,
}

/// Main data store - holds all samples and pipeline data
#[wasm_bindgen]
pub struct GenomeData {
    samples: HashMap<String, SampleData>,
    sample_labels: HashMap<String, String>,
    pipeline_ids: Vec<String>,  // Ordered list of pipelines
    pipeline_labels: HashMap<String, String>,
    pipeline_commands: HashMap<String, String>,
    /// Pipelines where SNPs come from BAM pileup (no variant calling)
    pipelines_from_bam_pileup: std::collections::HashSet<String>,
    /// Ground truth pipeline ID (if any) - used as baseline for comparison
    ground_truth_pipeline: Option<String>,
    ref_seq: String,
    ref_name: String,
    ref_label: Option<String>,
    ref_len: u32,
    report_version: String,
    generated_at: String,
    warnings: Vec<String>,
    /// Pileup options
    pileup_options: Option<JsonPileupOptions>,
    /// Description (markdown content)
    description: Option<String>,
    /// Raw YAML configuration
    config_yaml: Option<String>,
    /// Pre-computed distance matrices from pipelines
    pipeline_distance_matrices: HashMap<String, JsonPipelineDistanceMatrix>,
    /// Pre-computed GT disc vs pipeline results
    gt_disc_vs_pipelines: Option<Vec<JsonGtDiscVsPipelineResult>>,
    /// Pre-computed KPIs (v2 format)
    pre_kpis: Option<JsonPreComputedKpis>,
    /// Pre-computed per-pipeline stats (v2 format)
    pre_pipeline_stats: Option<HashMap<String, JsonPipelineStats>>,
}

#[wasm_bindgen]
impl GenomeData {
    /// Create a new empty GenomeData
    #[wasm_bindgen(constructor)]
    pub fn new() -> GenomeData {
        GenomeData {
            samples: HashMap::new(),
            sample_labels: HashMap::new(),
            pipeline_ids: Vec::new(),
            pipeline_labels: HashMap::new(),
            pipeline_commands: HashMap::new(),
            pipelines_from_bam_pileup: std::collections::HashSet::new(),
            ground_truth_pipeline: None,
            ref_seq: String::new(),
            ref_name: String::new(),
            ref_label: None,
            ref_len: 0,
            report_version: String::new(),
            generated_at: String::new(),
            warnings: Vec::new(),
            pileup_options: None,
            description: None,
            config_yaml: None,
            pipeline_distance_matrices: HashMap::new(),
            gt_disc_vs_pipelines: None,
            pre_kpis: None,
            pre_pipeline_stats: None,
        }
    }

    /// Load data from JSON report (the main entry point)
    #[wasm_bindgen]
    pub fn load_json(&mut self, json: &str) -> Result<(), JsValue> {
        let report: JsonReport = serde_json::from_str(json)
            .map_err(|e| JsValue::from_str(&format!("JSON parse error: {}", e)))?;

        self.load_report(report)
    }

    /// Load data from binary (bincode) report - faster than JSON
    #[wasm_bindgen]
    pub fn load_binary(&mut self, data: &[u8]) -> Result<(), JsValue> {
        let report: JsonReport = bincode::deserialize(data)
            .map_err(|e| JsValue::from_str(&format!("Bincode parse error: {}", e)))?;

        self.load_report(report)
    }

    /// Common logic for loading a parsed report (used by both load_json and load_binary)
    fn load_report(&mut self, report: JsonReport) -> Result<(), JsValue> {
        let t0 = js_sys::Date::now();

        // Clear existing data
        self.samples.clear();
        self.sample_labels.clear();
        self.pipeline_ids.clear();
        self.pipeline_labels.clear();
        self.pipeline_commands.clear();
        self.pipelines_from_bam_pileup.clear();
        self.ground_truth_pipeline = None;

        // Load reference
        self.ref_seq = report.reference.sequence;
        self.ref_name = report.reference.name;
        self.ref_label = report.reference.label;
        self.ref_len = report.reference.length as u32;
        self.report_version = report.version;
        self.generated_at = report.summary.generated_at;
        self.warnings = report.summary.warnings;
        self.pileup_options = report.summary.pileup_options;
        self.description = report.description;
        self.config_yaml = report.config_yaml;
        self.pipeline_distance_matrices = report.pipeline_distance_matrices;
        self.gt_disc_vs_pipelines = report.gt_disc_vs_pipelines;
        self.pre_kpis = report.kpis;
        self.pre_pipeline_stats = report.pipeline_stats;

        // Load sample labels
        for (id, info) in &report.samples {
            if let Some(label) = &info.label {
                self.sample_labels.insert(id.clone(), label.clone());
            }
        }

        // Detect ground truth pipeline from JSON
        for (id, info) in &report.pipelines {
            if info.ground_truth {
                self.ground_truth_pipeline = Some(id.clone());
                break;
            }
        }

        // Load pipeline metadata (ground truth first, then alphabetical)
        let mut pipeline_ids: Vec<_> = report.pipelines.keys().cloned().collect();
        let gt_id = self.ground_truth_pipeline.clone();
        pipeline_ids.sort_by(|a, b| {
            // Ground truth pipeline always first
            match (&gt_id, a.as_str(), b.as_str()) {
                (Some(gt), a_str, _) if a_str == gt => std::cmp::Ordering::Less,
                (Some(gt), _, b_str) if b_str == gt => std::cmp::Ordering::Greater,
                _ => a.cmp(b),
            }
        });
        for id in &pipeline_ids {
            if let Some(info) = report.pipelines.get(id) {
                if let Some(label) = &info.label {
                    self.pipeline_labels.insert(id.clone(), label.clone());
                }
                if let Some(command) = &info.command {
                    self.pipeline_commands.insert(id.clone(), command.clone());
                }
                if info.from_bam_pileup {
                    self.pipelines_from_bam_pileup.insert(id.clone());
                }
            }
        }
        self.pipeline_ids = pipeline_ids;

        let t1 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Metadata loaded: {}ms", t1 - t0).into());

        // Load data for each sample
        for (sample_id, sample_pipelines) in &report.data {
            let mut sample_data = SampleData::default();

            for (pipeline_id, json_data) in sample_pipelines {
                let mut pipeline_data = PipelineData::default();

                // Load gaps
                for gap in &json_data.gaps {
                    pipeline_data.gaps.push(GapRegion {
                        start: gap[0] as u32,
                        end: gap[1] as u32,
                    });
                }

                // Load SNPs
                for snp in &json_data.snps {
                    let alt_char = snp.alt.chars().next().unwrap_or('N') as u8;
                    pipeline_data.snps.push(Snp {
                        pos: snp.pos as u32,
                        alt_allele: alt_char,
                    });
                }

                // Store pipeline info
                if let Some(info) = report.pipelines.get(pipeline_id) {
                    pipeline_data.has_vcf = info.has_vcf;
                    pipeline_data.has_bam = info.has_bam;
                }

                // Store file paths for reproducibility
                pipeline_data.vcf_path = json_data.vcf_path.clone();
                pipeline_data.bam_path = json_data.bam_path.clone();

                sample_data.pipelines.insert(pipeline_id.clone(), pipeline_data);
            }

            self.samples.insert(sample_id.clone(), sample_data);
        }

        let t2 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Data loaded: {}ms", t2 - t1).into());

        // Finalize (sort for binary search)
        self.finalize();

        let t3 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Finalized: {}ms", t3 - t2).into());

        web_sys::console::log_1(&format!("TOTAL: {}ms", js_sys::Date::now() - t0).into());

        web_sys::console::log_1(&format!(
            "Loaded report v{}: {} samples, {} pipelines, {} bp reference",
            self.report_version,
            self.samples.len(),
            self.pipeline_ids.len(),
            self.ref_len,
        ).into());

        Ok(())
    }

    /// Sort all data for binary search (called after loading)
    fn finalize(&mut self) {
        for sample_data in self.samples.values_mut() {
            for pipeline_data in sample_data.pipelines.values_mut() {
                pipeline_data.gaps.sort_by_key(|g| g.start);
                pipeline_data.snps.sort_by_key(|s| s.pos);
            }
        }
    }

    /// Get reference length
    #[wasm_bindgen]
    pub fn get_ref_length(&self) -> u32 {
        self.ref_len
    }

    /// Get reference name
    #[wasm_bindgen]
    pub fn get_ref_name(&self) -> String {
        self.ref_label.clone().unwrap_or_else(|| self.ref_name.clone())
    }

    /// Get all sample IDs as JSON array
    #[wasm_bindgen]
    pub fn get_sample_ids(&self) -> String {
        let mut ids: Vec<_> = self.samples.keys().cloned().collect();
        ids.sort();
        serde_json::to_string(&ids).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get display label for a sample
    #[wasm_bindgen]
    pub fn get_sample_label(&self, sample_id: &str) -> String {
        self.sample_labels.get(sample_id)
            .cloned()
            .unwrap_or_else(|| sample_id.to_string())
    }

    /// Get all pipeline IDs as JSON array
    #[wasm_bindgen]
    pub fn get_pipeline_ids(&self) -> String {
        serde_json::to_string(&self.pipeline_ids).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get display label for a pipeline
    #[wasm_bindgen]
    pub fn get_pipeline_label(&self, pipeline_id: &str) -> String {
        self.pipeline_labels.get(pipeline_id)
            .cloned()
            .unwrap_or_else(|| pipeline_id.to_string())
    }

    /// Get command for a pipeline (if any)
    #[wasm_bindgen]
    pub fn get_pipeline_command(&self, pipeline_id: &str) -> Option<String> {
        self.pipeline_commands.get(pipeline_id).cloned()
    }

    /// Get ground truth pipeline ID (if any)
    #[wasm_bindgen]
    pub fn get_ground_truth_pipeline(&self) -> Option<String> {
        self.ground_truth_pipeline.clone()
    }

    /// Check if a pipeline is the ground truth
    #[wasm_bindgen]
    pub fn is_ground_truth(&self, pipeline_id: &str) -> bool {
        self.ground_truth_pipeline.as_ref().map(|gt| gt == pipeline_id).unwrap_or(false)
    }

    /// Check if a pipeline's SNPs come from BAM pileup (no variant calling)
    #[wasm_bindgen]
    pub fn is_from_bam_pileup(&self, pipeline_id: &str) -> bool {
        self.pipelines_from_bam_pileup.contains(pipeline_id)
    }

    /// Get pipelines that have VCF data (used for consensus/discordant)
    #[wasm_bindgen]
    pub fn get_vcf_pipelines(&self) -> String {
        let vcf_pipelines: Vec<&String> = self.pipeline_ids.iter()
            .filter(|p| {
                self.samples.values().any(|sd| {
                    sd.pipelines.get(*p)
                        .map(|pd| pd.has_vcf)
                        .unwrap_or(false)
                })
            })
            .collect();
        serde_json::to_string(&vcf_pipelines).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get report generation timestamp
    #[wasm_bindgen]
    pub fn get_generated_at(&self) -> String {
        self.generated_at.clone()
    }

    /// Get warnings as JSON array
    #[wasm_bindgen]
    pub fn get_warnings(&self) -> String {
        serde_json::to_string(&self.warnings).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get pileup options as JSON
    #[wasm_bindgen]
    pub fn get_pileup_options(&self) -> String {
        match &self.pileup_options {
            Some(opts) => serde_json::to_string(opts).unwrap_or_else(|_| "null".to_string()),
            None => "null".to_string(),
        }
    }

    /// Get report description (markdown content)
    /// Returns: description string or null if not available
    #[wasm_bindgen]
    pub fn get_description(&self) -> String {
        match &self.description {
            Some(desc) => desc.clone(),
            None => "".to_string(),
        }
    }

    /// Get raw YAML configuration
    #[wasm_bindgen]
    pub fn get_config_yaml(&self) -> String {
        match &self.config_yaml {
            Some(yaml) => yaml.clone(),
            None => "".to_string(),
        }
    }

    /// Get pre-computed distance matrices from pipelines
    /// Returns: JSON object { pipeline_id: { samples: [...], matrix: [[...], ...] } }
    #[wasm_bindgen]
    pub fn get_pipeline_distance_matrices(&self) -> String {
        if self.pipeline_distance_matrices.is_empty() {
            "{}".to_string()
        } else {
            serde_json::to_string(&self.pipeline_distance_matrices)
                .unwrap_or_else(|_| "{}".to_string())
        }
    }

    /// Build a SNP map for a sample/pipeline, filtering out SNPs where alt == genomic reference.
    /// These bogus SNPs arise from BAM pileup when the local alignment reference differs from
    /// the FASTA reference. Returns HashMap<position, alt_allele>.
    fn build_snp_map(&self, pipeline_data: &PipelineData) -> HashMap<u32, u8> {
        let ref_bytes = self.ref_seq.as_bytes();
        pipeline_data.snps.iter()
            .filter(|s| {
                let pos = s.pos as usize;
                // Keep SNP only if alt != genomic reference at this position
                pos < ref_bytes.len() && s.alt_allele != ref_bytes[pos]
            })
            .map(|s| (s.pos, s.alt_allele))
            .collect()
    }

    /// Get KPI summary as JSON
    #[wasm_bindgen]
    pub fn get_kpis(&self) -> String {
        // If pre-computed KPIs are available (v2 format), return them
        if let Some(ref pre) = self.pre_kpis {
            #[derive(Serialize)]
            struct Kpis {
                snps: HashMap<String, u32>,
                gaps: HashMap<String, u32>,
                core_snps: HashMap<String, u32>,
                consensus_snps: HashMap<String, u32>,
                gt_snps_missing: HashMap<String, u32>,
                gt_snps_called: HashMap<String, u32>,
                gt_total_snps: u32,
                core_gt_missing: HashMap<String, u32>,
                core_gt_total: u32,
                consensus_gt_missing: HashMap<String, u32>,
                consensus_gt_total: u32,
                snps_in_gt_gaps_total: HashMap<String, u32>,
                snps_in_gt_gaps_core: HashMap<String, u32>,
                snps_in_gt_gaps_consensus: HashMap<String, u32>,
                samples: usize,
                pipelines: usize,
                ref_length: u32,
            }

            let mut snps = HashMap::new();
            let mut gaps = HashMap::new();
            let mut core_snps_map = HashMap::new();
            let mut consensus_snps = HashMap::new();

            for (pid, kpi) in &pre.pipelines {
                snps.insert(pid.clone(), kpi.total_snps);
                gaps.insert(pid.clone(), kpi.total_gap_positions);
                core_snps_map.insert(pid.clone(), kpi.core_snps);
                // Consensus from pre-computed stats if available
                if let Some(ref stats) = self.pre_pipeline_stats {
                    if let Some(ps) = stats.get(pid) {
                        consensus_snps.insert(pid.clone(), ps.global.consensus_snps_union);
                    }
                }
            }

            let kpis = Kpis {
                snps,
                gaps,
                core_snps: core_snps_map,
                consensus_snps,
                gt_snps_missing: HashMap::new(),
                gt_snps_called: HashMap::new(),
                gt_total_snps: 0,
                core_gt_missing: HashMap::new(),
                core_gt_total: 0,
                consensus_gt_missing: HashMap::new(),
                consensus_gt_total: 0,
                snps_in_gt_gaps_total: HashMap::new(),
                snps_in_gt_gaps_core: HashMap::new(),
                snps_in_gt_gaps_consensus: HashMap::new(),
                samples: if self.samples.is_empty() { self.sample_labels.len() } else { self.samples.len() },
                pipelines: self.pipeline_ids.len(),
                ref_length: self.ref_len,
            };

            return serde_json::to_string(&kpis).unwrap_or_else(|_| "{}".to_string());
        }

        // Fallback: compute from raw data (v1 format)
        let ref_bytes = self.ref_seq.as_bytes();
        let mut total_snps: HashMap<String, u32> = HashMap::new();
        let mut total_gaps: HashMap<String, u32> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut snp_count = 0u32;
            let mut gap_bases = 0u32;

            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    snp_count += pipeline_data.snps.iter()
                        .filter(|s| {
                            let pos = s.pos as usize;
                            pos < ref_bytes.len() && s.alt_allele != ref_bytes[pos]
                        })
                        .count() as u32;
                    gap_bases += pipeline_data.gaps.iter()
                        .map(|g| g.end - g.start)
                        .sum::<u32>();
                }
            }

            total_snps.insert(pipeline_id.clone(), snp_count);
            total_gaps.insert(pipeline_id.clone(), gap_bases);
        }

        // Calculate core SNPs per pipeline (positions present in ALL samples)
        // Store both counts and position sets for GT comparison
        let mut core_snps: HashMap<String, u32> = HashMap::new();
        let mut core_positions: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut sample_positions: Vec<std::collections::HashSet<u32>> = Vec::new();

            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    let positions: std::collections::HashSet<u32> = pipeline_data.snps.iter()
                        .map(|s| s.pos)
                        .collect();
                    sample_positions.push(positions);
                }
            }

            // Intersection of all samples = core SNPs
            let core_set = if sample_positions.len() > 1 {
                let mut core = sample_positions[0].clone();
                for positions in &sample_positions[1..] {
                    core = core.intersection(positions).cloned().collect();
                }
                core
            } else if sample_positions.len() == 1 {
                sample_positions[0].clone()
            } else {
                std::collections::HashSet::new()
            };

            core_snps.insert(pipeline_id.clone(), core_set.len() as u32);
            core_positions.insert(pipeline_id.clone(), core_set);
        }

        // Calculate consensus SNPs per pipeline
        // Consensus = positions where ALL samples have the SAME alt allele
        let mut consensus_snps: HashMap<String, u32> = HashMap::new();
        let mut consensus_positions: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            // For each position in core, check if all samples have the same alt
            let core_pos = core_positions.get(pipeline_id).cloned().unwrap_or_default();
            let mut consensus_set: std::collections::HashSet<u32> = std::collections::HashSet::new();

            for &pos in &core_pos {
                // Get alt allele for each sample at this position
                let mut alts: Vec<u8> = Vec::new();
                let mut all_have_snp = true;

                let ref_base = ref_bytes.get(pos as usize).copied().unwrap_or(b'N');
                for sample_data in self.samples.values() {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                            if snp.alt_allele == ref_base {
                                // alt == genomic ref: not a real SNP
                                all_have_snp = false;
                                break;
                            }
                            alts.push(snp.alt_allele);
                        } else {
                            all_have_snp = false;
                            break;
                        }
                    } else {
                        all_have_snp = false;
                        break;
                    }
                }

                // Check if all samples have the same alt
                if all_have_snp && !alts.is_empty() && alts.iter().all(|&a| a == alts[0]) {
                    consensus_set.insert(pos);
                }
            }

            consensus_snps.insert(pipeline_id.clone(), consensus_set.len() as u32);
            consensus_positions.insert(pipeline_id.clone(), consensus_set);
        }

        // Calculate GT SNPs missing per pipeline
        // For each pipeline: sum across samples of (GT SNPs not called by pipeline)
        let mut gt_snps_missing: HashMap<String, u32> = HashMap::new();
        let mut gt_snps_called: HashMap<String, u32> = HashMap::new();
        let mut gt_total_snps: u32 = 0;

        // Core GT missing and Consensus GT missing
        let mut core_gt_missing: HashMap<String, u32> = HashMap::new();
        let mut core_gt_total: u32 = 0;
        let mut consensus_gt_missing: HashMap<String, u32> = HashMap::new();
        let mut consensus_gt_total: u32 = 0;

        if let Some(ref gt_id) = self.ground_truth_pipeline {
            // First calculate total GT SNPs
            for sample_data in self.samples.values() {
                if let Some(gt_data) = sample_data.pipelines.get(gt_id) {
                    gt_total_snps += gt_data.snps.len() as u32;
                }
            }

            // Get Core GT and Consensus GT
            let gt_core = core_positions.get(gt_id).cloned().unwrap_or_default();
            let gt_consensus = consensus_positions.get(gt_id).cloned().unwrap_or_default();
            core_gt_total = gt_core.len() as u32;
            consensus_gt_total = gt_consensus.len() as u32;

            // For each non-GT pipeline, calculate missing GT SNPs
            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_id {
                    continue;
                }

                let mut missing = 0u32;
                let mut called = 0u32;

                for sample_data in self.samples.values() {
                    // Get GT SNP positions for this sample
                    let gt_positions: std::collections::HashSet<u32> = sample_data
                        .pipelines.get(gt_id)
                        .map(|p| p.snps.iter().map(|s| s.pos).collect())
                        .unwrap_or_default();

                    // Get pipeline SNP positions for this sample
                    let pipeline_positions: std::collections::HashSet<u32> = sample_data
                        .pipelines.get(pipeline_id)
                        .map(|p| p.snps.iter().map(|s| s.pos).collect())
                        .unwrap_or_default();

                    // GT ∩ Pipeline = GT positions that pipeline also calls
                    let intersection = gt_positions.intersection(&pipeline_positions).count() as u32;
                    called += intersection;

                    // GT SNPs not in pipeline = |GT| - |GT ∩ Pipeline|
                    missing += gt_positions.len() as u32 - intersection;
                }

                gt_snps_missing.insert(pipeline_id.clone(), missing);
                gt_snps_called.insert(pipeline_id.clone(), called);

                // Core GT missing: |Core GT| - |Core GT ∩ Core Pipeline|
                let pipeline_core = core_positions.get(pipeline_id).cloned().unwrap_or_default();
                let core_intersection = gt_core.intersection(&pipeline_core).count() as u32;
                core_gt_missing.insert(pipeline_id.clone(), core_gt_total - core_intersection);

                // Consensus GT missing: |Consensus GT| - |Consensus GT ∩ Consensus Pipeline|
                let pipeline_consensus = consensus_positions.get(pipeline_id).cloned().unwrap_or_default();
                let consensus_intersection = gt_consensus.intersection(&pipeline_consensus).count() as u32;
                consensus_gt_missing.insert(pipeline_id.clone(), consensus_gt_total - consensus_intersection);
            }
        }

        // Calculate SNPs in GT gaps for total, core, and consensus
        let mut snps_in_gt_gaps_total: HashMap<String, u32> = HashMap::new();
        let mut snps_in_gt_gaps_core: HashMap<String, u32> = HashMap::new();
        let mut snps_in_gt_gaps_consensus: HashMap<String, u32> = HashMap::new();

        if let Some(ref gt_id) = self.ground_truth_pipeline {
            // Collect all GT gap regions across all samples
            let mut all_gt_gaps: Vec<(u32, u32)> = Vec::new();
            for sample_data in self.samples.values() {
                if let Some(gt_data) = sample_data.pipelines.get(gt_id) {
                    for gap in &gt_data.gaps {
                        all_gt_gaps.push((gap.start, gap.end));
                    }
                }
            }

            // Helper to check if position is in any GT gap
            let in_gt_gap = |pos: u32| -> bool {
                all_gt_gaps.iter().any(|(start, end)| pos >= *start && pos < *end)
            };

            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_id {
                    continue;
                }

                // Total SNPs in GT gaps (sum across samples)
                let mut total_in_gaps = 0u32;
                for sample_data in self.samples.values() {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        // Get GT gaps for this sample
                        let sample_gt_gaps: Vec<(u32, u32)> = sample_data.pipelines.get(gt_id)
                            .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                            .unwrap_or_default();

                        total_in_gaps += pipeline_data.snps.iter()
                            .filter(|snp| sample_gt_gaps.iter().any(|(s, e)| snp.pos >= *s && snp.pos < *e))
                            .count() as u32;
                    }
                }
                snps_in_gt_gaps_total.insert(pipeline_id.clone(), total_in_gaps);

                // Core SNPs in GT gaps
                let pipeline_core = core_positions.get(pipeline_id).cloned().unwrap_or_default();
                let core_in_gaps = pipeline_core.iter()
                    .filter(|&&pos| in_gt_gap(pos))
                    .count() as u32;
                snps_in_gt_gaps_core.insert(pipeline_id.clone(), core_in_gaps);

                // Consensus SNPs in GT gaps
                let pipeline_cons = consensus_positions.get(pipeline_id).cloned().unwrap_or_default();
                let cons_in_gaps = pipeline_cons.iter()
                    .filter(|&&pos| in_gt_gap(pos))
                    .count() as u32;
                snps_in_gt_gaps_consensus.insert(pipeline_id.clone(), cons_in_gaps);
            }
        }

        #[derive(Serialize)]
        struct Kpis {
            snps: HashMap<String, u32>,
            gaps: HashMap<String, u32>,
            core_snps: HashMap<String, u32>,
            consensus_snps: HashMap<String, u32>,
            gt_snps_missing: HashMap<String, u32>,
            gt_snps_called: HashMap<String, u32>,
            gt_total_snps: u32,
            core_gt_missing: HashMap<String, u32>,
            core_gt_total: u32,
            consensus_gt_missing: HashMap<String, u32>,
            consensus_gt_total: u32,
            snps_in_gt_gaps_total: HashMap<String, u32>,
            snps_in_gt_gaps_core: HashMap<String, u32>,
            snps_in_gt_gaps_consensus: HashMap<String, u32>,
            samples: usize,
            pipelines: usize,
            ref_length: u32,
        }

        let kpis = Kpis {
            snps: total_snps,
            gaps: total_gaps,
            core_snps,
            consensus_snps,
            gt_snps_missing,
            gt_snps_called,
            gt_total_snps,
            core_gt_missing,
            core_gt_total,
            consensus_gt_missing,
            consensus_gt_total,
            snps_in_gt_gaps_total,
            snps_in_gt_gaps_core,
            snps_in_gt_gaps_consensus,
            samples: self.samples.len(),
            pipelines: self.pipeline_ids.len(),
            ref_length: self.ref_len,
        };

        serde_json::to_string(&kpis).unwrap_or_else(|_| "{}".to_string())
    }

    /// Global stats for GT pipeline (backward compat)
    #[wasm_bindgen]
    pub fn get_global_stats(&self) -> String {
        match &self.ground_truth_pipeline {
            Some(id) => self.get_global_stats_for_pipeline(id),
            None => "null".to_string(),
        }
    }

    /// Global stats for a specific pipeline: both union and intersection of gaps
    ///
    /// Strict (union): exclude position if at least 1 sample has gap
    /// Relaxed (intersection): exclude position only if ALL samples have gap
    /// For each: Usable Space, Total SNPs (in usable space), Consensus SNPs, Discriminating SNPs
    #[wasm_bindgen]
    pub fn get_global_stats_for_pipeline(&self, pipeline_id: &str) -> String {
        // If pre-computed stats available, return them
        if let Some(ref stats_map) = self.pre_pipeline_stats {
            if let Some(ps) = stats_map.get(pipeline_id) {
                let g = &ps.global;
                let bd = g.disc_breakdown.as_ref();

                #[derive(Serialize)]
                struct DiscBreakdownOut { gap_affected: u32, gt_consensus: u32, majority_rule: u32, confirmed: u32 }
                #[derive(Serialize)]
                struct GlobalVariantOut { usable_space: u32, usable_space_pct: f64, total_snps: u32, consensus_snps: u32, discriminating_snps: u32, disc_breakdown: DiscBreakdownOut, missing_calls: u32 }
                #[derive(Serialize)]
                struct GlobalStatsOut { strict: GlobalVariantOut, relaxed: GlobalVariantOut }

                let stats = GlobalStatsOut {
                    strict: GlobalVariantOut {
                        usable_space: g.usable_union,
                        usable_space_pct: if g.ref_length > 0 { (g.usable_union as f64 / g.ref_length as f64) * 100.0 } else { 0.0 },
                        total_snps: g.total_snps_union,
                        consensus_snps: g.consensus_snps_union,
                        discriminating_snps: g.disc_snps_union,
                        disc_breakdown: DiscBreakdownOut {
                            gap_affected: 0, // Union has no gap-affected
                            gt_consensus: bd.map(|b| b.gt_consensus).unwrap_or(0),
                            majority_rule: bd.map(|b| b.majority_rule).unwrap_or(0),
                            confirmed: bd.map(|b| b.confirmed).unwrap_or(0),
                        },
                        missing_calls: g.missing_vcf_union,
                    },
                    relaxed: GlobalVariantOut {
                        usable_space: g.usable_intersect,
                        usable_space_pct: if g.ref_length > 0 { (g.usable_intersect as f64 / g.ref_length as f64) * 100.0 } else { 0.0 },
                        total_snps: g.total_snps_intersect,
                        consensus_snps: g.consensus_snps_intersect,
                        discriminating_snps: g.disc_snps_intersect,
                        disc_breakdown: DiscBreakdownOut {
                            gap_affected: bd.map(|b| b.gap_affected).unwrap_or(0),
                            gt_consensus: bd.map(|b| b.gt_consensus).unwrap_or(0),
                            majority_rule: bd.map(|b| b.majority_rule).unwrap_or(0),
                            confirmed: bd.map(|b| b.confirmed).unwrap_or(0),
                        },
                        missing_calls: g.missing_vcf_intersect,
                    },
                };

                return serde_json::to_string(&stats).unwrap_or_else(|_| "{}".to_string());
            }
        }

        // Fallback: compute from raw data (v1 format)
        #[derive(Serialize)]
        struct DiscBreakdown {
            gap_affected: u32,
            gt_consensus: u32,
            majority_rule: u32,
            confirmed: u32,
        }

        #[derive(Serialize)]
        struct GlobalVariant {
            usable_space: u32,
            usable_space_pct: f64,
            total_snps: u32,
            consensus_snps: u32,
            discriminating_snps: u32,
            disc_breakdown: DiscBreakdown,
            missing_calls: u32,
        }

        #[derive(Serialize)]
        struct GlobalStats {
            strict: GlobalVariant,
            relaxed: GlobalVariant,
        }

        let pid = pipeline_id.to_string();

        let sample_ids: Vec<&String> = self.samples.keys().collect();

        // Build per-sample gap sets for the target pipeline
        let mut sample_gap_sets: Vec<std::collections::HashSet<u32>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let mut gap_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
            if let Some(p_data) = sample_data.pipelines.get(&pid) {
                for gap in &p_data.gaps {
                    for pos in gap.start..gap.end {
                        gap_positions.insert(pos);
                    }
                }
            }
            sample_gap_sets.push(gap_positions);
        }

        // Union: positions where at least 1 sample has gap
        let mut gap_union: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for gs in &sample_gap_sets {
            gap_union.extend(gs);
        }

        // Intersection: positions where ALL samples have gap
        let gap_intersection = if sample_gap_sets.len() > 1 {
            let mut isect = sample_gap_sets[0].clone();
            for gs in &sample_gap_sets[1..] {
                isect = isect.intersection(gs).cloned().collect();
            }
            isect
        } else if sample_gap_sets.len() == 1 {
            sample_gap_sets[0].clone()
        } else {
            std::collections::HashSet::new()
        };

        // Build per-sample SNP maps for the target pipeline
        let mut snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let snps: HashMap<u32, u8> = sample_data.pipelines.get(&pid)
                .map(|p| self.build_snp_map(p))
                .unwrap_or_default();
            snp_maps.push(snps);
        }

        // Build per-sample GT SNP maps (for cross-check heuristic)
        let gt_id = self.ground_truth_pipeline.clone().unwrap_or_default();
        let is_gt_pipeline = pid == gt_id;
        let mut gt_snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
        if !is_gt_pipeline && !gt_id.is_empty() {
            for sample_id in &sample_ids {
                let sample_data = &self.samples[*sample_id];
                let snps: HashMap<u32, u8> = sample_data.pipelines.get(&gt_id)
                    .map(|p| self.build_snp_map(p))
                    .unwrap_or_default();
                gt_snp_maps.push(snps);
            }
        }

        // All SNP positions for this pipeline
        let mut all_snp_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for snp_map in &snp_maps {
            all_snp_positions.extend(snp_map.keys());
        }

        // Helper: check if GT shows consensus at a position
        // Returns true if all samples agree in GT (all same alt, or all ref)
        let gt_is_consensus_at = |pos: u32| -> bool {
            if is_gt_pipeline || gt_snp_maps.is_empty() {
                return false;
            }
            let first = gt_snp_maps[0].get(&pos).copied();
            gt_snp_maps.iter().all(|m| m.get(&pos).copied() == first)
        };

        // Helper: check majority rule on a set of alleles
        // Returns true if all-but-one agree (N-1 have same allele, 1 differs)
        let is_majority = |alleles: &[Option<u8>]| -> bool {
            if alleles.len() < 3 { return false; } // need ≥3 to have meaningful majority
            // Count occurrences of each allele
            let mut counts: HashMap<Option<u8>, usize> = HashMap::new();
            for a in alleles {
                *counts.entry(*a).or_insert(0) += 1;
            }
            // Check if one allele has N-1 and another has 1
            let max_count = counts.values().max().copied().unwrap_or(0);
            max_count == alleles.len() - 1 && counts.len() == 2
        };

        let compute_variant = |gap_set: &std::collections::HashSet<u32>, gap_aware: bool| -> GlobalVariant {
            let usable_space = self.ref_len - gap_set.len() as u32;
            let usable_space_pct = (usable_space as f64 / self.ref_len as f64) * 100.0;

            let mut total_count: u32 = 0;
            let mut consensus_count: u32 = 0;
            let mut discriminating_count: u32 = 0;
            let mut h_gap_affected: u32 = 0;
            let mut h_gt_consensus: u32 = 0;
            let mut h_majority: u32 = 0;
            let mut h_confirmed: u32 = 0;
            let mut missing_calls_count: u32 = 0;

            for &pos in &all_snp_positions {
                if gap_set.contains(&pos) {
                    continue;
                }
                total_count += 1;

                if gap_aware {
                    // Gap-Intersect: consider only samples without gap
                    let mut alleles: Vec<Option<u8>> = Vec::new();
                    let mut any_gap = false;
                    for (idx, snp_map) in snp_maps.iter().enumerate() {
                        if sample_gap_sets[idx].contains(&pos) {
                            any_gap = true;
                            continue;
                        }
                        alleles.push(snp_map.get(&pos).copied());
                    }
                    if alleles.len() < 2 {
                        continue;
                    }
                    // Missing call: ≥1 non-gap sample has SNP, ≥1 non-gap sample has no call (None)
                    let has_snp = alleles.iter().any(|a| a.is_some());
                    let has_no_call = alleles.iter().any(|a| a.is_none());
                    if has_snp && has_no_call {
                        missing_calls_count += 1;
                    }
                    let first = alleles[0];
                    let all_same = alleles.iter().all(|a| *a == first);
                    if all_same {
                        if first.is_some() {
                            consensus_count += 1;
                        }
                    } else {
                        discriminating_count += 1;
                        // Classify: priority order gap > gt > majority > confirmed
                        if any_gap {
                            h_gap_affected += 1;
                        } else if gt_is_consensus_at(pos) {
                            h_gt_consensus += 1;
                        } else if is_majority(&alleles) {
                            h_majority += 1;
                        } else {
                            h_confirmed += 1;
                        }
                    }
                } else {
                    // Gap-Union: all samples have data (no gaps)
                    // Missing call: ≥1 sample has SNP, ≥1 sample has no call
                    let has_snp = snp_maps.iter().any(|m| m.contains_key(&pos));
                    let has_no_call = snp_maps.iter().any(|m| !m.contains_key(&pos));
                    if has_snp && has_no_call {
                        missing_calls_count += 1;
                    }
                    let mut all_have = true;
                    let mut first_alt: Option<u8> = None;
                    let mut all_same = true;
                    for snp_map in &snp_maps {
                        if let Some(&alt) = snp_map.get(&pos) {
                            match first_alt {
                                None => first_alt = Some(alt),
                                Some(f) => if alt != f { all_same = false; }
                            }
                        } else {
                            all_have = false;
                            break;
                        }
                    }
                    if all_have && all_same && first_alt.is_some() {
                        consensus_count += 1;
                    } else {
                        discriminating_count += 1;
                        // Classify: no gap_affected possible in Gap-Union
                        let alleles: Vec<Option<u8>> = snp_maps.iter()
                            .map(|m| m.get(&pos).copied())
                            .collect();
                        if gt_is_consensus_at(pos) {
                            h_gt_consensus += 1;
                        } else if is_majority(&alleles) {
                            h_majority += 1;
                        } else {
                            h_confirmed += 1;
                        }
                    }
                }
            }

            GlobalVariant {
                usable_space,
                usable_space_pct,
                total_snps: total_count,
                consensus_snps: consensus_count,
                discriminating_snps: discriminating_count,
                disc_breakdown: DiscBreakdown {
                    gap_affected: h_gap_affected,
                    gt_consensus: h_gt_consensus,
                    majority_rule: h_majority,
                    confirmed: h_confirmed,
                },
                missing_calls: missing_calls_count,
            }
        };

        let stats = GlobalStats {
            strict: compute_variant(&gap_union, false),
            relaxed: compute_variant(&gap_intersection, true),
        };

        serde_json::to_string(&stats).unwrap_or_else(|_| "{}".to_string())
    }

    /// Pairwise stats for GT pipeline (backward compat)
    #[wasm_bindgen]
    pub fn get_pairwise_usable_stats(&self) -> String {
        match &self.ground_truth_pipeline {
            Some(id) => self.get_pairwise_usable_stats_for_pipeline(id),
            None => "{}".to_string(),
        }
    }

    /// Get average pairwise usable stats for a specific pipeline
    /// For each pair (A, B):
    ///   - usable_space = refLength - union of pipeline gap bases for A and B
    ///   - discriminating SNPs not in gaps
    /// Returns averages across all N*(N-1)/2 pairs + per-sample breakdown
    #[wasm_bindgen]
    pub fn get_pairwise_usable_stats_for_pipeline(&self, pipeline_id: &str) -> String {
        // If pre-computed stats available, return them
        if let Some(ref stats_map) = self.pre_pipeline_stats {
            if let Some(ps) = stats_map.get(pipeline_id) {
                let pw = &ps.pairwise;

                #[derive(Serialize)]
                struct PairDetailOut { other_sample: String, other_label: String, usable_space: u32, disc_snps: u32 }
                #[derive(Serialize)]
                struct PerSamplePairwiseOut { sample_id: String, sample_label: String, avg_usable_space: f64, avg_usable_space_pct: f64, avg_disc_snps: f64, pairs: Vec<PairDetailOut> }
                #[derive(Serialize)]
                struct PairwiseUsableStatsOut { avg_usable_space: f64, avg_usable_space_pct: f64, avg_usable_snps: f64, min_usable_snps: u32, max_usable_snps: u32, median_usable_snps: f64, num_pairs: u32, per_sample: Vec<PerSamplePairwiseOut> }

                let per_sample: Vec<PerSamplePairwiseOut> = pw.per_sample.iter().map(|(sid, stats)| {
                    let pairs: Vec<PairDetailOut> = stats.pairs.iter().map(|(other_id, detail)| {
                        PairDetailOut {
                            other_sample: other_id.clone(),
                            other_label: self.sample_labels.get(other_id).cloned().unwrap_or_else(|| other_id.clone()),
                            usable_space: detail.usable_space,
                            disc_snps: detail.disc_snps,
                        }
                    }).collect();
                    PerSamplePairwiseOut {
                        sample_id: sid.clone(),
                        sample_label: self.sample_labels.get(sid).cloned().unwrap_or_else(|| sid.clone()),
                        avg_usable_space: stats.avg_usable_space,
                        avg_usable_space_pct: if self.ref_len > 0 { (stats.avg_usable_space / self.ref_len as f64) * 100.0 } else { 0.0 },
                        avg_disc_snps: stats.avg_disc_snps,
                        pairs,
                    }
                }).collect();

                let stats = PairwiseUsableStatsOut {
                    avg_usable_space: pw.usable_space_avg,
                    avg_usable_space_pct: if self.ref_len > 0 { (pw.usable_space_avg / self.ref_len as f64) * 100.0 } else { 0.0 },
                    avg_usable_snps: pw.disc_snps_avg,
                    min_usable_snps: pw.disc_snps_min,
                    max_usable_snps: pw.disc_snps_max,
                    median_usable_snps: pw.disc_snps_median,
                    num_pairs: pw.num_pairs,
                    per_sample,
                };

                return serde_json::to_string(&stats).unwrap_or_else(|_| "{}".to_string());
            }
        }

        // Fallback: compute from raw data (v1 format)
        #[derive(Serialize)]
        struct PerSamplePairwise {
            sample_id: String,
            sample_label: String,
            avg_usable_space: f64,
            avg_usable_space_pct: f64,
            avg_disc_snps: f64,
        }

        #[derive(Serialize)]
        struct PairwiseUsableStats {
            avg_usable_space: f64,
            avg_usable_space_pct: f64,
            avg_usable_snps: f64,
            min_usable_snps: u32,
            max_usable_snps: u32,
            median_usable_snps: f64,
            num_pairs: usize,
            per_sample: Vec<PerSamplePairwise>,
        }

        let sample_ids: Vec<&String> = self.samples.keys().collect();
        let n = sample_ids.len();
        if n < 2 {
            return serde_json::to_string(&PairwiseUsableStats {
                avg_usable_space: self.ref_len as f64,
                avg_usable_space_pct: 100.0,
                avg_usable_snps: 0.0,
                min_usable_snps: 0,
                max_usable_snps: 0,
                median_usable_snps: 0.0,
                num_pairs: 0,
                per_sample: Vec::new(),
            }).unwrap_or_else(|_| "{}".to_string());
        }

        let gt_id = Some(pipeline_id.to_string());
        let num_pairs = n * (n - 1) / 2;
        let mut total_usable_space: f64 = 0.0;
        let mut total_usable_snps: f64 = 0.0;
        let mut per_pair_disc: Vec<u32> = Vec::with_capacity(num_pairs);
        // Per-sample accumulators: sum of usable_space and disc_snps across all pairs involving sample i
        let mut sample_sum_space: Vec<f64> = vec![0.0; n];
        let mut sample_sum_disc: Vec<f64> = vec![0.0; n];

        // Helper: merge gap regions into non-overlapping sorted list and compute total bases
        fn merge_gaps_total(gaps_a: &[(u32, u32)], gaps_b: &[(u32, u32)]) -> u32 {
            let mut all: Vec<(u32, u32)> = Vec::with_capacity(gaps_a.len() + gaps_b.len());
            all.extend_from_slice(gaps_a);
            all.extend_from_slice(gaps_b);
            all.sort_unstable();
            let mut total = 0u32;
            let mut cur_start = 0u32;
            let mut cur_end = 0u32;
            for &(s, e) in &all {
                if s > cur_end {
                    total += cur_end - cur_start;
                    cur_start = s;
                    cur_end = e;
                } else if e > cur_end {
                    cur_end = e;
                }
            }
            total += cur_end - cur_start;
            total
        }

        // Helper: check if position is in any gap from merged list
        fn in_merged_gaps(pos: u32, gaps: &[(u32, u32)]) -> bool {
            // Binary search for efficiency
            match gaps.binary_search_by(|&(s, _)| s.cmp(&pos)) {
                Ok(_) => true, // pos == start of a gap
                Err(idx) => {
                    // Check if pos is inside the preceding gap
                    if idx > 0 {
                        let (_, end) = gaps[idx - 1];
                        pos < end
                    } else {
                        false
                    }
                }
            }
        }

        // Merge and sort gaps helper
        fn merge_gap_regions(gaps_a: &[(u32, u32)], gaps_b: &[(u32, u32)]) -> Vec<(u32, u32)> {
            let mut all: Vec<(u32, u32)> = Vec::with_capacity(gaps_a.len() + gaps_b.len());
            all.extend_from_slice(gaps_a);
            all.extend_from_slice(gaps_b);
            all.sort_unstable();
            let mut merged: Vec<(u32, u32)> = Vec::new();
            for &(s, e) in &all {
                if let Some(last) = merged.last_mut() {
                    if s <= last.1 {
                        last.1 = last.1.max(e);
                    } else {
                        merged.push((s, e));
                    }
                } else {
                    merged.push((s, e));
                }
            }
            merged
        }

        for i in 0..n {
            for j in (i+1)..n {
                let sample_a = &self.samples[sample_ids[i]];
                let sample_b = &self.samples[sample_ids[j]];

                // Get GT gaps for both samples
                let gaps_a: Vec<(u32, u32)> = gt_id.as_ref()
                    .and_then(|gt| sample_a.pipelines.get(gt))
                    .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                    .unwrap_or_default();
                let gaps_b: Vec<(u32, u32)> = gt_id.as_ref()
                    .and_then(|gt| sample_b.pipelines.get(gt))
                    .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                    .unwrap_or_default();

                // Usable space = refLen - merged GT gaps
                let gap_bases = merge_gaps_total(&gaps_a, &gaps_b);
                let pair_usable_space = (self.ref_len - gap_bases) as f64;
                total_usable_space += pair_usable_space;
                sample_sum_space[i] += pair_usable_space;
                sample_sum_space[j] += pair_usable_space;

                // Count discriminating GT SNPs not in GT gaps
                if let Some(ref gt) = gt_id {
                    let merged_gaps = merge_gap_regions(&gaps_a, &gaps_b);

                    let snps_a: HashMap<u32, u8> = sample_a.pipelines.get(gt)
                        .map(|p| self.build_snp_map(p))
                        .unwrap_or_default();
                    let snps_b: HashMap<u32, u8> = sample_b.pipelines.get(gt)
                        .map(|p| self.build_snp_map(p))
                        .unwrap_or_default();

                    // All GT SNP positions in either sample
                    let mut all_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
                    all_positions.extend(snps_a.keys());
                    all_positions.extend(snps_b.keys());

                    let mut discriminating = 0u32;
                    for &pos in &all_positions {
                        // Skip if in GT gaps
                        if !merged_gaps.is_empty() && in_merged_gaps(pos, &merged_gaps) {
                            continue;
                        }
                        // Discriminating: different between the two samples
                        let alt_a = snps_a.get(&pos);
                        let alt_b = snps_b.get(&pos);
                        if alt_a != alt_b {
                            discriminating += 1;
                        }
                    }

                    per_pair_disc.push(discriminating);
                    total_usable_snps += discriminating as f64;
                    sample_sum_disc[i] += discriminating as f64;
                    sample_sum_disc[j] += discriminating as f64;
                }
            }
        }

        let avg_usable_space = total_usable_space / num_pairs as f64;
        let avg_usable_space_pct = (avg_usable_space / self.ref_len as f64) * 100.0;
        let avg_usable_snps = total_usable_snps / num_pairs as f64;

        per_pair_disc.sort_unstable();
        let min_usable_snps = *per_pair_disc.first().unwrap_or(&0);
        let max_usable_snps = *per_pair_disc.last().unwrap_or(&0);
        let median_usable_snps = if per_pair_disc.is_empty() {
            0.0
        } else {
            let mid = per_pair_disc.len() / 2;
            if per_pair_disc.len() % 2 == 0 {
                (per_pair_disc[mid - 1] as f64 + per_pair_disc[mid] as f64) / 2.0
            } else {
                per_pair_disc[mid] as f64
            }
        };

        // Per-sample averages: each sample is in (n-1) pairs
        let pairs_per_sample = (n - 1) as f64;
        let per_sample: Vec<PerSamplePairwise> = (0..n).map(|i| {
            let avg_space = sample_sum_space[i] / pairs_per_sample;
            PerSamplePairwise {
                sample_id: sample_ids[i].clone(),
                sample_label: self.sample_labels.get(sample_ids[i])
                    .cloned()
                    .unwrap_or_else(|| sample_ids[i].clone()),
                avg_usable_space: avg_space,
                avg_usable_space_pct: (avg_space / self.ref_len as f64) * 100.0,
                avg_disc_snps: sample_sum_disc[i] / pairs_per_sample,
            }
        }).collect();

        let stats = PairwiseUsableStats {
            avg_usable_space,
            avg_usable_space_pct,
            avg_usable_snps,
            min_usable_snps,
            max_usable_snps,
            median_usable_snps,
            num_pairs,
            per_sample,
        };

        serde_json::to_string(&stats).unwrap_or_else(|_| "{}".to_string())
    }


    /// For each VCF pipeline, return GT discriminating SNPs vs pipeline core SNP data.
    /// Returns pre-computed results from the CLI compare command, or falls back to
    /// VCF-based computation if no pre-computed data is available.
    /// Output format: { pipeline_id: { gap_intersect_gt_disc, ..., concordant (nullable) } }
    #[wasm_bindgen]
    pub fn get_gt_disc_vs_pipelines(&self) -> String {
        // If pre-computed data exists, convert to the flat format expected by the HTML
        if let Some(ref results) = self.gt_disc_vs_pipelines {
            #[derive(Serialize)]
            struct GtDiscVsPipeline {
                pl_total_core_snps: u32,
                pl_discriminating_core_snps: u32,

                gap_intersect_gt_disc: u32,
                gap_intersect_same_pos: u32,
                gap_intersect_concordant: Option<u32>,
                gap_intersect_pl_snps_in_gt_gaps: u32,

                gap_union_gt_disc: u32,
                gap_union_same_pos: u32,
                gap_union_concordant: Option<u32>,
                gap_union_pl_snps_in_gt_gaps: u32,

                pairwise_gt_disc_avg: f64,
                pairwise_same_pos_avg: f64,
                pairwise_concordant_avg: Option<f64>,
                pairwise_num_pairs: u32,
            }

            let mut map: HashMap<String, GtDiscVsPipeline> = HashMap::new();
            for r in results {
                map.insert(r.pipeline_id.clone(), GtDiscVsPipeline {
                    pl_total_core_snps: r.pl_total_core_snps,
                    pl_discriminating_core_snps: r.pl_discriminating_core_snps,
                    gap_intersect_gt_disc: r.gap_intersect.gt_disc,
                    gap_intersect_same_pos: r.gap_intersect.same_pos,
                    gap_intersect_concordant: r.gap_intersect.concordant,
                    gap_intersect_pl_snps_in_gt_gaps: r.gap_intersect.pl_snps_in_gt_gaps,

                    gap_union_gt_disc: r.gap_union.gt_disc,
                    gap_union_same_pos: r.gap_union.same_pos,
                    gap_union_concordant: r.gap_union.concordant,
                    gap_union_pl_snps_in_gt_gaps: r.gap_union.pl_snps_in_gt_gaps,

                    pairwise_gt_disc_avg: r.pairwise.gt_disc_avg,
                    pairwise_same_pos_avg: r.pairwise.same_pos_avg,
                    pairwise_concordant_avg: r.pairwise.concordant_avg,
                    pairwise_num_pairs: r.pairwise.num_pairs,
                });
            }
            return serde_json::to_string(&map).unwrap_or_else(|_| "{}".to_string());
        }

        // Fallback: compute from VCF data (legacy behavior for reports without core_snps)
        self.compute_gt_disc_vs_pipelines_from_vcf()
    }

    /// Legacy VCF-based computation of GT disc vs pipelines (fallback when no pre-computed data)
    fn compute_gt_disc_vs_pipelines_from_vcf(&self) -> String {
        #[derive(Serialize)]
        struct GtDiscVsPipeline {
            pl_total_core_snps: u32,
            pl_discriminating_core_snps: u32,

            gap_intersect_gt_disc: u32,
            gap_intersect_same_pos: u32,
            gap_intersect_concordant: Option<u32>,
            gap_intersect_pl_snps_in_gt_gaps: u32,

            gap_union_gt_disc: u32,
            gap_union_same_pos: u32,
            gap_union_concordant: Option<u32>,
            gap_union_pl_snps_in_gt_gaps: u32,

            pairwise_gt_disc_avg: f64,
            pairwise_same_pos_avg: f64,
            pairwise_concordant_avg: Option<f64>,
            pairwise_num_pairs: u32,
        }

        let gt_id = match &self.ground_truth_pipeline {
            Some(id) => id.clone(),
            None => return "{}".to_string(),
        };

        let sample_ids: Vec<&String> = self.samples.keys().collect();
        let n = sample_ids.len();
        if n < 2 {
            return "{}".to_string();
        }

        // Build per-sample GT gap sets
        let mut gt_gap_sets: Vec<std::collections::HashSet<u32>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let mut gaps: std::collections::HashSet<u32> = std::collections::HashSet::new();
            if let Some(gt_data) = sample_data.pipelines.get(&gt_id) {
                for gap in &gt_data.gaps {
                    for pos in gap.start..gap.end {
                        gaps.insert(pos);
                    }
                }
            }
            gt_gap_sets.push(gaps);
        }

        // GT gap union (positions where ANY sample has GT gap)
        let mut gt_gap_union: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for gs in &gt_gap_sets {
            gt_gap_union.extend(gs);
        }

        // GT gap intersection (positions where ALL samples have GT gap)
        let gt_gap_intersection = if gt_gap_sets.len() > 1 {
            let mut isect = gt_gap_sets[0].clone();
            for gs in &gt_gap_sets[1..] {
                isect = isect.intersection(gs).cloned().collect();
            }
            isect
        } else if gt_gap_sets.len() == 1 {
            gt_gap_sets[0].clone()
        } else {
            std::collections::HashSet::new()
        };

        // Build per-sample GT SNP maps
        let mut gt_snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
        for sample_id in &sample_ids {
            let sample_data = &self.samples[*sample_id];
            let snps: HashMap<u32, u8> = sample_data.pipelines.get(&gt_id)
                .map(|p| self.build_snp_map(p))
                .unwrap_or_default();
            gt_snp_maps.push(snps);
        }

        // Find all GT SNP positions
        let mut all_gt_snp_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
        for snp_map in &gt_snp_maps {
            all_gt_snp_positions.extend(snp_map.keys());
        }

        // --- Gap-Union GT discriminating positions ---
        let mut gt_disc_union: Vec<u32> = Vec::new();
        for &pos in &all_gt_snp_positions {
            if gt_gap_union.contains(&pos) {
                continue;
            }
            let alleles: Vec<Option<u8>> = (0..n).map(|idx| gt_snp_maps[idx].get(&pos).copied()).collect();
            let first = alleles[0];
            if alleles.iter().any(|a| *a != first) {
                gt_disc_union.push(pos);
            }
        }

        // --- Gap-Intersect GT discriminating positions ---
        let mut gt_disc_intersect: Vec<u32> = Vec::new();
        for &pos in &all_gt_snp_positions {
            if gt_gap_intersection.contains(&pos) {
                continue;
            }
            let alleles: Vec<Option<u8>> = (0..n)
                .filter(|&idx| !gt_gap_sets[idx].contains(&pos))
                .map(|idx| gt_snp_maps[idx].get(&pos).copied())
                .collect();
            if alleles.len() < 2 {
                continue;
            }
            let first = alleles[0];
            if alleles.iter().any(|a| *a != first) {
                gt_disc_intersect.push(pos);
            }
        }

        let ref_bytes = self.ref_seq.as_bytes();

        // Helper: for a set of GT disc positions, compute same_pos and concordant
        let count_same_concordant = |disc_positions: &[u32],
                                      sample_indices: &[usize],
                                      gt_snp_maps: &[HashMap<u32, u8>],
                                      pl_gap_sets: &[std::collections::HashSet<u32>],
                                      pl_snp_maps: &[HashMap<u32, u8>]| -> (u32, u32) {
            let mut same_pos: u32 = 0;
            let mut concordant: u32 = 0;
            for &pos in disc_positions {
                let pl_has_snp = sample_indices.iter().any(|&idx| pl_snp_maps[idx].contains_key(&pos));
                if !pl_has_snp {
                    continue;
                }
                same_pos += 1;

                let any_pl_gap = sample_indices.iter().any(|&idx| pl_gap_sets[idx].contains(&pos));
                if any_pl_gap {
                    continue;
                }

                let all_match = sample_indices.iter().all(|&idx| {
                    let gt_allele = gt_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    let pl_allele = pl_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    gt_allele == pl_allele
                });
                if all_match {
                    concordant += 1;
                }
            }
            (same_pos, concordant)
        };

        // Helper: count pipeline SNPs that fall in a GT gap set
        let count_pl_snps_in_gt_gaps = |gt_gaps: &std::collections::HashSet<u32>,
                                         pl_snp_maps: &[HashMap<u32, u8>]| -> u32 {
            let mut all_pl_snp_positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
            for snp_map in pl_snp_maps {
                all_pl_snp_positions.extend(snp_map.keys());
            }
            all_pl_snp_positions.iter().filter(|pos| gt_gaps.contains(pos)).count() as u32
        };

        let all_indices: Vec<usize> = (0..n).collect();

        let mut result: HashMap<String, GtDiscVsPipeline> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            if *pipeline_id == gt_id {
                continue;
            }

            // Build per-sample pipeline gap sets
            let mut pl_gap_sets: Vec<std::collections::HashSet<u32>> = Vec::new();
            for sample_id in &sample_ids {
                let sample_data = &self.samples[*sample_id];
                let mut gaps: std::collections::HashSet<u32> = std::collections::HashSet::new();
                if let Some(pl_data) = sample_data.pipelines.get(pipeline_id) {
                    for gap in &pl_data.gaps {
                        for pos in gap.start..gap.end {
                            gaps.insert(pos);
                        }
                    }
                }
                pl_gap_sets.push(gaps);
            }

            // Build per-sample pipeline SNP maps
            let mut pl_snp_maps: Vec<HashMap<u32, u8>> = Vec::new();
            let mut all_pl_snp_pos: std::collections::HashSet<u32> = std::collections::HashSet::new();
            for sample_id in &sample_ids {
                let sample_data = &self.samples[*sample_id];
                let snps: HashMap<u32, u8> = sample_data.pipelines.get(pipeline_id)
                    .map(|p| self.build_snp_map(p))
                    .unwrap_or_default();
                all_pl_snp_pos.extend(snps.keys());
                pl_snp_maps.push(snps);
            }
            let pl_total_core_snps = all_pl_snp_pos.len() as u32;

            // Count discriminating positions: at least 2 samples with different alleles
            let pl_discriminating_core_snps = all_pl_snp_pos.iter().filter(|&&pos| {
                let alleles: Vec<Option<u8>> = pl_snp_maps.iter()
                    .map(|m| m.get(&pos).copied())
                    .collect();
                if alleles.len() < 2 { return false; }
                let first = alleles[0];
                alleles.iter().any(|a| *a != first)
            }).count() as u32;

            let (gu_same_pos, gu_concordant) = count_same_concordant(
                &gt_disc_union, &all_indices, &gt_snp_maps, &pl_gap_sets, &pl_snp_maps);
            let gu_pl_in_gaps = count_pl_snps_in_gt_gaps(&gt_gap_union, &pl_snp_maps);

            let mut gi_same_pos: u32 = 0;
            let mut gi_concordant: u32 = 0;
            for &pos in &gt_disc_intersect {
                let active: Vec<usize> = (0..n).filter(|&idx| !gt_gap_sets[idx].contains(&pos)).collect();
                if active.len() < 2 { continue; }

                let pl_has_snp = active.iter().any(|&idx| pl_snp_maps[idx].contains_key(&pos));
                if !pl_has_snp { continue; }
                gi_same_pos += 1;

                let any_pl_gap = active.iter().any(|&idx| pl_gap_sets[idx].contains(&pos));
                if any_pl_gap { continue; }

                let all_match = active.iter().all(|&idx| {
                    let gt_allele = gt_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    let pl_allele = pl_snp_maps[idx].get(&pos).copied()
                        .unwrap_or_else(|| if (pos as usize) < ref_bytes.len() { ref_bytes[pos as usize] } else { b'N' });
                    gt_allele == pl_allele
                });
                if all_match {
                    gi_concordant += 1;
                }
            }
            let gi_pl_in_gaps = count_pl_snps_in_gt_gaps(&gt_gap_intersection, &pl_snp_maps);

            let mut pw_total_disc: f64 = 0.0;
            let mut pw_total_same_pos: f64 = 0.0;
            let mut pw_total_concordant: f64 = 0.0;
            let mut num_pairs: u32 = 0;

            for i in 0..n {
                for j in (i+1)..n {
                    let pair_gap_union: std::collections::HashSet<u32> = gt_gap_sets[i].union(&gt_gap_sets[j]).cloned().collect();

                    let mut pair_disc: Vec<u32> = Vec::new();
                    for &pos in &all_gt_snp_positions {
                        if pair_gap_union.contains(&pos) { continue; }
                        let a_i = gt_snp_maps[i].get(&pos).copied();
                        let a_j = gt_snp_maps[j].get(&pos).copied();
                        if a_i != a_j {
                            pair_disc.push(pos);
                        }
                    }

                    let pair_indices = vec![i, j];
                    let (p_same, p_conc) = count_same_concordant(
                        &pair_disc, &pair_indices, &gt_snp_maps, &pl_gap_sets, &pl_snp_maps);

                    pw_total_disc += pair_disc.len() as f64;
                    pw_total_same_pos += p_same as f64;
                    pw_total_concordant += p_conc as f64;
                    num_pairs += 1;
                }
            }

            let np = if num_pairs > 0 { num_pairs as f64 } else { 1.0 };

            result.insert(pipeline_id.clone(), GtDiscVsPipeline {
                pl_total_core_snps,
                pl_discriminating_core_snps,
                gap_intersect_gt_disc: gt_disc_intersect.len() as u32,
                gap_intersect_same_pos: gi_same_pos,
                gap_intersect_concordant: Some(gi_concordant),
                gap_intersect_pl_snps_in_gt_gaps: gi_pl_in_gaps,

                gap_union_gt_disc: gt_disc_union.len() as u32,
                gap_union_same_pos: gu_same_pos,
                gap_union_concordant: Some(gu_concordant),
                gap_union_pl_snps_in_gt_gaps: gu_pl_in_gaps,

                pairwise_gt_disc_avg: pw_total_disc / np,
                pairwise_same_pos_avg: pw_total_same_pos / np,
                pairwise_concordant_avg: Some(pw_total_concordant / np),
                pairwise_num_pairs: num_pairs,
            });
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Return per-position detail for GT discriminating SNPs vs a specific pipeline.
    /// Returns pre-computed data from the CLI if available, otherwise falls back to
    /// VCF-based computation (which may differ due to different allele sources).
    /// `strategy` must be "gap_union" or "gap_intersect".
    #[wasm_bindgen]
    pub fn get_gt_disc_position_details(&self, pipeline_id: &str, strategy: &str) -> String {
        // Try pre-computed data first (guaranteed to match table counts)
        if let Some(ref results) = self.gt_disc_vs_pipelines {
            if let Some(r) = results.iter().find(|r| r.pipeline_id == pipeline_id) {
                let strategy_result = if strategy == "gap_union" { &r.gap_union } else { &r.gap_intersect };
                if let Some(ref details) = strategy_result.position_details {
                    // Get sample list from the detail entries
                    let samples: Vec<String> = if let Some(first) = details.first() {
                        let mut s: Vec<String> = first.gt.keys().cloned().collect();
                        s.sort();
                        s
                    } else {
                        Vec::new()
                    };

                    let result = serde_json::json!({
                        "samples": samples,
                        "positions": details.iter().map(|d| {
                            serde_json::json!({
                                "pos": d.pos,
                                "ref": d.ref_allele,
                                "gt": d.gt,
                                "pl": d.pl,
                                "status": d.status
                            })
                        }).collect::<Vec<_>>()
                    });
                    return serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string());
                }
            }
        }

        // No pre-computed data available
        "{}".to_string()
    }

    // Internal helper: binary search for SNP at position
    fn find_snp(snps: &[Snp], pos: u32) -> Option<&Snp> {
        snps.binary_search_by_key(&pos, |s| s.pos)
            .ok()
            .map(|idx| &snps[idx])
    }

}

/// Initialize panic hook for better error messages
#[wasm_bindgen(start)]
pub fn init() {
    console_error_panic_hook::set_once();
}
