//! CoreGuard WASM module for fast SNP comparison visualization
//!
//! This module loads JSON reports generated by `coreguard compare` and provides
//! fast querying and rendering for the browser-based viewer.

use wasm_bindgen::prelude::*;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// A gap region [start, end) - 1-based positions
#[derive(Clone, Debug)]
struct GapRegion {
    start: u32,
    end: u32,
}

/// SNP data at a position
#[derive(Clone, Debug)]
struct Snp {
    pos: u32,
    ref_allele: u8,  // ASCII char code
    alt_allele: u8,  // ASCII char code
    qual: f32,
    depth: u16,
}

/// Pipeline data with gaps and SNPs stored in sorted vectors for binary search
#[derive(Default)]
struct PipelineData {
    gaps: Vec<GapRegion>,
    snps: Vec<Snp>,
    has_vcf: bool,
    has_bam: bool,
    vcf_path: Option<String>,
    bam_path: Option<String>,
}

/// Sample data containing data for each pipeline
#[derive(Default)]
struct SampleData {
    pipelines: HashMap<String, PipelineData>,
}

/// Report schema matching the JSON from `coreguard compare`
#[derive(Debug, Deserialize, Serialize)]
struct JsonReport {
    #[serde(rename = "_version")]
    version: String,
    reference: JsonReference,
    samples: HashMap<String, JsonSampleInfo>,
    pipelines: HashMap<String, JsonPipelineInfo>,
    data: HashMap<String, HashMap<String, JsonPipelineData>>,
    /// Polymorphic sites per pipeline: pipeline_id -> position (as string) -> site data
    #[serde(default)]
    polymorphic_sites: HashMap<String, HashMap<String, JsonPolymorphicSite>>,
    summary: JsonSummary,
}

/// Polymorphic site data for distance matrix calculation
#[derive(Debug, Deserialize, Serialize)]
struct JsonPolymorphicSite {
    #[serde(rename = "ref")]
    ref_allele: char,
    alleles: HashMap<String, JsonSampleAllele>,
}

/// Sample allele at a polymorphic site
#[derive(Debug, Deserialize, Serialize)]
struct JsonSampleAllele {
    base: char,
    source: String,
    #[serde(default)]
    depth: Option<u32>,
    #[serde(default)]
    qual: Option<f64>,
    #[serde(default)]
    consensus: Option<f64>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonReference {
    name: String,
    label: Option<String>,
    length: usize,
    sequence: String,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonSampleInfo {
    label: Option<String>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonPipelineInfo {
    label: Option<String>,
    command: Option<String>,
    has_vcf: bool,
    has_bam: bool,
    #[serde(default)]
    ground_truth: bool,
}

#[derive(Debug, Deserialize, Serialize, Default)]
struct JsonPipelineData {
    #[serde(default)]
    gaps: Vec<[usize; 2]>,
    #[serde(default)]
    snps: Vec<JsonSnp>,
    #[serde(default)]
    vcf_path: Option<String>,
    #[serde(default)]
    bam_path: Option<String>,
}

#[derive(Debug, Deserialize, Serialize)]
struct JsonSnp {
    pos: usize,
    #[serde(rename = "ref")]
    ref_allele: String,
    alt: String,
    qual: f64,
    dp: usize,
}

#[derive(Debug, Deserialize, Serialize)]
#[allow(dead_code)]
struct JsonSummary {
    total_samples: usize,
    total_pipelines: usize,
    generated_at: String,
    coreguard_version: String,
    #[serde(default)]
    warnings: Vec<String>,
    #[serde(default)]
    snps_in_gt_gaps: Option<HashMap<String, JsonSnpsInGapsStats>>,
    #[serde(default)]
    ground_truth_pileup: Option<JsonGroundTruthPileupStats>,
    #[serde(default)]
    mnp_stats: Option<HashMap<String, JsonMnpStats>>,
}

/// Ground truth pileup statistics from BAM (without variant calling)
#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonGroundTruthPileupStats {
    total_snps: usize,
    per_sample: HashMap<String, usize>,
    covered_positions: usize,
    pipeline_comparison: HashMap<String, JsonPipelineVsGroundTruth>,
}

/// Comparison of a pipeline's SNP count vs ground truth pileup
#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonPipelineVsGroundTruth {
    pipeline_snps: usize,
    ground_truth_snps: usize,
    difference: i64,
    percentage_diff: f64,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonSnpsInGapsStats {
    total_snps: usize,
    snps_in_gaps: usize,
    percentage: f64,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
struct JsonMnpStats {
    mnps_found: usize,
    snps_from_mnps: usize,
}

/// Allele data at a polymorphic site for a specific sample
#[derive(Clone, Debug)]
struct AlleleData {
    base: char,
    source: String,  // "vcf", "bam", "gap", "inferred"
    depth: Option<u32>,
    qual: Option<f64>,
    consensus: Option<f64>,
}

/// Main data store - holds all samples and pipeline data
#[wasm_bindgen]
pub struct GenomeData {
    samples: HashMap<String, SampleData>,
    sample_labels: HashMap<String, String>,
    pipeline_ids: Vec<String>,  // Ordered list of pipelines
    pipeline_labels: HashMap<String, String>,
    pipeline_commands: HashMap<String, String>,
    /// Ground truth pipeline ID (if any) - used as baseline for comparison
    ground_truth_pipeline: Option<String>,
    ref_seq: String,
    ref_name: String,
    ref_label: Option<String>,
    ref_len: u32,
    report_version: String,
    generated_at: String,
    warnings: Vec<String>,
    /// SNPs in ground truth gaps statistics
    snps_in_gt_gaps: Option<HashMap<String, JsonSnpsInGapsStats>>,
    /// Ground truth pileup statistics (SNP count from BAM without variant calling)
    ground_truth_pileup: Option<JsonGroundTruthPileupStats>,
    /// MNP decomposition statistics per pipeline
    mnp_stats: Option<HashMap<String, JsonMnpStats>>,
    /// Polymorphic sites for distance matrix calculation (per pipeline)
    /// Key: pipeline_id -> position -> sample_id -> allele data
    polymorphic_sites: HashMap<String, HashMap<u32, HashMap<String, AlleleData>>>,
    /// Reference allele at each polymorphic site (per pipeline)
    polymorphic_refs: HashMap<String, HashMap<u32, char>>,
}

#[wasm_bindgen]
impl GenomeData {
    /// Create a new empty GenomeData
    #[wasm_bindgen(constructor)]
    pub fn new() -> GenomeData {
        GenomeData {
            samples: HashMap::new(),
            sample_labels: HashMap::new(),
            pipeline_ids: Vec::new(),
            pipeline_labels: HashMap::new(),
            pipeline_commands: HashMap::new(),
            ground_truth_pipeline: None,
            ref_seq: String::new(),
            ref_name: String::new(),
            ref_label: None,
            ref_len: 0,
            report_version: String::new(),
            generated_at: String::new(),
            warnings: Vec::new(),
            snps_in_gt_gaps: None,
            ground_truth_pileup: None,
            mnp_stats: None,
            polymorphic_sites: HashMap::new(),
            polymorphic_refs: HashMap::new(),
        }
    }

    /// Load data from JSON report (the main entry point)
    #[wasm_bindgen]
    pub fn load_json(&mut self, json: &str) -> Result<(), JsValue> {
        let report: JsonReport = serde_json::from_str(json)
            .map_err(|e| JsValue::from_str(&format!("JSON parse error: {}", e)))?;

        self.load_report(report)
    }

    /// Load data from binary (bincode) report - faster than JSON
    #[wasm_bindgen]
    pub fn load_binary(&mut self, data: &[u8]) -> Result<(), JsValue> {
        let report: JsonReport = bincode::deserialize(data)
            .map_err(|e| JsValue::from_str(&format!("Bincode parse error: {}", e)))?;

        self.load_report(report)
    }

    /// Common logic for loading a parsed report (used by both load_json and load_binary)
    fn load_report(&mut self, report: JsonReport) -> Result<(), JsValue> {
        let t0 = js_sys::Date::now();

        // Clear existing data
        self.samples.clear();
        self.sample_labels.clear();
        self.pipeline_ids.clear();
        self.pipeline_labels.clear();
        self.pipeline_commands.clear();
        self.ground_truth_pipeline = None;

        // Load reference
        self.ref_seq = report.reference.sequence;
        self.ref_name = report.reference.name;
        self.ref_label = report.reference.label;
        self.ref_len = report.reference.length as u32;
        self.report_version = report.version;
        self.generated_at = report.summary.generated_at;
        self.warnings = report.summary.warnings;
        self.snps_in_gt_gaps = report.summary.snps_in_gt_gaps;
        self.ground_truth_pileup = report.summary.ground_truth_pileup;
        self.mnp_stats = report.summary.mnp_stats;

        // Load sample labels
        for (id, info) in &report.samples {
            if let Some(label) = &info.label {
                self.sample_labels.insert(id.clone(), label.clone());
            }
        }

        // Detect ground truth pipeline from JSON
        for (id, info) in &report.pipelines {
            if info.ground_truth {
                self.ground_truth_pipeline = Some(id.clone());
                break;
            }
        }

        // Load pipeline metadata (ground truth first, then alphabetical)
        let mut pipeline_ids: Vec<_> = report.pipelines.keys().cloned().collect();
        let gt_id = self.ground_truth_pipeline.clone();
        pipeline_ids.sort_by(|a, b| {
            // Ground truth pipeline always first
            match (&gt_id, a.as_str(), b.as_str()) {
                (Some(gt), a_str, _) if a_str == gt => std::cmp::Ordering::Less,
                (Some(gt), _, b_str) if b_str == gt => std::cmp::Ordering::Greater,
                _ => a.cmp(b),
            }
        });
        for id in &pipeline_ids {
            if let Some(info) = report.pipelines.get(id) {
                if let Some(label) = &info.label {
                    self.pipeline_labels.insert(id.clone(), label.clone());
                }
                if let Some(command) = &info.command {
                    self.pipeline_commands.insert(id.clone(), command.clone());
                }
            }
        }
        self.pipeline_ids = pipeline_ids;

        let t1 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Metadata loaded: {}ms", t1 - t0).into());

        // Load data for each sample
        for (sample_id, sample_pipelines) in &report.data {
            let mut sample_data = SampleData::default();

            for (pipeline_id, json_data) in sample_pipelines {
                let mut pipeline_data = PipelineData::default();

                // Load gaps
                for gap in &json_data.gaps {
                    pipeline_data.gaps.push(GapRegion {
                        start: gap[0] as u32,
                        end: gap[1] as u32,
                    });
                }

                // Load SNPs
                for snp in &json_data.snps {
                    let ref_char = snp.ref_allele.chars().next().unwrap_or('N') as u8;
                    let alt_char = snp.alt.chars().next().unwrap_or('N') as u8;
                    pipeline_data.snps.push(Snp {
                        pos: snp.pos as u32,
                        ref_allele: ref_char,
                        alt_allele: alt_char,
                        qual: snp.qual as f32,
                        depth: snp.dp as u16,
                    });
                }

                // Store pipeline info
                if let Some(info) = report.pipelines.get(pipeline_id) {
                    pipeline_data.has_vcf = info.has_vcf;
                    pipeline_data.has_bam = info.has_bam;
                }

                // Store file paths for reproducibility
                pipeline_data.vcf_path = json_data.vcf_path.clone();
                pipeline_data.bam_path = json_data.bam_path.clone();

                sample_data.pipelines.insert(pipeline_id.clone(), pipeline_data);
            }

            self.samples.insert(sample_id.clone(), sample_data);
        }

        let t2 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Data loaded: {}ms", t2 - t1).into());

        // Finalize (sort for binary search)
        self.finalize();

        let t3 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Finalized: {}ms", t3 - t2).into());

        // Load polymorphic sites for distance matrix calculation (per pipeline)
        self.polymorphic_sites.clear();
        self.polymorphic_refs.clear();

        let mut total_sites = 0usize;
        for (pipeline_id, pipeline_sites) in &report.polymorphic_sites {
            let mut sites_map: HashMap<u32, HashMap<String, AlleleData>> = HashMap::new();
            let mut refs_map: HashMap<u32, char> = HashMap::new();

            for (pos_str, site) in pipeline_sites {
                if let Ok(pos) = pos_str.parse::<u32>() {
                    refs_map.insert(pos, site.ref_allele);

                    let mut sample_alleles: HashMap<String, AlleleData> = HashMap::new();
                    for (sample_id, allele) in &site.alleles {
                        sample_alleles.insert(sample_id.clone(), AlleleData {
                            base: allele.base,
                            source: allele.source.clone(),
                            depth: allele.depth,
                            qual: allele.qual,
                            consensus: allele.consensus,
                        });
                    }
                    sites_map.insert(pos, sample_alleles);
                }
            }

            total_sites = total_sites.max(sites_map.len());
            self.polymorphic_sites.insert(pipeline_id.clone(), sites_map);
            self.polymorphic_refs.insert(pipeline_id.clone(), refs_map);
        }

        let t4 = js_sys::Date::now();
        web_sys::console::log_1(&format!("Polymorphic sites: {}ms", t4 - t3).into());
        web_sys::console::log_1(&format!("TOTAL: {}ms", t4 - t0).into());

        web_sys::console::log_1(&format!(
            "Loaded report v{}: {} samples, {} pipelines, {} bp reference, {} polymorphic sites per pipeline",
            self.report_version,
            self.samples.len(),
            self.pipeline_ids.len(),
            self.ref_len,
            total_sites
        ).into());

        Ok(())
    }

    /// Sort all data for binary search (called after loading)
    fn finalize(&mut self) {
        for sample_data in self.samples.values_mut() {
            for pipeline_data in sample_data.pipelines.values_mut() {
                pipeline_data.gaps.sort_by_key(|g| g.start);
                pipeline_data.snps.sort_by_key(|s| s.pos);
            }
        }
    }

    /// Get reference length
    #[wasm_bindgen]
    pub fn get_ref_length(&self) -> u32 {
        self.ref_len
    }

    /// Get reference name
    #[wasm_bindgen]
    pub fn get_ref_name(&self) -> String {
        self.ref_label.clone().unwrap_or_else(|| self.ref_name.clone())
    }

    /// Get all sample IDs as JSON array
    #[wasm_bindgen]
    pub fn get_sample_ids(&self) -> String {
        let mut ids: Vec<_> = self.samples.keys().cloned().collect();
        ids.sort();
        serde_json::to_string(&ids).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get display label for a sample
    #[wasm_bindgen]
    pub fn get_sample_label(&self, sample_id: &str) -> String {
        self.sample_labels.get(sample_id)
            .cloned()
            .unwrap_or_else(|| sample_id.to_string())
    }

    /// Get all pipeline IDs as JSON array
    #[wasm_bindgen]
    pub fn get_pipeline_ids(&self) -> String {
        serde_json::to_string(&self.pipeline_ids).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get display label for a pipeline
    #[wasm_bindgen]
    pub fn get_pipeline_label(&self, pipeline_id: &str) -> String {
        self.pipeline_labels.get(pipeline_id)
            .cloned()
            .unwrap_or_else(|| pipeline_id.to_string())
    }

    /// Get command for a pipeline (if any)
    #[wasm_bindgen]
    pub fn get_pipeline_command(&self, pipeline_id: &str) -> Option<String> {
        self.pipeline_commands.get(pipeline_id).cloned()
    }

    /// Get ground truth pipeline ID (if any)
    #[wasm_bindgen]
    pub fn get_ground_truth_pipeline(&self) -> Option<String> {
        self.ground_truth_pipeline.clone()
    }

    /// Check if a pipeline is the ground truth
    #[wasm_bindgen]
    pub fn is_ground_truth(&self, pipeline_id: &str) -> bool {
        self.ground_truth_pipeline.as_ref().map(|gt| gt == pipeline_id).unwrap_or(false)
    }

    /// Get pipelines that have VCF data (used for consensus/discordant)
    #[wasm_bindgen]
    pub fn get_vcf_pipelines(&self) -> String {
        let vcf_pipelines: Vec<&String> = self.pipeline_ids.iter()
            .filter(|p| {
                self.samples.values().any(|sd| {
                    sd.pipelines.get(*p)
                        .map(|pd| pd.has_vcf)
                        .unwrap_or(false)
                })
            })
            .collect();
        serde_json::to_string(&vcf_pipelines).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get report generation timestamp
    #[wasm_bindgen]
    pub fn get_generated_at(&self) -> String {
        self.generated_at.clone()
    }

    /// Get warnings as JSON array
    #[wasm_bindgen]
    pub fn get_warnings(&self) -> String {
        serde_json::to_string(&self.warnings).unwrap_or_else(|_| "[]".to_string())
    }

    /// Get SNPs in ground truth gaps statistics as JSON
    #[wasm_bindgen]
    pub fn get_snps_in_gt_gaps(&self) -> String {
        match &self.snps_in_gt_gaps {
            Some(stats) => serde_json::to_string(stats).unwrap_or_else(|_| "{}".to_string()),
            None => "null".to_string(),
        }
    }

    /// Get ground truth pileup statistics as JSON
    /// Returns: { total_snps, per_sample, covered_positions, pipeline_comparison }
    #[wasm_bindgen]
    pub fn get_ground_truth_pileup(&self) -> String {
        match &self.ground_truth_pileup {
            Some(stats) => serde_json::to_string(stats).unwrap_or_else(|_| "{}".to_string()),
            None => "null".to_string(),
        }
    }

    /// Get MNP (Multi-Nucleotide Polymorphism) statistics per pipeline
    /// Returns: { pipeline_id: { mnps_found, snps_from_mnps } }
    #[wasm_bindgen]
    pub fn get_mnp_stats(&self) -> String {
        match &self.mnp_stats {
            Some(stats) => serde_json::to_string(stats).unwrap_or_else(|_| "{}".to_string()),
            None => "null".to_string(),
        }
    }

    /// Get file paths for reproducibility (sample -> pipeline -> {vcf_path, bam_path})
    #[wasm_bindgen]
    pub fn get_file_paths(&self) -> String {
        let mut result: HashMap<String, HashMap<String, HashMap<String, String>>> = HashMap::new();

        for (sample_id, sample_data) in &self.samples {
            let mut sample_paths: HashMap<String, HashMap<String, String>> = HashMap::new();

            for (pipeline_id, pipeline_data) in &sample_data.pipelines {
                let mut paths: HashMap<String, String> = HashMap::new();
                if let Some(vcf) = &pipeline_data.vcf_path {
                    paths.insert("vcf".to_string(), vcf.clone());
                }
                if let Some(bam) = &pipeline_data.bam_path {
                    paths.insert("bam".to_string(), bam.clone());
                }
                if !paths.is_empty() {
                    sample_paths.insert(pipeline_id.clone(), paths);
                }
            }

            if !sample_paths.is_empty() {
                result.insert(sample_id.clone(), sample_paths);
            }
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get reference nucleotide at position (0-based index)
    #[wasm_bindgen]
    pub fn get_ref_nuc(&self, pos: u32) -> char {
        self.ref_seq.chars().nth(pos as usize).unwrap_or('N')
    }

    /// Check if position is in a gap for a sample/pipeline
    #[wasm_bindgen]
    pub fn is_gap(&self, sample: &str, pipeline: &str, pos: u32) -> bool {
        self.samples.get(sample)
            .and_then(|s| s.pipelines.get(pipeline))
            .map(|p| Self::pos_in_gaps(&p.gaps, pos))
            .unwrap_or(false)
    }

    /// Get SNP at position (returns "ref,alt,qual,depth" or empty string)
    #[wasm_bindgen]
    pub fn get_snp(&self, sample: &str, pipeline: &str, pos: u32) -> String {
        self.samples.get(sample)
            .and_then(|s| s.pipelines.get(pipeline))
            .and_then(|p| Self::find_snp(&p.snps, pos))
            .map(|s| format!("{},{},{},{}",
                s.ref_allele as char,
                s.alt_allele as char,
                s.qual,
                s.depth))
            .unwrap_or_default()
    }

    /// Get SNP alt allele at position (returns empty if no SNP)
    #[wasm_bindgen]
    pub fn get_snp_alt(&self, sample: &str, pipeline: &str, pos: u32) -> String {
        self.samples.get(sample)
            .and_then(|s| s.pipelines.get(pipeline))
            .and_then(|p| Self::find_snp(&p.snps, pos))
            .map(|s| (s.alt_allele as char).to_string())
            .unwrap_or_default()
    }

    /// Render HTML for a region
    #[wasm_bindgen]
    pub fn render_region(&self, samples_json: &str, start: u32, end: u32) -> String {
        let samples: Vec<String> = serde_json::from_str(samples_json).unwrap_or_default();
        let mut html = String::with_capacity(((end - start) as usize) * samples.len() * 50);

        // Reference row
        html.push_str("<div class=\"row\"><span class=\"lbl\">REF</span><span class=\"ref\">");
        for i in start..end {
            html.push(self.get_ref_nuc(i));
        }
        html.push_str("</span></div>");

        // Sample rows
        for sample in &samples {
            let sample_label = self.get_sample_label(sample);

            // Consensus row (reconstructed sequence using all pipelines)
            html.push_str(&format!("<div class=\"row\"><span class=\"lbl\">{}</span><span class=\"sample\">", sample_label));
            for i in start..end {
                let pos = i + 1; // 1-based for SNP lookup

                // Check if any pipeline has a gap at this position
                let in_gap = self.pipeline_ids.iter().any(|p| self.is_gap(sample, p, pos));

                if in_gap {
                    html.push_str("<span class=\"gap\">-</span>");
                } else {
                    // Collect all SNP alts from different pipelines
                    let alts: Vec<char> = self.pipeline_ids.iter()
                        .filter_map(|p| {
                            let alt = self.get_snp_alt(sample, p, pos);
                            if !alt.is_empty() {
                                alt.chars().next()
                            } else {
                                None
                            }
                        })
                        .collect();

                    if alts.is_empty() {
                        html.push(self.get_ref_nuc(i));
                    } else if alts.len() == 1 {
                        // Only one pipeline has a SNP
                        html.push_str(&format!("<span class=\"snp-uncertain\">{}</span>", alts[0]));
                    } else if alts.iter().all(|&a| a == alts[0]) {
                        // All pipelines agree
                        html.push_str(&format!("<span class=\"snp-consensus\">{}</span>", alts[0]));
                    } else {
                        // Pipelines disagree
                        html.push_str(&format!("<span class=\"snp-discord\">{}</span>", self.get_ref_nuc(i)));
                    }
                }
            }
            html.push_str("</span></div>");

            // Pipeline-specific rows
            // Skip ground truth pipeline (it's used for the sample row above)
            for pipeline_id in &self.pipeline_ids {
                // Skip ground truth pipeline - its data is shown in the sample row
                if let Some(ref gt) = self.ground_truth_pipeline {
                    if pipeline_id == gt {
                        continue;
                    }
                }

                let pipeline_label = self.get_pipeline_label(pipeline_id);
                html.push_str(&format!("<div class=\"row\"><span class=\"lbl sub\">{}</span><span class=\"sample\">", pipeline_label));

                for i in start..end {
                    let pos = i + 1;
                    let alt = self.get_snp_alt(sample, pipeline_id, pos);

                    if !alt.is_empty() {
                        html.push_str(&format!("<span class=\"snp-pipeline\">{}</span>", alt));
                    } else if self.is_gap(sample, pipeline_id, pos) {
                        html.push_str("<span class=\"gap\">-</span>");
                    } else {
                        html.push_str("<span class=\"dim\">.</span>");
                    }
                }
                html.push_str("</span></div>");
            }
        }

        html
    }

    /// Get KPI summary as JSON
    #[wasm_bindgen]
    pub fn get_kpis(&self) -> String {
        let mut total_snps: HashMap<String, u32> = HashMap::new();
        let mut total_gaps: HashMap<String, u32> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut snp_count = 0u32;
            let mut gap_bases = 0u32;

            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    snp_count += pipeline_data.snps.len() as u32;
                    gap_bases += pipeline_data.gaps.iter()
                        .map(|g| g.end - g.start)
                        .sum::<u32>();
                }
            }

            total_snps.insert(pipeline_id.clone(), snp_count);
            total_gaps.insert(pipeline_id.clone(), gap_bases);
        }

        // Calculate core SNPs per pipeline (positions present in ALL samples)
        // Store both counts and position sets for GT comparison
        let mut core_snps: HashMap<String, u32> = HashMap::new();
        let mut core_positions: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut sample_positions: Vec<std::collections::HashSet<u32>> = Vec::new();

            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    let positions: std::collections::HashSet<u32> = pipeline_data.snps.iter()
                        .map(|s| s.pos)
                        .collect();
                    sample_positions.push(positions);
                }
            }

            // Intersection of all samples = core SNPs
            let core_set = if sample_positions.len() > 1 {
                let mut core = sample_positions[0].clone();
                for positions in &sample_positions[1..] {
                    core = core.intersection(positions).cloned().collect();
                }
                core
            } else if sample_positions.len() == 1 {
                sample_positions[0].clone()
            } else {
                std::collections::HashSet::new()
            };

            core_snps.insert(pipeline_id.clone(), core_set.len() as u32);
            core_positions.insert(pipeline_id.clone(), core_set);
        }

        // Calculate consensus SNPs per pipeline
        // Consensus = positions where ALL samples have the SAME alt allele
        let mut consensus_snps: HashMap<String, u32> = HashMap::new();
        let mut consensus_positions: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            // For each position in core, check if all samples have the same alt
            let core_pos = core_positions.get(pipeline_id).cloned().unwrap_or_default();
            let mut consensus_set: std::collections::HashSet<u32> = std::collections::HashSet::new();

            for &pos in &core_pos {
                // Get alt allele for each sample at this position
                let mut alts: Vec<u8> = Vec::new();
                let mut all_have_snp = true;

                for sample_data in self.samples.values() {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                            alts.push(snp.alt_allele);
                        } else {
                            all_have_snp = false;
                            break;
                        }
                    } else {
                        all_have_snp = false;
                        break;
                    }
                }

                // Check if all samples have the same alt
                if all_have_snp && !alts.is_empty() && alts.iter().all(|&a| a == alts[0]) {
                    consensus_set.insert(pos);
                }
            }

            consensus_snps.insert(pipeline_id.clone(), consensus_set.len() as u32);
            consensus_positions.insert(pipeline_id.clone(), consensus_set);
        }

        // Calculate GT SNPs missing per pipeline
        // For each pipeline: sum across samples of (GT SNPs not called by pipeline)
        let mut gt_snps_missing: HashMap<String, u32> = HashMap::new();
        let mut gt_snps_called: HashMap<String, u32> = HashMap::new();
        let mut gt_total_snps: u32 = 0;

        // Core GT missing and Consensus GT missing
        let mut core_gt_missing: HashMap<String, u32> = HashMap::new();
        let mut core_gt_total: u32 = 0;
        let mut consensus_gt_missing: HashMap<String, u32> = HashMap::new();
        let mut consensus_gt_total: u32 = 0;

        if let Some(ref gt_id) = self.ground_truth_pipeline {
            // First calculate total GT SNPs
            for sample_data in self.samples.values() {
                if let Some(gt_data) = sample_data.pipelines.get(gt_id) {
                    gt_total_snps += gt_data.snps.len() as u32;
                }
            }

            // Get Core GT and Consensus GT
            let gt_core = core_positions.get(gt_id).cloned().unwrap_or_default();
            let gt_consensus = consensus_positions.get(gt_id).cloned().unwrap_or_default();
            core_gt_total = gt_core.len() as u32;
            consensus_gt_total = gt_consensus.len() as u32;

            // For each non-GT pipeline, calculate missing GT SNPs
            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_id {
                    continue;
                }

                let mut missing = 0u32;
                let mut called = 0u32;

                for sample_data in self.samples.values() {
                    // Get GT SNP positions for this sample
                    let gt_positions: std::collections::HashSet<u32> = sample_data
                        .pipelines.get(gt_id)
                        .map(|p| p.snps.iter().map(|s| s.pos).collect())
                        .unwrap_or_default();

                    // Get pipeline SNP positions for this sample
                    let pipeline_positions: std::collections::HashSet<u32> = sample_data
                        .pipelines.get(pipeline_id)
                        .map(|p| p.snps.iter().map(|s| s.pos).collect())
                        .unwrap_or_default();

                    // GT ∩ Pipeline = GT positions that pipeline also calls
                    let intersection = gt_positions.intersection(&pipeline_positions).count() as u32;
                    called += intersection;

                    // GT SNPs not in pipeline = |GT| - |GT ∩ Pipeline|
                    missing += gt_positions.len() as u32 - intersection;
                }

                gt_snps_missing.insert(pipeline_id.clone(), missing);
                gt_snps_called.insert(pipeline_id.clone(), called);

                // Core GT missing: |Core GT| - |Core GT ∩ Core Pipeline|
                let pipeline_core = core_positions.get(pipeline_id).cloned().unwrap_or_default();
                let core_intersection = gt_core.intersection(&pipeline_core).count() as u32;
                core_gt_missing.insert(pipeline_id.clone(), core_gt_total - core_intersection);

                // Consensus GT missing: |Consensus GT| - |Consensus GT ∩ Consensus Pipeline|
                let pipeline_consensus = consensus_positions.get(pipeline_id).cloned().unwrap_or_default();
                let consensus_intersection = gt_consensus.intersection(&pipeline_consensus).count() as u32;
                consensus_gt_missing.insert(pipeline_id.clone(), consensus_gt_total - consensus_intersection);
            }
        }

        // Calculate SNPs in GT gaps for total, core, and consensus
        let mut snps_in_gt_gaps_total: HashMap<String, u32> = HashMap::new();
        let mut snps_in_gt_gaps_core: HashMap<String, u32> = HashMap::new();
        let mut snps_in_gt_gaps_consensus: HashMap<String, u32> = HashMap::new();

        if let Some(ref gt_id) = self.ground_truth_pipeline {
            // Collect all GT gap regions across all samples
            let mut all_gt_gaps: Vec<(u32, u32)> = Vec::new();
            for sample_data in self.samples.values() {
                if let Some(gt_data) = sample_data.pipelines.get(gt_id) {
                    for gap in &gt_data.gaps {
                        all_gt_gaps.push((gap.start, gap.end));
                    }
                }
            }

            // Helper to check if position is in any GT gap
            let in_gt_gap = |pos: u32| -> bool {
                all_gt_gaps.iter().any(|(start, end)| pos >= *start && pos < *end)
            };

            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_id {
                    continue;
                }

                // Total SNPs in GT gaps (sum across samples)
                let mut total_in_gaps = 0u32;
                for sample_data in self.samples.values() {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        // Get GT gaps for this sample
                        let sample_gt_gaps: Vec<(u32, u32)> = sample_data.pipelines.get(gt_id)
                            .map(|p| p.gaps.iter().map(|g| (g.start, g.end)).collect())
                            .unwrap_or_default();

                        total_in_gaps += pipeline_data.snps.iter()
                            .filter(|snp| sample_gt_gaps.iter().any(|(s, e)| snp.pos >= *s && snp.pos < *e))
                            .count() as u32;
                    }
                }
                snps_in_gt_gaps_total.insert(pipeline_id.clone(), total_in_gaps);

                // Core SNPs in GT gaps
                let pipeline_core = core_positions.get(pipeline_id).cloned().unwrap_or_default();
                let core_in_gaps = pipeline_core.iter()
                    .filter(|&&pos| in_gt_gap(pos))
                    .count() as u32;
                snps_in_gt_gaps_core.insert(pipeline_id.clone(), core_in_gaps);

                // Consensus SNPs in GT gaps
                let pipeline_cons = consensus_positions.get(pipeline_id).cloned().unwrap_or_default();
                let cons_in_gaps = pipeline_cons.iter()
                    .filter(|&&pos| in_gt_gap(pos))
                    .count() as u32;
                snps_in_gt_gaps_consensus.insert(pipeline_id.clone(), cons_in_gaps);
            }
        }

        #[derive(Serialize)]
        struct Kpis {
            snps: HashMap<String, u32>,
            gaps: HashMap<String, u32>,
            core_snps: HashMap<String, u32>,
            consensus_snps: HashMap<String, u32>,
            gt_snps_missing: HashMap<String, u32>,
            gt_snps_called: HashMap<String, u32>,
            gt_total_snps: u32,
            core_gt_missing: HashMap<String, u32>,
            core_gt_total: u32,
            consensus_gt_missing: HashMap<String, u32>,
            consensus_gt_total: u32,
            snps_in_gt_gaps_total: HashMap<String, u32>,
            snps_in_gt_gaps_core: HashMap<String, u32>,
            snps_in_gt_gaps_consensus: HashMap<String, u32>,
            samples: usize,
            pipelines: usize,
            ref_length: u32,
        }

        let kpis = Kpis {
            snps: total_snps,
            gaps: total_gaps,
            core_snps,
            consensus_snps,
            gt_snps_missing,
            gt_snps_called,
            gt_total_snps,
            core_gt_missing,
            core_gt_total,
            consensus_gt_missing,
            consensus_gt_total,
            snps_in_gt_gaps_total,
            snps_in_gt_gaps_core,
            snps_in_gt_gaps_consensus,
            samples: self.samples.len(),
            pipelines: self.pipeline_ids.len(),
            ref_length: self.ref_len,
        };

        serde_json::to_string(&kpis).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get per-sample statistics as JSON
    /// Returns: { sample_id: { pipeline_id: { snps, snps_in_gt_gaps, agreement_with_gt, ... } } }
    #[wasm_bindgen]
    pub fn get_per_sample_stats(&self) -> String {
        #[derive(Serialize)]
        struct PipelineStats {
            snps: u32,
            gap_bp: u32,
            snps_in_gt_gaps: u32,
            snps_in_gt_gaps_pct: f64,
            agreement_with_gt: u32,
            agreement_with_gt_pct: f64,
        }

        #[derive(Serialize)]
        struct SampleStats {
            pipelines: HashMap<String, PipelineStats>,
        }

        let mut result: HashMap<String, SampleStats> = HashMap::new();

        // Find ground truth pipeline
        let gt_pipeline = self.pipeline_ids.iter()
            .find(|p| self.ground_truth_pipeline.as_ref() == Some(*p))
            .cloned();

        for (sample_id, sample_data) in &self.samples {
            let mut pipelines_stats: HashMap<String, PipelineStats> = HashMap::new();

            // Get GT SNP positions for this sample (for comparison)
            let gt_snp_positions: std::collections::HashSet<u32> = if let Some(ref gt_id) = gt_pipeline {
                sample_data.pipelines.get(gt_id)
                    .map(|p| p.snps.iter().map(|s| s.pos).collect())
                    .unwrap_or_default()
            } else {
                std::collections::HashSet::new()
            };

            // Get GT gap regions for this sample
            let gt_gaps: Vec<&GapRegion> = if let Some(ref gt_id) = gt_pipeline {
                sample_data.pipelines.get(gt_id)
                    .map(|p| p.gaps.iter().collect())
                    .unwrap_or_default()
            } else {
                Vec::new()
            };

            for pipeline_id in &self.pipeline_ids {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    let snps = pipeline_data.snps.len() as u32;
                    let gap_bp: u32 = pipeline_data.gaps.iter()
                        .map(|g| g.end - g.start)
                        .sum();

                    // Count SNPs in GT gaps
                    let snps_in_gt_gaps: u32 = if gt_pipeline.is_some() && gt_pipeline.as_ref() != Some(pipeline_id) {
                        pipeline_data.snps.iter()
                            .filter(|snp| {
                                gt_gaps.iter().any(|g| snp.pos >= g.start && snp.pos < g.end)
                            })
                            .count() as u32
                    } else {
                        0
                    };

                    let snps_in_gt_gaps_pct = if snps > 0 {
                        (snps_in_gt_gaps as f64 / snps as f64) * 100.0
                    } else {
                        0.0
                    };

                    // Count agreement with GT (SNPs at same position)
                    let agreement_with_gt: u32 = if gt_pipeline.is_some() && gt_pipeline.as_ref() != Some(pipeline_id) {
                        pipeline_data.snps.iter()
                            .filter(|snp| gt_snp_positions.contains(&snp.pos))
                            .count() as u32
                    } else {
                        0
                    };

                    let agreement_with_gt_pct = if !gt_snp_positions.is_empty() && gt_pipeline.as_ref() != Some(pipeline_id) {
                        (agreement_with_gt as f64 / gt_snp_positions.len() as f64) * 100.0
                    } else if gt_pipeline.as_ref() == Some(pipeline_id) {
                        100.0
                    } else {
                        0.0
                    };

                    pipelines_stats.insert(pipeline_id.clone(), PipelineStats {
                        snps,
                        gap_bp,
                        snps_in_gt_gaps,
                        snps_in_gt_gaps_pct,
                        agreement_with_gt,
                        agreement_with_gt_pct,
                    });
                }
            }

            result.insert(sample_id.clone(), SampleStats {
                pipelines: pipelines_stats,
            });
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get SNP intersection statistics between pipelines
    /// Returns: { pipeline_a: { pipeline_b: { intersection, pct_of_a, pct_of_b } } }
    #[wasm_bindgen]
    pub fn get_snp_intersection(&self) -> String {
        #[derive(Serialize)]
        struct IntersectionStats {
            intersection: u32,
            total_a: u32,
            total_b: u32,
            pct_of_a: f64,
            pct_of_b: f64,
        }

        let mut result: HashMap<String, HashMap<String, IntersectionStats>> = HashMap::new();

        // Collect all SNP positions per pipeline (across all samples)
        let mut pipeline_snps: HashMap<String, std::collections::HashSet<u32>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut positions: std::collections::HashSet<u32> = std::collections::HashSet::new();
            for sample_data in self.samples.values() {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    for snp in &pipeline_data.snps {
                        positions.insert(snp.pos);
                    }
                }
            }
            pipeline_snps.insert(pipeline_id.clone(), positions);
        }

        // Calculate intersection between all pairs
        for pipeline_a in &self.pipeline_ids {
            let mut inner: HashMap<String, IntersectionStats> = HashMap::new();
            let snps_a = pipeline_snps.get(pipeline_a).unwrap();
            let total_a = snps_a.len() as u32;

            for pipeline_b in &self.pipeline_ids {
                if pipeline_a == pipeline_b {
                    continue;
                }

                let snps_b = pipeline_snps.get(pipeline_b).unwrap();
                let total_b = snps_b.len() as u32;

                let intersection = snps_a.intersection(snps_b).count() as u32;

                let pct_of_a = if total_a > 0 {
                    (intersection as f64 / total_a as f64) * 100.0
                } else {
                    0.0
                };

                let pct_of_b = if total_b > 0 {
                    (intersection as f64 / total_b as f64) * 100.0
                } else {
                    0.0
                };

                inner.insert(pipeline_b.clone(), IntersectionStats {
                    intersection,
                    total_a,
                    total_b,
                    pct_of_a,
                    pct_of_b,
                });
            }

            result.insert(pipeline_a.clone(), inner);
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get detailed pipeline concordance statistics
    /// Returns 4 metrics for each pipeline pair:
    /// - concordance_any: positions where at least 1 sample has SNP in both pipelines
    /// - concordance_all: positions where ALL samples have SNP in both pipelines
    /// - consensus_any: positions where at least 1 sample has same allele in both pipelines
    /// - consensus_all: positions where ALL samples have same allele in both pipelines
    #[wasm_bindgen]
    pub fn get_pipeline_concordance(&self) -> String {
        #[derive(Serialize)]
        struct ConcordanceStats {
            concordance_any: u32,
            concordance_all: u32,
            consensus_any: u32,
            consensus_all: u32,
            total_a: u32,
            total_b: u32,
        }

        let mut result: HashMap<String, HashMap<String, ConcordanceStats>> = HashMap::new();
        let num_samples = self.samples.len();

        // For each pipeline, collect per-sample SNP data: position -> (sample_id -> alt_allele)
        let mut pipeline_sample_snps: HashMap<String, HashMap<u32, HashMap<String, u8>>> = HashMap::new();

        for pipeline_id in &self.pipeline_ids {
            let mut pos_to_samples: HashMap<u32, HashMap<String, u8>> = HashMap::new();
            for (sample_id, sample_data) in &self.samples {
                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    for snp in &pipeline_data.snps {
                        pos_to_samples
                            .entry(snp.pos)
                            .or_insert_with(HashMap::new)
                            .insert(sample_id.clone(), snp.alt_allele);
                    }
                }
            }
            pipeline_sample_snps.insert(pipeline_id.clone(), pos_to_samples);
        }

        // Calculate concordance between all pairs
        for pipeline_a in &self.pipeline_ids {
            let mut inner: HashMap<String, ConcordanceStats> = HashMap::new();
            let snps_a = pipeline_sample_snps.get(pipeline_a).unwrap();
            let total_a = snps_a.len() as u32;

            for pipeline_b in &self.pipeline_ids {
                if pipeline_a >= pipeline_b {
                    continue; // Only compute each pair once (avoid duplicates)
                }

                let snps_b = pipeline_sample_snps.get(pipeline_b).unwrap();
                let total_b = snps_b.len() as u32;

                let mut concordance_any = 0u32;
                let mut concordance_all = 0u32;
                let mut consensus_any = 0u32;
                let mut consensus_all = 0u32;

                // Get all positions present in either pipeline
                let all_positions: std::collections::HashSet<u32> =
                    snps_a.keys().chain(snps_b.keys()).cloned().collect();

                for pos in all_positions {
                    let samples_a = snps_a.get(&pos);
                    let samples_b = snps_b.get(&pos);

                    match (samples_a, samples_b) {
                        (Some(sa), Some(sb)) => {
                            // Count samples that have SNP in BOTH pipelines at this position
                            let mut samples_with_both = 0;
                            let mut any_same_allele = false;
                            let mut all_same_allele = true;

                            for (sample_id, alt_a) in sa {
                                if let Some(alt_b) = sb.get(sample_id) {
                                    samples_with_both += 1;
                                    if alt_a == alt_b {
                                        any_same_allele = true;
                                    } else {
                                        all_same_allele = false;
                                    }
                                }
                            }

                            // concordance_any: at least 1 sample has SNP in BOTH pipelines
                            if samples_with_both > 0 {
                                concordance_any += 1;
                            }

                            // concordance_all: ALL samples have SNP in BOTH pipelines
                            if samples_with_both == num_samples {
                                concordance_all += 1;
                            }

                            // consensus_any: at least 1 sample has SAME allele in both
                            if any_same_allele {
                                consensus_any += 1;
                            }

                            // consensus_all: ALL samples have SAME allele in both pipelines
                            if samples_with_both == num_samples && all_same_allele {
                                consensus_all += 1;
                            }
                        }
                        _ => {}
                    }
                }

                inner.insert(pipeline_b.clone(), ConcordanceStats {
                    concordance_any,
                    concordance_all,
                    consensus_any,
                    consensus_all,
                    total_a,
                    total_b,
                });
            }

            if !inner.is_empty() {
                result.insert(pipeline_a.clone(), inner);
            }
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get per-sample SNP intersection with GT
    /// Returns: { sample_id: { pipeline_id: { intersection, pipeline_snps, gt_snps, pct_of_pipeline, pct_of_gt } } }
    #[wasm_bindgen]
    pub fn get_per_sample_intersection_with_gt(&self) -> String {
        #[derive(Serialize)]
        struct SampleIntersection {
            intersection: u32,
            pipeline_snps: u32,
            gt_snps: u32,
            pct_of_pipeline: f64,
            pct_of_gt: f64,
        }

        let mut result: HashMap<String, HashMap<String, SampleIntersection>> = HashMap::new();

        let gt_pipeline = match &self.ground_truth_pipeline {
            Some(gt) => gt,
            None => return "{}".to_string(),
        };

        for (sample_id, sample_data) in &self.samples {
            let mut sample_intersections: HashMap<String, SampleIntersection> = HashMap::new();

            // Get GT SNPs for this sample
            let gt_snps: std::collections::HashSet<u32> = sample_data.pipelines.get(gt_pipeline)
                .map(|pd| pd.snps.iter().map(|s| s.pos).collect())
                .unwrap_or_default();
            let gt_count = gt_snps.len() as u32;

            // Calculate intersection with each non-GT pipeline
            for pipeline_id in &self.pipeline_ids {
                if pipeline_id == gt_pipeline {
                    continue;
                }

                if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                    let pipeline_snps: std::collections::HashSet<u32> = pipeline_data.snps.iter()
                        .map(|s| s.pos)
                        .collect();
                    let pipeline_count = pipeline_snps.len() as u32;

                    let intersection = pipeline_snps.intersection(&gt_snps).count() as u32;

                    let pct_of_pipeline = if pipeline_count > 0 {
                        (intersection as f64 / pipeline_count as f64) * 100.0
                    } else {
                        0.0
                    };

                    let pct_of_gt = if gt_count > 0 {
                        (intersection as f64 / gt_count as f64) * 100.0
                    } else {
                        0.0
                    };

                    sample_intersections.insert(pipeline_id.clone(), SampleIntersection {
                        intersection,
                        pipeline_snps: pipeline_count,
                        gt_snps: gt_count,
                        pct_of_pipeline,
                        pct_of_gt,
                    });
                }
            }

            result.insert(sample_id.clone(), sample_intersections);
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get consensus SNP statistics (positions where ALL VCF pipelines agree)
    /// Returns global and per-sample consensus vs GT comparison
    #[wasm_bindgen]
    pub fn get_consensus_stats(&self) -> String {
        #[derive(Serialize)]
        struct ConsensusVsGt {
            consensus_snps: u32,
            gt_snps: u32,
            consensus_in_gt: u32,
            consensus_in_gt_pct: f64,
            gt_in_consensus: u32,
            gt_in_consensus_pct: f64,
        }

        #[derive(Serialize)]
        struct SampleConsensusStats {
            vcf_consensus: ConsensusVsGt,
            all_consensus: u32,  // GT ∩ all VCF pipelines
        }

        #[derive(Serialize)]
        struct ConsensusStats {
            global: ConsensusVsGt,
            global_all: u32,  // Total positions where ALL pipelines (including GT) agree
            per_sample: HashMap<String, SampleConsensusStats>,
        }

        // Get VCF pipelines (pipelines that have SNP data)
        let vcf_pipelines: Vec<&String> = self.pipeline_ids.iter()
            .filter(|p| {
                self.samples.values().any(|s| {
                    s.pipelines.get(*p).map(|pd| pd.has_vcf).unwrap_or(false)
                })
            })
            .collect();

        // Find ground truth pipeline
        let gt_pipeline = self.ground_truth_pipeline.as_ref();

        // Use sums instead of unique positions to be consistent with other KPIs
        let mut sum_consensus_snps: u32 = 0;
        let mut sum_gt_snps: u32 = 0;
        let mut sum_consensus_in_gt: u32 = 0;
        let mut sum_all_consensus: u32 = 0;
        let mut per_sample_stats: HashMap<String, SampleConsensusStats> = HashMap::new();

        // Calculate per-sample consensus
        for (sample_id, sample_data) in &self.samples {
            // Get SNP positions for each VCF pipeline in this sample
            let mut pipeline_positions: Vec<std::collections::HashSet<u32>> = Vec::new();

            for pipeline_id in &vcf_pipelines {
                if let Some(pipeline_data) = sample_data.pipelines.get(*pipeline_id) {
                    let positions: std::collections::HashSet<u32> = pipeline_data.snps.iter()
                        .map(|s| s.pos)
                        .collect();
                    pipeline_positions.push(positions);
                }
            }

            // VCF Consensus = intersection of all VCF pipelines (excluding GT)
            let sample_vcf_consensus: std::collections::HashSet<u32> = if pipeline_positions.len() > 1 {
                let mut consensus = pipeline_positions[0].clone();
                for positions in &pipeline_positions[1..] {
                    consensus = consensus.intersection(positions).cloned().collect();
                }
                consensus
            } else if pipeline_positions.len() == 1 {
                pipeline_positions[0].clone()
            } else {
                std::collections::HashSet::new()
            };

            // Get GT SNPs for this sample
            let sample_gt: std::collections::HashSet<u32> = if let Some(gt_id) = gt_pipeline {
                sample_data.pipelines.get(gt_id)
                    .map(|pd| pd.snps.iter().map(|s| s.pos).collect())
                    .unwrap_or_default()
            } else {
                std::collections::HashSet::new()
            };

            // ALL Consensus = GT ∩ all VCF pipelines
            let sample_all_consensus: std::collections::HashSet<u32> =
                sample_vcf_consensus.intersection(&sample_gt).cloned().collect();

            // Calculate sample stats
            let consensus_in_gt = sample_vcf_consensus.intersection(&sample_gt).count() as u32;
            let gt_in_consensus = sample_gt.intersection(&sample_vcf_consensus).count() as u32;

            let consensus_snps = sample_vcf_consensus.len() as u32;
            let gt_snps = sample_gt.len() as u32;
            let all_consensus = sample_all_consensus.len() as u32;

            // Add to sums (consistent with other KPIs that sum across samples)
            sum_consensus_snps += consensus_snps;
            sum_gt_snps += gt_snps;
            sum_consensus_in_gt += consensus_in_gt;
            sum_all_consensus += all_consensus;

            per_sample_stats.insert(sample_id.clone(), SampleConsensusStats {
                vcf_consensus: ConsensusVsGt {
                    consensus_snps,
                    gt_snps,
                    consensus_in_gt,
                    consensus_in_gt_pct: if consensus_snps > 0 {
                        (consensus_in_gt as f64 / consensus_snps as f64) * 100.0
                    } else { 0.0 },
                    gt_in_consensus,
                    gt_in_consensus_pct: if gt_snps > 0 {
                        (gt_in_consensus as f64 / gt_snps as f64) * 100.0
                    } else { 0.0 },
                },
                all_consensus,
            });
        }

        // Calculate global stats using SUMS (consistent with other KPIs)
        let result = ConsensusStats {
            global: ConsensusVsGt {
                consensus_snps: sum_consensus_snps,
                gt_snps: sum_gt_snps,
                consensus_in_gt: sum_consensus_in_gt,
                consensus_in_gt_pct: if sum_consensus_snps > 0 {
                    (sum_consensus_in_gt as f64 / sum_consensus_snps as f64) * 100.0
                } else { 0.0 },
                gt_in_consensus: sum_consensus_in_gt,  // Same as consensus_in_gt when using sums
                gt_in_consensus_pct: if sum_gt_snps > 0 {
                    (sum_consensus_in_gt as f64 / sum_gt_snps as f64) * 100.0
                } else { 0.0 },
            },
            global_all: sum_all_consensus,
            per_sample: per_sample_stats,
        };

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Get all SNP positions that match the given filters
    /// filters: comma-separated list of pipeline IDs, or special filters:
    /// - "consensus": positions where all pipelines agree
    /// - "discordant": positions where pipelines disagree
    /// - "exclusive:<pipeline>": positions only in that pipeline
    /// - "gaps:<pipeline>": positions where pipeline has a gap
    /// filter_mode: "and" (all filters must match) or "or" (any filter matches)
    /// sample_mode: "any" (at least one sample) or "all" (all samples)
    #[wasm_bindgen]
    pub fn get_filtered_positions_v2(
        &self,
        samples_json: &str,
        filters: &str,
        filter_mode: &str,
        sample_mode: &str,
    ) -> String {
        let samples: Vec<String> = serde_json::from_str(samples_json).unwrap_or_default();
        let filter_parts: Vec<&str> = filters.split(',').filter(|f| !f.is_empty()).collect();
        let use_or = filter_mode == "or";
        let require_all_samples = sample_mode == "all";

        // Check if we have any gap filters
        let gap_filters: Vec<&str> = filter_parts.iter()
            .filter(|f| f.starts_with("gaps:"))
            .map(|f| &f[5..])
            .collect();

        let mut positions: std::collections::HashSet<u32> = std::collections::HashSet::new();

        // Collect all SNP positions
        for sample in &samples {
            if let Some(sample_data) = self.samples.get(sample) {
                for pipeline_data in sample_data.pipelines.values() {
                    for snp in &pipeline_data.snps {
                        positions.insert(snp.pos);
                    }
                }
            }
        }

        // If gap filters are active, also collect gap positions
        if !gap_filters.is_empty() {
            for sample in &samples {
                if let Some(sample_data) = self.samples.get(sample) {
                    for gap_pipeline in &gap_filters {
                        if let Some(pipeline_data) = sample_data.pipelines.get(*gap_pipeline) {
                            for gap in &pipeline_data.gaps {
                                for pos in gap.start..gap.end.min(gap.start + 1000) {
                                    positions.insert(pos);
                                }
                            }
                        }
                    }
                }
            }
        }

        // If no filters, return all positions
        if filter_parts.is_empty() {
            let mut sorted: Vec<u32> = positions.into_iter().collect();
            sorted.sort();
            return serde_json::to_string(&sorted).unwrap_or_else(|_| "[]".to_string());
        }

        // Extract pipeline filters (those that are not special filters)
        let pipeline_filters: Vec<&str> = filter_parts.iter()
            .filter(|f| {
                !f.starts_with("gaps:") &&
                !f.starts_with("exclusive:") &&
                **f != "consensus" &&
                **f != "discordant"
            })
            .copied()
            .collect();

        // Apply filters
        let filtered: Vec<u32> = positions.into_iter().filter(|&pos| {
            // For each filter, check if it matches
            let filter_results: Vec<bool> = filter_parts.iter().map(|filter| {
                self.check_filter_at_pos(&samples, pos, filter, require_all_samples, &pipeline_filters)
            }).collect();

            // Combine results based on filter mode
            if use_or {
                filter_results.iter().any(|&r| r)
            } else {
                filter_results.iter().all(|&r| r)
            }
        }).collect();

        let mut sorted = filtered;
        sorted.sort();
        serde_json::to_string(&sorted).unwrap_or_else(|_| "[]".to_string())
    }

    /// Check if a single filter matches at a position
    /// pipeline_scope: if not empty, consensus/discordant only consider these pipelines
    fn check_filter_at_pos(&self, samples: &[String], pos: u32, filter: &str, require_all_samples: bool, pipeline_scope: &[&str]) -> bool {
        if filter == "consensus" {
            return self.check_consensus(samples, pos, pipeline_scope);
        } else if filter == "discordant" {
            return self.check_discordant(samples, pos, pipeline_scope);
        } else if filter.starts_with("exclusive:") {
            let target = &filter[10..];
            return self.check_exclusive(samples, pos, target);
        } else if filter.starts_with("gaps:") {
            let target_pipeline = &filter[5..];
            return self.check_gap(samples, pos, target_pipeline, require_all_samples);
        } else {
            // Regular pipeline SNP filter
            return self.check_snp_in_pipeline(samples, pos, filter, require_all_samples);
        }
    }

    /// Check if position has consensus (all pipelines with VCF agree)
    ///
    /// For each sample, ALL pipelines in scope that have VCF data must have called a SNP
    /// at this position, and all calls must agree on the same allele.
    /// pipeline_scope: if not empty, only consider these pipelines; otherwise use all VCF pipelines
    fn check_consensus(&self, samples: &[String], pos: u32, pipeline_scope: &[&str]) -> bool {
        // Get pipelines to check: either scoped or all VCF pipelines
        let vcf_pipelines: Vec<&String> = if pipeline_scope.is_empty() {
            // No scope - use all VCF pipelines
            self.pipeline_ids.iter()
                .filter(|p| {
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        } else {
            // Use only scoped pipelines that have VCF
            self.pipeline_ids.iter()
                .filter(|p| {
                    pipeline_scope.contains(&p.as_str()) &&
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        };

        // Need at least 2 VCF pipelines to check consensus
        if vcf_pipelines.len() < 2 {
            return false;
        }

        // For each sample, check if ALL VCF pipelines have a SNP and they agree
        for sample in samples {
            let mut sample_alts: Vec<char> = Vec::new();
            let mut all_have_snp = true;

            for pipeline_id in &vcf_pipelines {
                if let Some(sample_data) = self.samples.get(sample) {
                    if let Some(pipeline_data) = sample_data.pipelines.get(*pipeline_id) {
                        if pipeline_data.has_vcf {
                            if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                                sample_alts.push(snp.alt_allele as char);
                            } else {
                                all_have_snp = false;
                                break;
                            }
                        }
                    }
                }
            }

            // If all VCF pipelines have SNP for this sample and they agree, it's consensus
            if all_have_snp && sample_alts.len() >= 2 {
                let first = sample_alts[0];
                if sample_alts.iter().all(|&a| a == first) {
                    return true;  // Found consensus for at least one sample
                }
            }
        }

        false
    }

    /// Check if position has discordance (pipelines disagree)
    ///
    /// For at least one sample, multiple pipelines in scope with VCF must have called
    /// different SNPs at this position.
    /// pipeline_scope: if not empty, only consider these pipelines; otherwise use all VCF pipelines
    fn check_discordant(&self, samples: &[String], pos: u32, pipeline_scope: &[&str]) -> bool {
        // Get pipelines to check: either scoped or all VCF pipelines
        let vcf_pipelines: Vec<&String> = if pipeline_scope.is_empty() {
            self.pipeline_ids.iter()
                .filter(|p| {
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        } else {
            self.pipeline_ids.iter()
                .filter(|p| {
                    pipeline_scope.contains(&p.as_str()) &&
                    samples.iter().any(|s| {
                        self.samples.get(s)
                            .and_then(|sd| sd.pipelines.get(*p))
                            .map(|pd| pd.has_vcf)
                            .unwrap_or(false)
                    })
                })
                .collect()
        };

        if vcf_pipelines.len() < 2 {
            return false;
        }

        // For each sample, check if pipelines disagree
        for sample in samples {
            let mut sample_alts: Vec<char> = Vec::new();

            for pipeline_id in &vcf_pipelines {
                if let Some(sample_data) = self.samples.get(sample) {
                    if let Some(pipeline_data) = sample_data.pipelines.get(*pipeline_id) {
                        if pipeline_data.has_vcf {
                            if let Some(snp) = Self::find_snp(&pipeline_data.snps, pos) {
                                sample_alts.push(snp.alt_allele as char);
                            }
                        }
                    }
                }
            }

            // If at least 2 pipelines have SNPs for this sample and they disagree
            if sample_alts.len() >= 2 {
                let first = sample_alts[0];
                if !sample_alts.iter().all(|&a| a == first) {
                    return true;  // Found discordance for at least one sample
                }
            }
        }

        false
    }

    /// Check if position is exclusive to one pipeline
    fn check_exclusive(&self, samples: &[String], pos: u32, target: &str) -> bool {
        let mut found_in_target = false;
        let mut found_in_other = false;

        for pipeline_id in &self.pipeline_ids {
            for sample in samples {
                if let Some(sample_data) = self.samples.get(sample) {
                    if let Some(pipeline_data) = sample_data.pipelines.get(pipeline_id) {
                        if Self::find_snp(&pipeline_data.snps, pos).is_some() {
                            if pipeline_id == target {
                                found_in_target = true;
                            } else {
                                found_in_other = true;
                            }
                        }
                    }
                }
            }
        }

        found_in_target && !found_in_other
    }

    /// Check if position is in a gap for a pipeline
    fn check_gap(&self, samples: &[String], pos: u32, pipeline: &str, require_all: bool) -> bool {
        if require_all {
            // All samples must have gap
            samples.iter().all(|sample| self.is_gap(sample, pipeline, pos))
        } else {
            // At least one sample has gap
            samples.iter().any(|sample| self.is_gap(sample, pipeline, pos))
        }
    }

    /// Check if position has SNP in a specific pipeline
    fn check_snp_in_pipeline(&self, samples: &[String], pos: u32, pipeline: &str, require_all: bool) -> bool {
        let sample_results: Vec<bool> = samples.iter().map(|sample| {
            self.samples.get(sample)
                .and_then(|s| s.pipelines.get(pipeline))
                .map(|p| Self::find_snp(&p.snps, pos).is_some())
                .unwrap_or(false)
        }).collect();

        if require_all {
            sample_results.iter().all(|&r| r)
        } else {
            sample_results.iter().any(|&r| r)
        }
    }

    /// Legacy method for backwards compatibility
    #[wasm_bindgen]
    pub fn get_filtered_positions(&self, samples_json: &str, filters: &str) -> String {
        self.get_filtered_positions_v2(samples_json, filters, "and", "any")
    }

    /// Render filtered view (compact, only SNP positions)
    #[wasm_bindgen]
    pub fn render_filtered(&self, samples_json: &str, positions_json: &str, offset: u32, limit: u32) -> String {
        let samples: Vec<String> = serde_json::from_str(samples_json).unwrap_or_default();
        let positions: Vec<u32> = serde_json::from_str(positions_json).unwrap_or_default();

        let start = offset as usize;
        let end = (offset + limit) as usize;
        let visible: Vec<u32> = positions.iter()
            .skip(start)
            .take(end - start)
            .copied()
            .collect();

        if visible.is_empty() {
            return "<div class=\"block\"><p style=\"color:#888;padding:20px;\">No positions match this filter.</p></div>".to_string();
        }

        let mut html = String::with_capacity(visible.len() * samples.len() * 80);
        html.push_str("<div class=\"block compact\">");

        // Position markers - minimal width, full position in tooltip
        html.push_str("<div class=\"row\"><span class=\"lbl\">Pos</span><span class=\"ref\">");
        for &pos in &visible {
            html.push_str(&format!("<span class=\"pos-num\" data-pos=\"{}\">|</span>", pos));
        }
        html.push_str("</span></div>");

        // Reference row
        html.push_str("<div class=\"row\"><span class=\"lbl\">REF</span><span class=\"ref\">");
        for &pos in &visible {
            let nuc = self.get_ref_nuc(pos - 1);
            html.push_str(&format!("<span class=\"nuc\" data-pos=\"{}\">{}</span>", pos, nuc));
        }
        html.push_str("</span></div>");

        // Sample rows
        for sample in &samples {
            let sample_label = self.get_sample_label(sample);

            // Consensus row
            html.push_str(&format!("<div class=\"row\"><span class=\"lbl\">{}</span><span class=\"sample\">", sample_label));
            for &pos in &visible {
                let idx = pos - 1;

                // Check gaps
                let in_gap = self.pipeline_ids.iter().any(|p| self.is_gap(sample, p, pos));

                if in_gap {
                    html.push_str(&format!("<span class=\"gap\" data-pos=\"{}\">-</span>", pos));
                } else {
                    let alts: Vec<char> = self.pipeline_ids.iter()
                        .filter_map(|p| {
                            let alt = self.get_snp_alt(sample, p, pos);
                            if !alt.is_empty() { alt.chars().next() } else { None }
                        })
                        .collect();

                    if alts.is_empty() {
                        html.push_str(&format!("<span class=\"nuc\" data-pos=\"{}\">{}</span>", pos, self.get_ref_nuc(idx)));
                    } else if alts.len() == 1 {
                        html.push_str(&format!("<span class=\"snp-uncertain\" data-pos=\"{}\">{}</span>", pos, alts[0]));
                    } else if alts.iter().all(|&a| a == alts[0]) {
                        html.push_str(&format!("<span class=\"snp-consensus\" data-pos=\"{}\">{}</span>", pos, alts[0]));
                    } else {
                        html.push_str(&format!("<span class=\"snp-discord\" data-pos=\"{}\">{}</span>", pos, self.get_ref_nuc(idx)));
                    }
                }
            }
            html.push_str("</span></div>");

            // Pipeline-specific rows - shows VCF calls only
            // Skip ground truth pipeline (it's used for the sample row above)
            for pipeline_id in &self.pipeline_ids {
                // Skip ground truth pipeline - its data is shown in the sample row
                if let Some(ref gt) = self.ground_truth_pipeline {
                    if pipeline_id == gt {
                        continue;
                    }
                }

                let pipeline_label = self.get_pipeline_label(pipeline_id);
                html.push_str(&format!("<div class=\"row\"><span class=\"lbl sub\">{}</span><span class=\"sample\">", pipeline_label));

                for &pos in &visible {
                    let alt = self.get_snp_alt(sample, pipeline_id, pos);

                    if !alt.is_empty() {
                        html.push_str(&format!("<span class=\"snp-pipeline\" data-pos=\"{}\">{}</span>", pos, alt));
                    } else if self.is_gap(sample, pipeline_id, pos) {
                        html.push_str(&format!("<span class=\"gap\" data-pos=\"{}\">-</span>", pos));
                    } else {
                        html.push_str(&format!("<span class=\"dim\" data-pos=\"{}\">.</span>", pos));
                    }
                }
                html.push_str("</span></div>");
            }
        }

        html.push_str("</div>");
        html
    }

    /// Calculate SNP distance matrix between all samples using polymorphic_sites
    /// Returns JSON: { "samples": [...], "matrix": [[...], ...], "comparable": [[...], ...] }
    /// pipeline_filter: which pipeline's data to use
    /// mode: "vcf_bam" (use BAM bases when no VCF) or "vcf_ref" (use reference when no VCF, matches Snippy)
    #[wasm_bindgen]
    pub fn calculate_distance_matrix(&self, pipeline_filter: &str, mode: &str) -> String {
        // Check if we have polymorphic sites data
        if self.polymorphic_sites.is_empty() {
            return self.calculate_distance_matrix_fallback(pipeline_filter);
        }

        // Get the polymorphic sites for the specified pipeline
        let pipeline_id = if pipeline_filter.is_empty() {
            self.pipeline_ids.first().map(|s| s.as_str()).unwrap_or("")
        } else {
            pipeline_filter
        };

        let pipeline_sites = self.polymorphic_sites.get(pipeline_id);
        let pipeline_refs = self.polymorphic_refs.get(pipeline_id);

        let (pipeline_sites, pipeline_refs) = match (pipeline_sites, pipeline_refs) {
            (Some(sites), Some(refs)) => (sites, refs),
            _ => return self.calculate_distance_matrix_fallback(pipeline_filter),
        };

        let use_ref_mode = mode == "vcf_ref";

        let mut sorted_samples: Vec<String> = self.samples.keys().cloned().collect();
        sorted_samples.sort();
        let n = sorted_samples.len();

        let positions: Vec<u32> = pipeline_sites.keys().copied().collect();

        // Calculate pairwise distances
        let mut matrix: Vec<Vec<u32>> = vec![vec![0; n]; n];
        let mut comparable: Vec<Vec<u32>> = vec![vec![0; n]; n];

        for i in 0..n {
            for j in (i+1)..n {
                let sample_a = &sorted_samples[i];
                let sample_b = &sorted_samples[j];

                let mut dist = 0u32;
                let mut comp = 0u32;

                for &pos in &positions {
                    if let Some(site_alleles) = pipeline_sites.get(&pos) {
                        let allele_a = site_alleles.get(sample_a);
                        let allele_b = site_alleles.get(sample_b);

                        // Get reference for this position
                        let ref_base = pipeline_refs.get(&pos).copied().unwrap_or('N');

                        // Get bases based on mode
                        let base_a = match allele_a {
                            Some(a) if a.source == "gap" => None,
                            Some(a) if a.source == "vcf" => Some(a.base),
                            Some(a) if use_ref_mode => Some(ref_base), // Use ref instead of BAM
                            Some(a) => Some(a.base), // Use BAM base
                            None => if use_ref_mode { Some(ref_base) } else { None },
                        };

                        let base_b = match allele_b {
                            Some(b) if b.source == "gap" => None,
                            Some(b) if b.source == "vcf" => Some(b.base),
                            Some(b) if use_ref_mode => Some(ref_base),
                            Some(b) => Some(b.base),
                            None => if use_ref_mode { Some(ref_base) } else { None },
                        };

                        // Only count if both have valid bases
                        match (base_a, base_b) {
                            (Some(a), Some(b)) if a != 'N' && b != 'N' => {
                                comp += 1;
                                if a != b {
                                    dist += 1;
                                }
                            }
                            _ => {}
                        }
                    }
                }

                matrix[i][j] = dist;
                matrix[j][i] = dist;
                comparable[i][j] = comp;
                comparable[j][i] = comp;
            }
        }

        #[derive(Serialize)]
        struct DistanceMatrix {
            samples: Vec<String>,
            labels: Vec<String>,
            matrix: Vec<Vec<u32>>,
            comparable: Vec<Vec<u32>>,
            polymorphic_count: usize,
            pipeline: String,
            mode: String,
        }

        let labels: Vec<String> = sorted_samples.iter()
            .map(|s| self.get_sample_label(s))
            .collect();

        let result = DistanceMatrix {
            samples: sorted_samples,
            labels,
            matrix,
            comparable,
            polymorphic_count: positions.len(),
            pipeline: if pipeline_filter.is_empty() {
                self.pipeline_ids.first().cloned().unwrap_or_default()
            } else {
                pipeline_filter.to_string()
            },
            mode: mode.to_string(),
        };

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Fallback distance matrix calculation when polymorphic_sites is not available
    /// (for older reports that don't have polymorphic_sites)
    fn calculate_distance_matrix_fallback(&self, pipeline_filter: &str) -> String {
        use std::collections::HashSet;

        let mut sorted_samples: Vec<String> = self.samples.keys().cloned().collect();
        sorted_samples.sort();
        let n = sorted_samples.len();

        // Pre-compute allele map for each sample from SNP data
        let ref_bytes = self.ref_seq.as_bytes();

        let sample_alleles: Vec<HashMap<u32, u8>> = sorted_samples.iter().map(|sample_id| {
            let mut alleles: HashMap<u32, u8> = HashMap::new();

            if let Some(sample_data) = self.samples.get(sample_id) {
                // First, collect all gap positions for this sample
                let mut gap_positions: HashSet<u32> = HashSet::new();
                for (_pid, pipeline_data) in &sample_data.pipelines {
                    for gap in &pipeline_data.gaps {
                        for pos in gap.start..gap.end {
                            gap_positions.insert(pos);
                        }
                    }
                }

                // Then collect SNP alleles
                for (_pid, pipeline_data) in &sample_data.pipelines {
                    for snp in &pipeline_data.snps {
                        if !gap_positions.contains(&snp.pos) {
                            alleles.entry(snp.pos).or_insert(snp.alt_allele);
                        }
                    }
                }

                // Mark gap positions with 0
                for pos in gap_positions {
                    alleles.insert(pos, 0);
                }
            }
            alleles
        }).collect();

        // Collect all positions where at least one sample has a SNP
        let mut all_positions: HashSet<u32> = HashSet::new();
        for allele_map in &sample_alleles {
            for (&pos, &allele) in allele_map {
                if allele != 0 {
                    all_positions.insert(pos);
                }
            }
        }
        let positions: Vec<u32> = all_positions.into_iter().collect();

        // Calculate pairwise distances
        let mut matrix: Vec<Vec<u32>> = vec![vec![0; n]; n];
        let mut comparable: Vec<Vec<u32>> = vec![vec![0; n]; n];

        for i in 0..n {
            for j in (i+1)..n {
                let map_a = &sample_alleles[i];
                let map_b = &sample_alleles[j];

                let mut dist = 0u32;
                let mut comp = 0u32;

                for &pos in &positions {
                    let a_val = match map_a.get(&pos).copied() {
                        Some(0) => 0,
                        Some(v) => v,
                        None => ref_bytes.get((pos - 1) as usize).copied().unwrap_or(b'N'),
                    };
                    let b_val = match map_b.get(&pos).copied() {
                        Some(0) => 0,
                        Some(v) => v,
                        None => ref_bytes.get((pos - 1) as usize).copied().unwrap_or(b'N'),
                    };

                    if a_val == 0 || b_val == 0 {
                        continue;
                    }

                    comp += 1;
                    if a_val != b_val {
                        dist += 1;
                    }
                }

                matrix[i][j] = dist;
                matrix[j][i] = dist;
                comparable[i][j] = comp;
                comparable[j][i] = comp;
            }
        }

        #[derive(Serialize)]
        struct DistanceMatrix {
            samples: Vec<String>,
            labels: Vec<String>,
            matrix: Vec<Vec<u32>>,
            comparable: Vec<Vec<u32>>,
            polymorphic_count: usize,
        }

        let labels: Vec<String> = sorted_samples.iter()
            .map(|s| self.get_sample_label(s))
            .collect();

        let result = DistanceMatrix {
            samples: sorted_samples,
            labels,
            matrix,
            comparable,
            polymorphic_count: positions.len(),
        };

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    // Internal helper: binary search for position in gaps
    fn pos_in_gaps(gaps: &[GapRegion], pos: u32) -> bool {
        let idx = gaps.partition_point(|g| g.end <= pos);
        if idx < gaps.len() {
            let gap = &gaps[idx];
            pos >= gap.start && pos < gap.end
        } else {
            false
        }
    }

    // Internal helper: binary search for SNP at position
    fn find_snp(snps: &[Snp], pos: u32) -> Option<&Snp> {
        snps.binary_search_by_key(&pos, |s| s.pos)
            .ok()
            .map(|idx| &snps[idx])
    }

    /// Get coverage statistics per sample per pipeline
    #[wasm_bindgen]
    pub fn get_coverage_stats(&self) -> String {
        #[derive(Serialize)]
        struct PipelineStats {
            snp_count: usize,
            avg_depth: Option<f64>,
            positions: usize,
            gap_bases: usize,
            // New: min/max/avg from polymorphic sites
            depth_min: Option<u32>,
            depth_max: Option<u32>,
            depth_avg: Option<f64>,
            qual_min: Option<f64>,
            qual_max: Option<f64>,
            qual_avg: Option<f64>,
            consensus_min: Option<f64>,
            consensus_max: Option<f64>,
            consensus_avg: Option<f64>,
        }

        let mut result: HashMap<String, HashMap<String, PipelineStats>> = HashMap::new();

        for (sample_id, sample_data) in &self.samples {
            let mut sample_stats: HashMap<String, PipelineStats> = HashMap::new();

            for (pipeline_id, pipeline_data) in &sample_data.pipelines {
                let snp_count = pipeline_data.snps.len();

                // Calculate average depth from SNPs
                let avg_depth = if snp_count > 0 {
                    let total_depth: u64 = pipeline_data.snps.iter()
                        .map(|s| s.depth as u64)
                        .sum();
                    Some(total_depth as f64 / snp_count as f64)
                } else {
                    None
                };

                // Calculate total gap bases
                let gap_bases: usize = pipeline_data.gaps.iter()
                    .map(|g| (g.end - g.start) as usize)
                    .sum();

                // Positions covered = ref_len - gap_bases
                let positions = self.ref_len as usize - gap_bases;

                // Calculate min/max/avg from polymorphic sites for this sample/pipeline
                let mut depths: Vec<u32> = Vec::new();
                let mut quals: Vec<f64> = Vec::new();
                let mut consensuses: Vec<f64> = Vec::new();

                if let Some(pipeline_sites) = self.polymorphic_sites.get(pipeline_id) {
                    for (_pos, site_alleles) in pipeline_sites {
                        if let Some(allele) = site_alleles.get(sample_id) {
                            if let Some(d) = allele.depth {
                                depths.push(d);
                            }
                            if let Some(q) = allele.qual {
                                quals.push(q);
                            }
                            if let Some(c) = allele.consensus {
                                consensuses.push(c);
                            }
                        }
                    }
                    web_sys::console::log_1(&format!(
                        "Stats {}/{}: {} depths, {} quals, {} consensus from {} sites",
                        sample_id, pipeline_id, depths.len(), quals.len(), consensuses.len(), pipeline_sites.len()
                    ).into());
                } else {
                    web_sys::console::log_1(&format!(
                        "No polymorphic_sites for pipeline: {}", pipeline_id
                    ).into());
                }

                let (depth_min, depth_max, depth_avg) = if !depths.is_empty() {
                    let min = *depths.iter().min().unwrap();
                    let max = *depths.iter().max().unwrap();
                    let avg = depths.iter().map(|d| *d as f64).sum::<f64>() / depths.len() as f64;
                    (Some(min), Some(max), Some(avg))
                } else {
                    (None, None, None)
                };

                let (qual_min, qual_max, qual_avg) = if !quals.is_empty() {
                    let min = quals.iter().cloned().fold(f64::INFINITY, f64::min);
                    let max = quals.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
                    let avg = quals.iter().sum::<f64>() / quals.len() as f64;
                    (Some(min), Some(max), Some(avg))
                } else {
                    (None, None, None)
                };

                let (consensus_min, consensus_max, consensus_avg) = if !consensuses.is_empty() {
                    let min = consensuses.iter().cloned().fold(f64::INFINITY, f64::min);
                    let max = consensuses.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
                    let avg = consensuses.iter().sum::<f64>() / consensuses.len() as f64;
                    (Some(min), Some(max), Some((avg * 100.0).round() / 100.0)) // Round to 2 decimals
                } else {
                    (None, None, None)
                };

                sample_stats.insert(pipeline_id.clone(), PipelineStats {
                    snp_count,
                    avg_depth,
                    positions,
                    gap_bases,
                    depth_min,
                    depth_max,
                    depth_avg,
                    qual_min,
                    qual_max,
                    qual_avg,
                    consensus_min,
                    consensus_max,
                    consensus_avg,
                });
            }

            result.insert(sample_id.clone(), sample_stats);
        }

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }

    /// Calculate distance matrix with quality filters
    /// mode: "vcf_ref", "vcf_bam", or "bam_only"
    /// min_depth: minimum depth to consider a position
    /// min_consensus: minimum consensus percentage (0-100)
    /// min_qual: minimum VCF QUAL score (only applies to VCF-sourced alleles)
    #[wasm_bindgen]
    pub fn calculate_distance_matrix_filtered(
        &self,
        pipeline_filter: &str,
        mode: &str,
        min_depth: u32,
        min_consensus: u32,
        min_qual: f64,
    ) -> String {
        // Check if we have polymorphic sites data
        if self.polymorphic_sites.is_empty() {
            return self.calculate_distance_matrix_fallback(pipeline_filter);
        }

        // Get the polymorphic sites for the specified pipeline
        let pipeline_id = if pipeline_filter.is_empty() {
            self.pipeline_ids.first().map(|s| s.as_str()).unwrap_or("")
        } else {
            pipeline_filter
        };

        let pipeline_sites = self.polymorphic_sites.get(pipeline_id);
        let pipeline_refs = self.polymorphic_refs.get(pipeline_id);

        let (pipeline_sites, pipeline_refs) = match (pipeline_sites, pipeline_refs) {
            (Some(sites), Some(refs)) => (sites, refs),
            _ => return self.calculate_distance_matrix_fallback(pipeline_filter),
        };

        let use_bam_only = mode == "bam_only";
        let use_ref_mode = mode == "vcf_ref";

        web_sys::console::log_1(&format!(
            "Distance matrix: pipeline={}, mode={}, min_depth={}, min_consensus={}, min_qual={}, use_bam_only={}",
            pipeline_id, mode, min_depth, min_consensus, min_qual, use_bam_only
        ).into());

        let mut sorted_samples: Vec<String> = self.samples.keys().cloned().collect();
        sorted_samples.sort();
        let n = sorted_samples.len();

        let positions: Vec<u32> = pipeline_sites.keys().copied().collect();

        web_sys::console::log_1(&format!(
            "Processing {} polymorphic positions for {} samples",
            positions.len(), n
        ).into());

        // Calculate pairwise distances
        let mut matrix: Vec<Vec<u32>> = vec![vec![0; n]; n];
        let mut comparable: Vec<Vec<u32>> = vec![vec![0; n]; n];
        let mut filtered_positions = 0usize;

        for i in 0..n {
            for j in (i+1)..n {
                let sample_a = &sorted_samples[i];
                let sample_b = &sorted_samples[j];

                let mut dist = 0u32;
                let mut comp = 0u32;

                for &pos in &positions {
                    if let Some(site_alleles) = pipeline_sites.get(&pos) {
                        let allele_a = site_alleles.get(sample_a);
                        let allele_b = site_alleles.get(sample_b);

                        // Apply depth filter based on mode
                        // In BAM only mode, only filter BAM-sourced alleles
                        // In VCF modes, filter all alleles with depth data
                        if min_depth > 0 {
                            let depth_a_ok = allele_a.map_or(false, |a| {
                                if use_bam_only {
                                    // In BAM only mode, only check BAM sources
                                    if a.source == "bam" {
                                        a.depth.map_or(false, |d| d >= min_depth)
                                    } else {
                                        false // Non-BAM sources don't pass in BAM only mode
                                    }
                                } else {
                                    // In VCF modes, check all sources with depth
                                    a.depth.map_or(true, |d| d >= min_depth)
                                }
                            });
                            let depth_b_ok = allele_b.map_or(false, |b| {
                                if use_bam_only {
                                    if b.source == "bam" {
                                        b.depth.map_or(false, |d| d >= min_depth)
                                    } else {
                                        false
                                    }
                                } else {
                                    b.depth.map_or(true, |d| d >= min_depth)
                                }
                            });
                            if !depth_a_ok || !depth_b_ok {
                                continue;
                            }
                        }

                        // Apply QUAL filter for VCF-sourced alleles only
                        if min_qual > 0.0 && !use_bam_only {
                            // Check if either allele is from VCF and has low qual
                            let qual_a_ok = allele_a.map_or(true, |a| {
                                if a.source == "vcf" {
                                    a.qual.map_or(true, |q| q >= min_qual)
                                } else {
                                    true
                                }
                            });
                            let qual_b_ok = allele_b.map_or(true, |b| {
                                if b.source == "vcf" {
                                    b.qual.map_or(true, |q| q >= min_qual)
                                } else {
                                    true
                                }
                            });
                            if !qual_a_ok || !qual_b_ok {
                                continue;
                            }
                        }

                        // Apply consensus filter for BAM-sourced alleles
                        if min_consensus > 0 {
                            let min_cons_frac = min_consensus as f64 / 100.0;
                            let cons_a_ok = allele_a.map_or(true, |a| {
                                if a.source == "bam" {
                                    a.consensus.map_or(true, |c| c >= min_cons_frac)
                                } else {
                                    true
                                }
                            });
                            let cons_b_ok = allele_b.map_or(true, |b| {
                                if b.source == "bam" {
                                    b.consensus.map_or(true, |c| c >= min_cons_frac)
                                } else {
                                    true
                                }
                            });
                            if !cons_a_ok || !cons_b_ok {
                                continue;
                            }
                        }

                        // Get reference for this position
                        let ref_base = pipeline_refs.get(&pos).copied().unwrap_or('N');

                        // Get bases based on mode
                        let base_a = if use_bam_only {
                            // BAM only mode: only use BAM sources, ignore VCF
                            match allele_a {
                                Some(a) if a.source == "bam" => Some(a.base),
                                Some(a) if a.source == "gap" => None,
                                _ => None,
                            }
                        } else {
                            match allele_a {
                                Some(a) if a.source == "gap" => None,
                                Some(a) if a.source == "vcf" => Some(a.base),
                                Some(a) if use_ref_mode => Some(ref_base),
                                Some(a) => Some(a.base),
                                None => if use_ref_mode { Some(ref_base) } else { None },
                            }
                        };

                        let base_b = if use_bam_only {
                            match allele_b {
                                Some(b) if b.source == "bam" => Some(b.base),
                                Some(b) if b.source == "gap" => None,
                                _ => None,
                            }
                        } else {
                            match allele_b {
                                Some(b) if b.source == "gap" => None,
                                Some(b) if b.source == "vcf" => Some(b.base),
                                Some(b) if use_ref_mode => Some(ref_base),
                                Some(b) => Some(b.base),
                                None => if use_ref_mode { Some(ref_base) } else { None },
                            }
                        };

                        // Only count if both have valid bases
                        match (base_a, base_b) {
                            (Some(a), Some(b)) if a != 'N' && b != 'N' => {
                                comp += 1;
                                if a != b {
                                    dist += 1;
                                }
                            }
                            _ => {}
                        }
                    }
                }

                matrix[i][j] = dist;
                matrix[j][i] = dist;
                comparable[i][j] = comp;
                comparable[j][i] = comp;

                if i == 0 && j == 1 {
                    filtered_positions = comp as usize;
                    web_sys::console::log_1(&format!(
                        "First pair {}-{}: dist={}, comparable={} out of {} positions",
                        sample_a, sample_b, dist, comp, positions.len()
                    ).into());
                }
            }
        }

        #[derive(Serialize)]
        struct DistanceMatrix {
            samples: Vec<String>,
            labels: Vec<String>,
            matrix: Vec<Vec<u32>>,
            comparable: Vec<Vec<u32>>,
            polymorphic_count: usize,
            pipeline: String,
            mode: String,
            min_depth: u32,
            min_consensus: u32,
            min_qual: f64,
        }

        let labels: Vec<String> = sorted_samples.iter()
            .map(|s| self.get_sample_label(s))
            .collect();

        let result = DistanceMatrix {
            samples: sorted_samples,
            labels,
            matrix,
            comparable,
            polymorphic_count: positions.len(),
            pipeline: if pipeline_filter.is_empty() {
                self.pipeline_ids.first().cloned().unwrap_or_default()
            } else {
                pipeline_filter.to_string()
            },
            mode: mode.to_string(),
            min_depth,
            min_consensus,
            min_qual,
        };

        serde_json::to_string(&result).unwrap_or_else(|_| "{}".to_string())
    }
}

/// Initialize panic hook for better error messages
#[wasm_bindgen(start)]
pub fn init() {
    console_error_panic_hook::set_once();
}
